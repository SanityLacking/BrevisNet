{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"..\") # Adds higher directory to python modules path.\n",
    "import branchingdnn as branching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (train_ds, test_ds, validation_ds) = branching.dataset.prepare.dataset(tf.keras.datasets.cifar10.load_data(),32,5000,22500,(227,227),include_targets=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcEntropy(y_hat):\n",
    "        #entropy is the sum of y * log(y) for all possible labels.\n",
    "        if isinstance(y_hat, list):\n",
    "            y_hat = np.array(y_hat)\n",
    "        sum_entropy = 0\n",
    "        if y_hat.ndim >1:\n",
    "            return list(map(calcEntropy,y_hat))\n",
    "        for i in range(len(y_hat)):\n",
    "            if y_hat[i] != 0: # log of zero is undefined, see MacKay's book \"Information Theory, Inference, and Learning Algorithms\"  for more info on this workaround reasoning.\n",
    "                entropy =y_hat[i] * math.log(y_hat[i],2)\n",
    "                sum_entropy +=  entropy\n",
    "\n",
    "        return -sum_entropy\n",
    "    \n",
    "def calcEntropy_Tensors(y_hat):\n",
    "        #entropy is the sum of y * log(y) for all possible labels.\n",
    "        #doesn't deal with cases of log(0)\n",
    "        rank = tf.rank(y_hat)\n",
    "        def calc_E(y_hat):\n",
    "            results = tf.clip_by_value((tf.math.log(y_hat)/tf.math.log(tf.constant(2, dtype=y_hat.dtype))), -1e12, 1e12)\n",
    "#             results = tf.clip_by_value(results, -1e12, 1e12)\n",
    "#             print(\"res \", results)\n",
    "            return tf.reduce_sum(y_hat * results)\n",
    "\n",
    "        sumEntropies = (tf.map_fn(calc_E,tf.cast(y_hat,'float')))\n",
    "        \n",
    "        if rank == 1:\n",
    "            sumEntropies = tf.reduce_sum(sumEntropies)\n",
    "        return -sumEntropies\n",
    "    \n",
    "def calcEntropy_Tensors2(y_hat):\n",
    "    #entropy is the sum of y * log(y) for all possible labels.\n",
    "    #doesn't deal with cases of log(0)\n",
    "#     num = tf.math.log(y_hat)\n",
    "# #     print(\"num\",num)\n",
    "#     dem = tf.math.log(tf.constant(2, dtype=y_hat.dtype))\n",
    "# #     print(\"dem\",dem)\n",
    "#     E = num / dem\n",
    "# #     print(\"E\",E)\n",
    "#     P = y_hat * E\n",
    "# #     print(\"p\",P)\n",
    "#     mean = tf.reduce_mean(tf.boolean_mask(P, tf.math.is_finite(P)))\n",
    "#     print(\"mean\",mean)\n",
    "#     sumEntropies = mean\n",
    "    val = y_hat * tf.math.log(y_hat)/tf.math.log(tf.constant(2, dtype=y_hat.dtype))\n",
    "    sumEntropies =  tf.reduce_mean(tf.boolean_mask(val,tf.math.is_finite(val)))\n",
    "    return -sumEntropies\n",
    "    \n",
    "# This function to generate evidence is used for the first example\n",
    "def relu_evidence(logits):\n",
    "    return tf.nn.relu(logits)\n",
    "\n",
    "# This one usually works better and used for the second and third examples\n",
    "# For general settings and different datasets, you may try this one first\n",
    "def exp_evidence(logits): \n",
    "    return tf.exp(tf.clip_by_value(logits,-10,10))\n",
    "\n",
    "# This one is another alternative and \n",
    "# usually behaves better than the relu_evidence \n",
    "def softplus_evidence(logits):\n",
    "    return tf.nn.softplus(logits)\n",
    "\n",
    "def KL(alpha):\n",
    "    # print(\"K:\",K)\n",
    "    beta=tf.constant(np.ones((1,K)),dtype=tf.float32)\n",
    "    S_alpha = tf.reduce_sum(alpha,axis=1,keepdims=True)\n",
    "    S_beta = tf.reduce_sum(beta,axis=1,keepdims=True)\n",
    "    lnB = tf.compat.v1.lgamma(S_alpha) - tf.reduce_sum(tf.compat.v1.lgamma(alpha),axis=1,keepdims=True)\n",
    "    lnB_uni = tf.reduce_sum(tf.compat.v1.lgamma(beta),axis=1,keepdims=True) - tf.compat.v1.lgamma(S_beta)\n",
    "\n",
    "    dg0 = tf.compat.v1.digamma(S_alpha)\n",
    "    dg1 = tf.compat.v1.digamma(alpha)\n",
    "\n",
    "    kl = tf.reduce_sum((alpha - beta)*(dg1-dg0),axis=1,keepdims=True) + lnB + lnB_uni\n",
    "    # print(\"kl\", kl)\n",
    "    return kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyEndpoint(tf.keras.layers.Layer):\n",
    "        def __init__(self, num_outputs, name=None, **kwargs):\n",
    "            super(CrossEntropyEndpoint, self).__init__(name=name)\n",
    "            self.num_outputs = num_outputs\n",
    "#             self.kl = tf.keras.losses.KLDivergence()\n",
    "            self.loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "#             self.loss_fn = tf.keras.losses.categorical_crossentropy\n",
    "            self.evidence = softplus_evidence\n",
    "#             self.evidence = tf.compat.v1.distributions.Dirichlet\n",
    "            self.temperature = 10\n",
    "            self.lmb = 0.005\n",
    "        def build(self, input_shape):\n",
    "            self.kernel = self.add_weight(\"kernel\", shape=[int(input_shape[-1]), self.num_outputs])\n",
    "        \n",
    "        def get_config(self):\n",
    "            config = super().get_config().copy()\n",
    "            config.update({\n",
    "                'num_outputs': self.num_outputs,\n",
    "                'name': self.name\n",
    "            })\n",
    "            return config\n",
    "\n",
    "        def call(self, inputs, labels,learning_rate=1):\n",
    "            outputs = tf.matmul(inputs,self.kernel)\n",
    "            softmax = tf.nn.softmax(outputs)\n",
    "            evidence = self.evidence (outputs)\n",
    "            alpha = evidence + 1\n",
    "            u = self.num_outputs / tf.reduce_sum(alpha, axis=1, keepdims=True) #uncertainty\n",
    "          \n",
    "            # prob = alpha/tf.reduce_sum(alpha, 1, keepdims=True) \n",
    "            pred = tf.argmax(outputs,1)\n",
    "            truth = tf.argmax(labels,1)\n",
    "            match = tf.reshape(tf.cast(tf.equal(pred, truth), tf.float32),(-1,1))\n",
    "            # total_evidence = tf.reduce_sum(evidence,1, keepdims=True)\n",
    "            mean_succ = tf.reduce_sum(tf.reduce_sum(evidence,1, keepdims=True)*match) / tf.reduce_sum(match+1e-20)\n",
    "            mean_fail = tf.reduce_sum(tf.reduce_sum(tf.reduce_sum(evidence,1, keepdims=True)*(1-match)) / (tf.reduce_sum(tf.abs(1-match))+1e-20) )\n",
    "            \n",
    "            self.add_metric(evidence, name=self.name+\"_evidence\",aggregation='mean')\n",
    "            self.add_metric(mean_succ, name=self.name+\"_mean_ev_succ\",aggregation='mean')\n",
    "            self.add_metric(mean_fail, name=self.name+\"_mean_ev_fail\",aggregation='mean')\n",
    "            \n",
    "            return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(annealing_rate=1, momentum=1, decay=1, global_loss=False):\n",
    "    #create a wrapper function that returns a function\n",
    "    temperature = 1\n",
    "    Classes = 10\n",
    "    keras_kl = tf.keras.losses.KLDivergence()\n",
    "    annealing_rate = annealing_rate\n",
    "    momentum_rate = momentum\n",
    "    decay_rate = decay\n",
    "\n",
    "    def cross_entropy_evidence(labels, outputs): \n",
    "        softmax = tf.nn.softmax(outputs)\n",
    "        # activated_outputs =tf.keras.activations.sigmoid(softmax)\n",
    "        evidence = softplus_evidence(outputs)\n",
    "        alpha = evidence + 1\n",
    "        S = tf.reduce_sum(alpha, axis=1, keepdims=True) \n",
    "        E = alpha - 1\n",
    "        m = alpha / S\n",
    "        A = tf.reduce_sum((labels-m)**2, axis=1, keepdims=True) \n",
    "        B = tf.reduce_sum(alpha*(S-alpha)/(S*S*(S+1)), axis=1, keepdims=True) \n",
    "\n",
    "        annealing_coef = tf.minimum(1.0,tf.cast(annealing_rate,tf.float32))\n",
    "#         annealing_coef = 1\n",
    "        alp = E*(1-labels) + 1 \n",
    "        C =  annealing_coef * KL(alp)\n",
    "        # C = keras_kl(labels,evidence)\n",
    "        loss = tf.keras.losses.categorical_crossentropy(labels, softmax)\n",
    "        pred = tf.argmax(outputs,1)\n",
    "        truth = tf.argmax(labels,1)\n",
    "        match = tf.reshape(tf.cast(tf.equal(pred, truth), tf.float32),(-1,1))\n",
    "        return loss + C\n",
    "        # return (A + B) + C\n",
    "\n",
    "    return  cross_entropy_evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10\n",
    "def loss_function(annealing_rate=1, momentum=1, decay=1, global_loss=False):\n",
    "    #create a wrapper function that returns a function\n",
    "    temperature = 1\n",
    "    Classes = 10\n",
    "    keras_kl = tf.keras.losses.KLDivergence()\n",
    "    annealing_rate = annealing_rate\n",
    "    momentum_rate = momentum\n",
    "    decay_rate = decay\n",
    "    def cross_entropy_evidence(labels, outputs): \n",
    "        softmax = tf.nn.softmax(outputs)\n",
    "        # activated_outputs =tf.keras.activations.sigmoid(softmax)\n",
    "        evidence = softplus_evidence(outputs)\n",
    "        alpha = evidence + 1\n",
    "        S = tf.reduce_sum(alpha, axis=1, keepdims=True) \n",
    "        E = alpha - 1\n",
    "        m = alpha / S\n",
    "        A = tf.reduce_sum((labels-m)**2, axis=1, keepdims=True) \n",
    "        B = tf.reduce_sum(alpha*(S-alpha)/(S*S*(S+1)), axis=1, keepdims=True) \n",
    "\n",
    "        annealing_coef = tf.minimum(1.0,tf.cast(annealing_rate,tf.float32))\n",
    "#         annealing_coef = 1\n",
    "        alp = E*(1-labels) + 1 \n",
    "        # print(\"alp\", alp)\n",
    "        C =  annealing_coef * KL(alp)\n",
    "        # C = keras_kl(labels,evidence)\n",
    "        loss = tf.keras.losses.categorical_crossentropy(labels, softmax)\n",
    "        pred = tf.argmax(outputs,1)\n",
    "        truth = tf.argmax(labels,1)\n",
    "        match = tf.reshape(tf.cast(tf.equal(pred, truth), tf.float32),(-1,1))\n",
    "        return loss + C\n",
    "        # return (A + B) + C\n",
    "    return  cross_entropy_evidence\n",
    "\n",
    "# outputs =[]\n",
    "# targets = tf.keras.Input(shape=(10,),name='targets')\n",
    "# inputs = tf.keras.Input(shape=(227,227,3))\n",
    "# x = tf.keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(227,227,3))(inputs)\n",
    "# x = tf.keras.layers.BatchNormalization()(x)\n",
    "# x = tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2),padding=\"same\")(x)\n",
    "\n",
    "\n",
    "# branchLayer = tf.keras.layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))(x)\n",
    "# branchLayer = tf.keras.layers.Dense(124, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch124\"))(branchLayer)\n",
    "# branchLayer = tf.keras.layers.Dense(64, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch64\"))(branchLayer)\n",
    "# # branchLayer = tf.keras.layers.Dense(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_output\"))(branchLayer)\n",
    "# # branch_output_1 = (CrossEntropyEndpoint(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_endpoint\"))(branchLayer,targets))\n",
    "# branch_output_1 = tf.keras.layers.Dense(10, activation=\"softmax\", name=tf.compat.v1.get_default_graph().unique_name(\"branch_endpoint\"))(branchLayer)\n",
    "\n",
    "# x = tf.keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "# x = tf.keras.layers.BatchNormalization()(x)\n",
    "# x = tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2),padding=\"same\")(x)\n",
    "\n",
    "\n",
    "# branchLayer = tf.keras.layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))(x)\n",
    "# branchLayer = tf.keras.layers.Dense(124, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch124\"))(branchLayer)\n",
    "# branchLayer = tf.keras.layers.Dense(64, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch64\"))(branchLayer)\n",
    "# # branchLayer = tf.keras.layers.Dense(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_output\"))(branchLayer)\n",
    "# # branch_output_2 = (CrossEntropyEndpoint(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_endpoint\"))(branchLayer,targets))\n",
    "# branch_output_2 = tf.keras.layers.Dense(10, activation=\"softmax\", name=tf.compat.v1.get_default_graph().unique_name(\"branch_endpoint\"))(branchLayer)\n",
    "\n",
    "# x = tf.keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "# x = tf.keras.layers.BatchNormalization()(x)\n",
    "# x = tf.keras.layers.Conv2D(filters=384, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "# x = tf.keras.layers.BatchNormalization()(x)\n",
    "# x = tf.keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "# x = tf.keras.layers.BatchNormalization()(x)\n",
    "# x = tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2),padding=\"same\")(x)\n",
    "# x = tf.keras.layers.Flatten()(x)\n",
    "# x = tf.keras.layers.Dense(4096, activation='relu')(x)\n",
    "\n",
    "\n",
    "\n",
    "# branchLayer = tf.keras.layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))(x)\n",
    "# branchLayer = tf.keras.layers.Dense(124, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch124\"))(branchLayer)\n",
    "# branchLayer = tf.keras.layers.Dense(64, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch64\"))(branchLayer)\n",
    "# # branchLayer = tf.keras.layers.Dense(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_endpoint\"))(branchLayer)\n",
    "# branch_output_3 = tf.keras.layers.Dense(10, activation=\"softmax\", name=tf.compat.v1.get_default_graph().unique_name(\"branch_endpoint\"))(branchLayer)\n",
    "# # branch_output_3 = (CrossEntropyEndpoint(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_endpoint\"))(branchLayer,targets))\n",
    "\n",
    "# x = tf.keras.layers.Dropout(0.5)(x)\n",
    "# x = tf.keras.layers.Dense(4096, activation='relu')(x)\n",
    "# x = tf.keras.layers.Dropout(0.5)(x)\n",
    "# output = tf.keras.layers.Dense(10, activation=\"softmax\", name=tf.compat.v1.get_default_graph().unique_name(\"endpoint\"))(x)\n",
    "# # output = CrossEntropyEndpoint(10, name=tf.compat.v1.get_default_graph().unique_name(\"endpoint\"))(x, targets)\n",
    "\n",
    "# model = tf.keras.Model(inputs=[inputs,targets], outputs=[output,branch_output_1,branch_output_2,branch_output_3], name=\"alexnet_branched_entropy\")\n",
    "# loss_fn = loss_function()\n",
    "# model.compile( loss=\"categorical_crossentropy\", optimizer=tf.optimizers.SGD(lr=0.001,momentum=0.9), metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# root_logdir = os.path.join(os.curdir, \"logs\\\\fit\\\\\")\n",
    "# checkpoint = tf.keras.callbacks.ModelCheckpoint(\"alexNetv6_entropy_branched_scratch_40.hdf5\", monitor='val_loss',verbose=1,save_best_only=True, mode='auto')\n",
    "# def get_run_logdir():\n",
    "#     run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "#     return os.path.join(root_logdir, run_id)\n",
    "\n",
    "# run_logdir = get_run_logdir()\n",
    "# tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "# model.fit(train_ds,\n",
    "#         epochs=40,\n",
    "#         validation_data=validation_ds,\n",
    "#         validation_freq=1,\n",
    "#         # batch_size=1,\n",
    "#         verbose=1,\n",
    "#         callbacks=[tensorboard_cb,checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augment Dataset\n",
      "targetsis : True\n",
      "adding targets to inputs\n",
      "trainSize 45000\n",
      "testSize 10000\n"
     ]
    }
   ],
   "source": [
    "dataset = branching.dataset.prepare.dataset(tf.keras.datasets.cifar10.load_data(),32,5000,22500,(224,224), include_targets=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (train_ds, validation_ds, test_ds) = dataset\n",
    "# print(train_ds.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets already present?  False\n",
      "added targets\n",
      "Matching Branchpoint by id number\n",
      "Matching Branchpoint by name\n",
      "add Branch to branch point  conv2_block1_out\n",
      "TensorShape([None, 56, 56, 256])\n",
      "TensorShape([None, 26, 26, 32])\n",
      "TensorShape([None, 11, 11, 32])\n",
      "TensorShape([None, 3872])\n",
      "inputShape TensorShape([None, 3872])\n",
      "add Branch to branch point  conv2_block3_out\n",
      "TensorShape([None, 56, 56, 256])\n",
      "TensorShape([None, 26, 26, 32])\n",
      "TensorShape([None, 11, 11, 32])\n",
      "TensorShape([None, 3872])\n",
      "inputShape TensorShape([None, 3872])\n",
      "add Branch to branch point  conv3_block4_out\n",
      "TensorShape([None, 28, 28, 512])\n",
      "TensorShape([None, 12, 12, 32])\n",
      "TensorShape([None, 4, 4, 32])\n",
      "TensorShape([None, 512])\n",
      "inputShape TensorShape([None, 512])\n",
      "<branchingdnn.core.BranchingDnn.branched_model object at 0x000002A48E29D9B0>\n"
     ]
    }
   ],
   "source": [
    "# model  = tf.keras.models.load_model('alexNetv6_evidence_branched_contin_30.hdf5', custom_objects={\"CrossEntropyEndpoint\":CrossEntropyEndpoint,\"cross_entropy_evidence\":loss_function()})\n",
    "\n",
    "loss_fn = loss_function()\n",
    "brevis = (branching.core.branched_model(modelName=\"../models/resnet50_finetuned.hdf5\",saveName=\"resNet_evidence_conv2d\",transfer=True,customOptions=\"\")\n",
    "            .add_branches(branching.branches.branch.branch_conv2d_resnet_evidence,[\"conv2_block1_out\",\"conv2_block3_out\",\"conv3_block4_out\"], target_input=True)\n",
    "            .set_dataset(dataset)\n",
    "            \n",
    "            )\n",
    "# brevis.evaluate(test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_branched\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "branch_conv2d (Conv2D)          (None, 54, 54, 32)   73760       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "branch_conv2d_2 (Conv2D)        (None, 54, 54, 32)   73760       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "branch_conv2d_4 (Conv2D)        (None, 26, 26, 32)   147488      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "branch_batchnorm (BatchNormaliz (None, 54, 54, 32)   128         branch_conv2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "branch_batchnorm_2 (BatchNormal (None, 54, 54, 32)   128         branch_conv2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "branch_batchnorm_4 (BatchNormal (None, 26, 26, 32)   128         branch_conv2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "branch_maxpool (MaxPooling2D)   (None, 26, 26, 32)   0           branch_batchnorm[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "branch_maxpool_2 (MaxPooling2D) (None, 26, 26, 32)   0           branch_batchnorm_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "branch_maxpool_4 (MaxPooling2D) (None, 12, 12, 32)   0           branch_batchnorm_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "branch_conv2d_1 (Conv2D)        (None, 24, 24, 32)   9248        branch_maxpool[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "branch_conv2d_3 (Conv2D)        (None, 24, 24, 32)   9248        branch_maxpool_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "branch_conv2d_5 (Conv2D)        (None, 10, 10, 32)   9248        branch_maxpool_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "branch_batchnorm_1 (BatchNormal (None, 24, 24, 32)   128         branch_conv2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "branch_batchnorm_3 (BatchNormal (None, 24, 24, 32)   128         branch_conv2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "branch_batchnorm_5 (BatchNormal (None, 10, 10, 32)   128         branch_conv2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         2098176     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "branch_maxpool_1 (MaxPooling2D) (None, 11, 11, 32)   0           branch_batchnorm_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "branch_maxpool_3 (MaxPooling2D) (None, 11, 11, 32)   0           branch_batchnorm_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "branch_maxpool_5 (MaxPooling2D) (None, 4, 4, 32)     0           branch_batchnorm_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          524800      dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "branch_flatten (Flatten)        (None, 3872)         0           branch_maxpool_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "targets (InputLayer)            [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "branch_flatten_1 (Flatten)      (None, 3872)         0           branch_maxpool_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "branch_flatten_2 (Flatten)      (None, 512)          0           branch_maxpool_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "classification (Dense)          (None, 10)           5130        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "branch_softmax (CrossEntropyEnd (None, 10)           38720       branch_flatten[0][0]             \n",
      "                                                                 targets[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "branch_softmax_1 (CrossEntropyE (None, 10)           38720       branch_flatten_1[0][0]           \n",
      "                                                                 targets[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "branch_softmax_2 (CrossEntropyE (None, 10)           5120        branch_flatten_2[0][0]           \n",
      "                                                                 targets[0][0]                    \n",
      "==================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 26,621,898\n",
      "Trainable params: 26,568,394\n",
      "Non-trainable params: 53,504\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "brevis.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting Main Layers  and branch layers training to true\n",
      "Model: \"model_branched\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "branch_conv2d (Conv2D)          (None, 54, 54, 32)   73760       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "branch_conv2d_2 (Conv2D)        (None, 54, 54, 32)   73760       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "branch_conv2d_4 (Conv2D)        (None, 26, 26, 32)   147488      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "branch_batchnorm (BatchNormaliz (None, 54, 54, 32)   128         branch_conv2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "branch_batchnorm_2 (BatchNormal (None, 54, 54, 32)   128         branch_conv2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "branch_batchnorm_4 (BatchNormal (None, 26, 26, 32)   128         branch_conv2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "branch_maxpool (MaxPooling2D)   (None, 26, 26, 32)   0           branch_batchnorm[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "branch_maxpool_2 (MaxPooling2D) (None, 26, 26, 32)   0           branch_batchnorm_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "branch_maxpool_4 (MaxPooling2D) (None, 12, 12, 32)   0           branch_batchnorm_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "branch_conv2d_1 (Conv2D)        (None, 24, 24, 32)   9248        branch_maxpool[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "branch_conv2d_3 (Conv2D)        (None, 24, 24, 32)   9248        branch_maxpool_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "branch_conv2d_5 (Conv2D)        (None, 10, 10, 32)   9248        branch_maxpool_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "branch_batchnorm_1 (BatchNormal (None, 24, 24, 32)   128         branch_conv2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "branch_batchnorm_3 (BatchNormal (None, 24, 24, 32)   128         branch_conv2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "branch_batchnorm_5 (BatchNormal (None, 10, 10, 32)   128         branch_conv2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         2098176     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "branch_maxpool_1 (MaxPooling2D) (None, 11, 11, 32)   0           branch_batchnorm_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "branch_maxpool_3 (MaxPooling2D) (None, 11, 11, 32)   0           branch_batchnorm_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "branch_maxpool_5 (MaxPooling2D) (None, 4, 4, 32)     0           branch_batchnorm_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          524800      dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "branch_flatten (Flatten)        (None, 3872)         0           branch_maxpool_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "targets (InputLayer)            [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "branch_flatten_1 (Flatten)      (None, 3872)         0           branch_maxpool_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "branch_flatten_2 (Flatten)      (None, 512)          0           branch_maxpool_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "classification (Dense)          (None, 10)           5130        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "branch_softmax (CrossEntropyEnd (None, 10)           38720       branch_flatten[0][0]             \n",
      "                                                                 targets[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "branch_softmax_1 (CrossEntropyE (None, 10)           38720       branch_flatten_1[0][0]           \n",
      "                                                                 targets[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "branch_softmax_2 (CrossEntropyE (None, 10)           5120        branch_flatten_2[0][0]           \n",
      "                                                                 targets[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 26,621,898\n",
      "Trainable params: 26,568,394\n",
      "Non-trainable params: 53,504\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "customOption: Other\n",
      "https://app.neptune.ai/cailen01/branchingDNN/e/BRAN-333\n",
      "Remember to stop your run once youve finished logging your metadata (https://docs.neptune.ai/api-reference/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1406/1406 [==============================] - ETA: 0s - loss: 6.9430 - classification_loss: 2.1888 - branch_softmax_loss: 1.8135 - branch_softmax_1_loss: 1.6583 - branch_softmax_2_loss: 1.2824 - classification_accuracy: 0.9833 - branch_softmax_accuracy: 0.4571 - branch_softmax_1_accuracy: 0.5123 - branch_softmax_2_accuracy: 0.5859 - branch_softmax_evidence: 0.0177 - branch_softmax_mean_ev_succ: 0.2259 - branch_softmax_mean_ev_fail: 0.1245 - branch_softmax_1_evidence: 0.0258 - branch_softmax_1_mean_ev_succ: 0.3205 - branch_softmax_1_mean_ev_fail: 0.1667 - branch_softmax_2_evidence: 0.0335 - branch_softmax_2_mean_ev_succ: 0.3945 - branch_softmax_2_mean_ev_fail: 0.1998"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: string series 'monitoring/stdout' value was longer than 1000 characters and was truncated. This warning is printed only once per series.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1406/1406 [==============================] - 665s 458ms/step - loss: 6.9421 - classification_loss: 2.1888 - branch_softmax_loss: 1.8132 - branch_softmax_1_loss: 1.6579 - branch_softmax_2_loss: 1.2822 - classification_accuracy: 0.9833 - branch_softmax_accuracy: 0.4571 - branch_softmax_1_accuracy: 0.5124 - branch_softmax_2_accuracy: 0.5860 - branch_softmax_evidence: 0.0177 - branch_softmax_mean_ev_succ: 0.2259 - branch_softmax_mean_ev_fail: 0.1245 - branch_softmax_1_evidence: 0.0258 - branch_softmax_1_mean_ev_succ: 0.3205 - branch_softmax_1_mean_ev_fail: 0.1667 - branch_softmax_2_evidence: 0.0335 - branch_softmax_2_mean_ev_succ: 0.3945 - branch_softmax_2_mean_ev_fail: 0.1998 - val_loss: 5.1964 - val_classification_loss: 2.1815 - val_branch_softmax_loss: 1.2192 - val_branch_softmax_1_loss: 1.0814 - val_branch_softmax_2_loss: 0.7144 - val_classification_accuracy: 0.9862 - val_branch_softmax_accuracy: 0.5978 - val_branch_softmax_1_accuracy: 0.6420 - val_branch_softmax_2_accuracy: 0.7518 - val_branch_softmax_evidence: 0.0100 - val_branch_softmax_mean_ev_succ: 0.1305 - val_branch_softmax_mean_ev_fail: 0.0561 - val_branch_softmax_1_evidence: 0.0402 - val_branch_softmax_1_mean_ev_succ: 0.4815 - val_branch_softmax_1_mean_ev_fail: 0.2622 - val_branch_softmax_2_evidence: 0.0200 - val_branch_softmax_2_mean_ev_succ: 0.2439 - val_branch_softmax_2_mean_ev_fail: 0.0649\n",
      "\n",
      "Epoch 00001: saving model to models\\resNet_evidence_conv2d.hdf5\n",
      "Epoch 2/30\n",
      "1406/1406 [==============================] - 663s 462ms/step - loss: 4.6152 - classification_loss: 2.1735 - branch_softmax_loss: 1.0194 - branch_softmax_1_loss: 0.8446 - branch_softmax_2_loss: 0.5777 - classification_accuracy: 0.9923 - branch_softmax_accuracy: 0.6502 - branch_softmax_1_accuracy: 0.7090 - branch_softmax_2_accuracy: 0.8001 - branch_softmax_evidence: 0.0118 - branch_softmax_mean_ev_succ: 0.1519 - branch_softmax_mean_ev_fail: 0.0530 - branch_softmax_1_evidence: 0.0169 - branch_softmax_1_mean_ev_succ: 0.2128 - branch_softmax_1_mean_ev_fail: 0.0614 - branch_softmax_2_evidence: 0.0260 - branch_softmax_2_mean_ev_succ: 0.3083 - branch_softmax_2_mean_ev_fail: 0.0622 - val_loss: 5.7156 - val_classification_loss: 2.1864 - val_branch_softmax_loss: 1.8551 - val_branch_softmax_1_loss: 0.9072 - val_branch_softmax_2_loss: 0.7669 - val_classification_accuracy: 0.9828 - val_branch_softmax_accuracy: 0.4619 - val_branch_softmax_1_accuracy: 0.6831 - val_branch_softmax_2_accuracy: 0.7474 - val_branch_softmax_evidence: 0.0078 - val_branch_softmax_mean_ev_succ: 0.1202 - val_branch_softmax_mean_ev_fail: 0.0418 - val_branch_softmax_1_evidence: 0.0152 - val_branch_softmax_1_mean_ev_succ: 0.1831 - val_branch_softmax_1_mean_ev_fail: 0.0884 - val_branch_softmax_2_evidence: 0.0207 - val_branch_softmax_2_mean_ev_succ: 0.2654 - val_branch_softmax_2_mean_ev_fail: 0.0379\n",
      "\n",
      "Epoch 00002: saving model to models\\resNet_evidence_conv2d.hdf5\n",
      "Epoch 3/30\n",
      "1406/1406 [==============================] - 666s 464ms/step - loss: 4.2301 - classification_loss: 2.1708 - branch_softmax_loss: 0.8771 - branch_softmax_1_loss: 0.7356 - branch_softmax_2_loss: 0.4466 - classification_accuracy: 0.9944 - branch_softmax_accuracy: 0.6988 - branch_softmax_1_accuracy: 0.7489 - branch_softmax_2_accuracy: 0.8464 - branch_softmax_evidence: 0.0123 - branch_softmax_mean_ev_succ: 0.1552 - branch_softmax_mean_ev_fail: 0.0474 - branch_softmax_1_evidence: 0.0159 - branch_softmax_1_mean_ev_succ: 0.1968 - branch_softmax_1_mean_ev_fail: 0.0470 - branch_softmax_2_evidence: 0.0265 - branch_softmax_2_mean_ev_succ: 0.3059 - branch_softmax_2_mean_ev_fail: 0.0443 - val_loss: 4.7189 - val_classification_loss: 2.1825 - val_branch_softmax_loss: 1.0998 - val_branch_softmax_1_loss: 0.8970 - val_branch_softmax_2_loss: 0.5395 - val_classification_accuracy: 0.9846 - val_branch_softmax_accuracy: 0.6352 - val_branch_softmax_1_accuracy: 0.6945 - val_branch_softmax_2_accuracy: 0.8135 - val_branch_softmax_evidence: 0.0031 - val_branch_softmax_mean_ev_succ: 0.0422 - val_branch_softmax_mean_ev_fail: 0.0117 - val_branch_softmax_1_evidence: 0.0306 - val_branch_softmax_1_mean_ev_succ: 0.3998 - val_branch_softmax_1_mean_ev_fail: 0.0934 - val_branch_softmax_2_evidence: 0.0208 - val_branch_softmax_2_mean_ev_succ: 0.2469 - val_branch_softmax_2_mean_ev_fail: 0.0374\n",
      "\n",
      "Epoch 00003: saving model to models\\resNet_evidence_conv2d.hdf5\n",
      "Epoch 4/30\n",
      "1406/1406 [==============================] - 669s 465ms/step - loss: 3.9971 - classification_loss: 2.1675 - branch_softmax_loss: 0.8042 - branch_softmax_1_loss: 0.6661 - branch_softmax_2_loss: 0.3593 - classification_accuracy: 0.9967 - branch_softmax_accuracy: 0.7234 - branch_softmax_1_accuracy: 0.7694 - branch_softmax_2_accuracy: 0.8783 - branch_softmax_evidence: 0.0124 - branch_softmax_mean_ev_succ: 0.1542 - branch_softmax_mean_ev_fail: 0.0426 - branch_softmax_1_evidence: 0.0167 - branch_softmax_1_mean_ev_succ: 0.2045 - branch_softmax_1_mean_ev_fail: 0.0412 - branch_softmax_2_evidence: 0.0302 - branch_softmax_2_mean_ev_succ: 0.3402 - branch_softmax_2_mean_ev_fail: 0.0345 - val_loss: 4.8103 - val_classification_loss: 2.1787 - val_branch_softmax_loss: 1.2335 - val_branch_softmax_1_loss: 0.8443 - val_branch_softmax_2_loss: 0.5538 - val_classification_accuracy: 0.9868 - val_branch_softmax_accuracy: 0.6154 - val_branch_softmax_1_accuracy: 0.7073 - val_branch_softmax_2_accuracy: 0.8143 - val_branch_softmax_evidence: 0.0901 - val_branch_softmax_mean_ev_succ: 1.0701 - val_branch_softmax_mean_ev_fail: 0.6241 - val_branch_softmax_1_evidence: 0.0303 - val_branch_softmax_1_mean_ev_succ: 0.3777 - val_branch_softmax_1_mean_ev_fail: 0.1259 - val_branch_softmax_2_evidence: 0.0235 - val_branch_softmax_2_mean_ev_succ: 0.2838 - val_branch_softmax_2_mean_ev_fail: 0.0212\n",
      "\n",
      "Epoch 00004: saving model to models\\resNet_evidence_conv2d.hdf5\n",
      "Epoch 5/30\n",
      "1406/1406 [==============================] - 669s 465ms/step - loss: 3.8051 - classification_loss: 2.1676 - branch_softmax_loss: 0.7404 - branch_softmax_1_loss: 0.6032 - branch_softmax_2_loss: 0.2940 - classification_accuracy: 0.9964 - branch_softmax_accuracy: 0.7444 - branch_softmax_1_accuracy: 0.7955 - branch_softmax_2_accuracy: 0.9005 - branch_softmax_evidence: 0.0112 - branch_softmax_mean_ev_succ: 0.1376 - branch_softmax_mean_ev_fail: 0.0385 - branch_softmax_1_evidence: 0.0158 - branch_softmax_1_mean_ev_succ: 0.1912 - branch_softmax_1_mean_ev_fail: 0.0336 - branch_softmax_2_evidence: 0.0331 - branch_softmax_2_mean_ev_succ: 0.3644 - branch_softmax_2_mean_ev_fail: 0.0271 - val_loss: 4.6867 - val_classification_loss: 2.1823 - val_branch_softmax_loss: 0.9640 - val_branch_softmax_1_loss: 0.8543 - val_branch_softmax_2_loss: 0.6860 - val_classification_accuracy: 0.9830 - val_branch_softmax_accuracy: 0.6719 - val_branch_softmax_1_accuracy: 0.7051 - val_branch_softmax_2_accuracy: 0.7835 - val_branch_softmax_evidence: 0.0097 - val_branch_softmax_mean_ev_succ: 0.1286 - val_branch_softmax_mean_ev_fail: 0.0337 - val_branch_softmax_1_evidence: 0.0146 - val_branch_softmax_1_mean_ev_succ: 0.1928 - val_branch_softmax_1_mean_ev_fail: 0.0328 - val_branch_softmax_2_evidence: 0.0301 - val_branch_softmax_2_mean_ev_succ: 0.3734 - val_branch_softmax_2_mean_ev_fail: 0.0349\n",
      "\n",
      "Epoch 00005: saving model to models\\resNet_evidence_conv2d.hdf5\n",
      "Epoch 6/30\n",
      "1406/1406 [==============================] - 669s 466ms/step - loss: 3.6814 - classification_loss: 2.1665 - branch_softmax_loss: 0.7126 - branch_softmax_1_loss: 0.5657 - branch_softmax_2_loss: 0.2366 - classification_accuracy: 0.9971 - branch_softmax_accuracy: 0.7568 - branch_softmax_1_accuracy: 0.8053 - branch_softmax_2_accuracy: 0.9182 - branch_softmax_evidence: 0.0114 - branch_softmax_mean_ev_succ: 0.1391 - branch_softmax_mean_ev_fail: 0.0338 - branch_softmax_1_evidence: 0.0165 - branch_softmax_1_mean_ev_succ: 0.1975 - branch_softmax_1_mean_ev_fail: 0.0335 - branch_softmax_2_evidence: 0.0393 - branch_softmax_2_mean_ev_succ: 0.4259 - branch_softmax_2_mean_ev_fail: 0.0270 - val_loss: 4.7480 - val_classification_loss: 2.1899 - val_branch_softmax_loss: 0.9472 - val_branch_softmax_1_loss: 0.8205 - val_branch_softmax_2_loss: 0.7904 - val_classification_accuracy: 0.9790 - val_branch_softmax_accuracy: 0.6819 - val_branch_softmax_1_accuracy: 0.7292 - val_branch_softmax_2_accuracy: 0.7660 - val_branch_softmax_evidence: 0.0042 - val_branch_softmax_mean_ev_succ: 0.0577 - val_branch_softmax_mean_ev_fail: 0.0089 - val_branch_softmax_1_evidence: 0.0174 - val_branch_softmax_1_mean_ev_succ: 0.2234 - val_branch_softmax_1_mean_ev_fail: 0.0402 - val_branch_softmax_2_evidence: 0.0245 - val_branch_softmax_2_mean_ev_succ: 0.3101 - val_branch_softmax_2_mean_ev_fail: 0.0301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00006: saving model to models\\resNet_evidence_conv2d.hdf5\n",
      "Epoch 7/30\n",
      "1406/1406 [==============================] - 671s 467ms/step - loss: 3.5593 - classification_loss: 2.1654 - branch_softmax_loss: 0.6774 - branch_softmax_1_loss: 0.5258 - branch_softmax_2_loss: 0.1908 - classification_accuracy: 0.9977 - branch_softmax_accuracy: 0.7651 - branch_softmax_1_accuracy: 0.8163 - branch_softmax_2_accuracy: 0.9346 - branch_softmax_evidence: 0.0124 - branch_softmax_mean_ev_succ: 0.1520 - branch_softmax_mean_ev_fail: 0.0328 - branch_softmax_1_evidence: 0.0155 - branch_softmax_1_mean_ev_succ: 0.1839 - branch_softmax_1_mean_ev_fail: 0.0260 - branch_softmax_2_evidence: 0.0424 - branch_softmax_2_mean_ev_succ: 0.4539 - branch_softmax_2_mean_ev_fail: 0.0232 - val_loss: 5.4303 - val_classification_loss: 2.2061 - val_branch_softmax_loss: 1.3626 - val_branch_softmax_1_loss: 0.9544 - val_branch_softmax_2_loss: 0.9072 - val_classification_accuracy: 0.9635 - val_branch_softmax_accuracy: 0.5829 - val_branch_softmax_1_accuracy: 0.6803 - val_branch_softmax_2_accuracy: 0.7484 - val_branch_softmax_evidence: 0.0135 - val_branch_softmax_mean_ev_succ: 0.1787 - val_branch_softmax_mean_ev_fail: 0.0777 - val_branch_softmax_1_evidence: 0.0104 - val_branch_softmax_1_mean_ev_succ: 0.1355 - val_branch_softmax_1_mean_ev_fail: 0.0360 - val_branch_softmax_2_evidence: 0.0395 - val_branch_softmax_2_mean_ev_succ: 0.5167 - val_branch_softmax_2_mean_ev_fail: 0.0305\n",
      "\n",
      "Epoch 00007: saving model to models\\resNet_evidence_conv2d.hdf5\n",
      "Epoch 8/30\n",
      "1406/1406 [==============================] - 673s 468ms/step - loss: 3.4230 - classification_loss: 2.1650 - branch_softmax_loss: 0.6330 - branch_softmax_1_loss: 0.4814 - branch_softmax_2_loss: 0.1437 - classification_accuracy: 0.9979 - branch_softmax_accuracy: 0.7798 - branch_softmax_1_accuracy: 0.8307 - branch_softmax_2_accuracy: 0.9523 - branch_softmax_evidence: 0.0119 - branch_softmax_mean_ev_succ: 0.1439 - branch_softmax_mean_ev_fail: 0.0313 - branch_softmax_1_evidence: 0.0166 - branch_softmax_1_mean_ev_succ: 0.1967 - branch_softmax_1_mean_ev_fail: 0.0236 - branch_softmax_2_evidence: 0.0505 - branch_softmax_2_mean_ev_succ: 0.5324 - branch_softmax_2_mean_ev_fail: 0.0197 - val_loss: 4.7004 - val_classification_loss: 2.1863 - val_branch_softmax_loss: 0.9034 - val_branch_softmax_1_loss: 0.9205 - val_branch_softmax_2_loss: 0.6902 - val_classification_accuracy: 0.9822 - val_branch_softmax_accuracy: 0.6963 - val_branch_softmax_1_accuracy: 0.7023 - val_branch_softmax_2_accuracy: 0.8029 - val_branch_softmax_evidence: 0.0201 - val_branch_softmax_mean_ev_succ: 0.2496 - val_branch_softmax_mean_ev_fail: 0.0880 - val_branch_softmax_1_evidence: 0.0047 - val_branch_softmax_1_mean_ev_succ: 0.0612 - val_branch_softmax_1_mean_ev_fail: 0.0106 - val_branch_softmax_2_evidence: 0.0471 - val_branch_softmax_2_mean_ev_succ: 0.5717 - val_branch_softmax_2_mean_ev_fail: 0.0724\n",
      "\n",
      "Epoch 00008: saving model to models\\resNet_evidence_conv2d.hdf5\n",
      "Epoch 9/30\n",
      "1406/1406 [==============================] - 674s 469ms/step - loss: 3.3500 - classification_loss: 2.1648 - branch_softmax_loss: 0.6172 - branch_softmax_1_loss: 0.4480 - branch_softmax_2_loss: 0.1200 - classification_accuracy: 0.9977 - branch_softmax_accuracy: 0.7880 - branch_softmax_1_accuracy: 0.8427 - branch_softmax_2_accuracy: 0.9603 - branch_softmax_evidence: 0.0117 - branch_softmax_mean_ev_succ: 0.1418 - branch_softmax_mean_ev_fail: 0.0282 - branch_softmax_1_evidence: 0.0161 - branch_softmax_1_mean_ev_succ: 0.1885 - branch_softmax_1_mean_ev_fail: 0.0219 - branch_softmax_2_evidence: 0.0549 - branch_softmax_2_mean_ev_succ: 0.5737 - branch_softmax_2_mean_ev_fail: 0.0215 - val_loss: 4.4572 - val_classification_loss: 2.1775 - val_branch_softmax_loss: 0.8383 - val_branch_softmax_1_loss: 0.7610 - val_branch_softmax_2_loss: 0.6804 - val_classification_accuracy: 0.9874 - val_branch_softmax_accuracy: 0.7175 - val_branch_softmax_1_accuracy: 0.7406 - val_branch_softmax_2_accuracy: 0.8167 - val_branch_softmax_evidence: 0.0181 - val_branch_softmax_mean_ev_succ: 0.2325 - val_branch_softmax_mean_ev_fail: 0.0536 - val_branch_softmax_1_evidence: 0.0206 - val_branch_softmax_1_mean_ev_succ: 0.2631 - val_branch_softmax_1_mean_ev_fail: 0.0452 - val_branch_softmax_2_evidence: 0.0883 - val_branch_softmax_2_mean_ev_succ: 1.0606 - val_branch_softmax_2_mean_ev_fail: 0.0978\n",
      "\n",
      "Epoch 00009: saving model to models\\resNet_evidence_conv2d.hdf5\n",
      "Epoch 10/30\n",
      "1406/1406 [==============================] - 676s 471ms/step - loss: 3.2783 - classification_loss: 2.1643 - branch_softmax_loss: 0.5914 - branch_softmax_1_loss: 0.4179 - branch_softmax_2_loss: 0.1046 - classification_accuracy: 0.9981 - branch_softmax_accuracy: 0.7992 - branch_softmax_1_accuracy: 0.8544 - branch_softmax_2_accuracy: 0.9647 - branch_softmax_evidence: 0.0121 - branch_softmax_mean_ev_succ: 0.1458 - branch_softmax_mean_ev_fail: 0.0242 - branch_softmax_1_evidence: 0.0168 - branch_softmax_1_mean_ev_succ: 0.1949 - branch_softmax_1_mean_ev_fail: 0.0187 - branch_softmax_2_evidence: 0.0641 - branch_softmax_2_mean_ev_succ: 0.6665 - branch_softmax_2_mean_ev_fail: 0.0199 - val_loss: 5.4438 - val_classification_loss: 2.1846 - val_branch_softmax_loss: 1.6245 - val_branch_softmax_1_loss: 0.8702 - val_branch_softmax_2_loss: 0.7646 - val_classification_accuracy: 0.9820 - val_branch_softmax_accuracy: 0.5891 - val_branch_softmax_1_accuracy: 0.7362 - val_branch_softmax_2_accuracy: 0.8025 - val_branch_softmax_evidence: 0.0276 - val_branch_softmax_mean_ev_succ: 0.4127 - val_branch_softmax_mean_ev_fail: 0.0755 - val_branch_softmax_1_evidence: 0.0268 - val_branch_softmax_1_mean_ev_succ: 0.3461 - val_branch_softmax_1_mean_ev_fail: 0.0473 - val_branch_softmax_2_evidence: 0.0544 - val_branch_softmax_2_mean_ev_succ: 0.6722 - val_branch_softmax_2_mean_ev_fail: 0.0275\n",
      "\n",
      "Epoch 00010: saving model to models\\resNet_evidence_conv2d.hdf5\n",
      "Epoch 11/30\n",
      "1406/1406 [==============================] - 678s 472ms/step - loss: 3.2013 - classification_loss: 2.1639 - branch_softmax_loss: 0.5660 - branch_softmax_1_loss: 0.3885 - branch_softmax_2_loss: 0.0829 - classification_accuracy: 0.9985 - branch_softmax_accuracy: 0.8046 - branch_softmax_1_accuracy: 0.8666 - branch_softmax_2_accuracy: 0.9731 - branch_softmax_evidence: 0.0121 - branch_softmax_mean_ev_succ: 0.1448 - branch_softmax_mean_ev_fail: 0.0223 - branch_softmax_1_evidence: 0.0159 - branch_softmax_1_mean_ev_succ: 0.1821 - branch_softmax_1_mean_ev_fail: 0.0174 - branch_softmax_2_evidence: 0.0683 - branch_softmax_2_mean_ev_succ: 0.7032 - branch_softmax_2_mean_ev_fail: 0.0157 - val_loss: 4.8399 - val_classification_loss: 2.1777 - val_branch_softmax_loss: 0.9519 - val_branch_softmax_1_loss: 0.8936 - val_branch_softmax_2_loss: 0.8167 - val_classification_accuracy: 0.9872 - val_branch_softmax_accuracy: 0.6937 - val_branch_softmax_1_accuracy: 0.7220 - val_branch_softmax_2_accuracy: 0.7983 - val_branch_softmax_evidence: 0.0131 - val_branch_softmax_mean_ev_succ: 0.1728 - val_branch_softmax_mean_ev_fail: 0.0375 - val_branch_softmax_1_evidence: 0.0202 - val_branch_softmax_1_mean_ev_succ: 0.2712 - val_branch_softmax_1_mean_ev_fail: 0.0247 - val_branch_softmax_2_evidence: 0.0818 - val_branch_softmax_2_mean_ev_succ: 1.0049 - val_branch_softmax_2_mean_ev_fail: 0.0766\n",
      "\n",
      "Epoch 00011: saving model to models\\resNet_evidence_conv2d.hdf5\n",
      "Epoch 12/30\n",
      "1406/1406 [==============================] - 681s 474ms/step - loss: 3.1359 - classification_loss: 2.1642 - branch_softmax_loss: 0.5397 - branch_softmax_1_loss: 0.3638 - branch_softmax_2_loss: 0.0681 - classification_accuracy: 0.9983 - branch_softmax_accuracy: 0.8143 - branch_softmax_1_accuracy: 0.8706 - branch_softmax_2_accuracy: 0.9775 - branch_softmax_evidence: 0.0120 - branch_softmax_mean_ev_succ: 0.1432 - branch_softmax_mean_ev_fail: 0.0230 - branch_softmax_1_evidence: 0.0176 - branch_softmax_1_mean_ev_succ: 0.2006 - branch_softmax_1_mean_ev_fail: 0.0206 - branch_softmax_2_evidence: 0.0691 - branch_softmax_2_mean_ev_succ: 0.7091 - branch_softmax_2_mean_ev_fail: 0.0139 - val_loss: 4.7767 - val_classification_loss: 2.1836 - val_branch_softmax_loss: 0.9088 - val_branch_softmax_1_loss: 0.8232 - val_branch_softmax_2_loss: 0.8611 - val_classification_accuracy: 0.9816 - val_branch_softmax_accuracy: 0.7101 - val_branch_softmax_1_accuracy: 0.7462 - val_branch_softmax_2_accuracy: 0.7887 - val_branch_softmax_evidence: 0.0171 - val_branch_softmax_mean_ev_succ: 0.2180 - val_branch_softmax_mean_ev_fail: 0.0560 - val_branch_softmax_1_evidence: 0.0094 - val_branch_softmax_1_mean_ev_succ: 0.1227 - val_branch_softmax_1_mean_ev_fail: 0.0107 - val_branch_softmax_2_evidence: 0.0638 - val_branch_softmax_2_mean_ev_succ: 0.7936 - val_branch_softmax_2_mean_ev_fail: 0.0430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00012: saving model to models\\resNet_evidence_conv2d.hdf5\n",
      "Epoch 13/30\n",
      "1406/1406 [==============================] - 681s 473ms/step - loss: 3.0840 - classification_loss: 2.1631 - branch_softmax_loss: 0.5244 - branch_softmax_1_loss: 0.3421 - branch_softmax_2_loss: 0.0544 - classification_accuracy: 0.9992 - branch_softmax_accuracy: 0.8173 - branch_softmax_1_accuracy: 0.8815 - branch_softmax_2_accuracy: 0.9814 - branch_softmax_evidence: 0.0119 - branch_softmax_mean_ev_succ: 0.1405 - branch_softmax_mean_ev_fail: 0.0234 - branch_softmax_1_evidence: 0.0173 - branch_softmax_1_mean_ev_succ: 0.1964 - branch_softmax_1_mean_ev_fail: 0.0145 - branch_softmax_2_evidence: 0.0792 - branch_softmax_2_mean_ev_succ: 0.8089 - branch_softmax_2_mean_ev_fail: 0.0092 - val_loss: 4.7164 - val_classification_loss: 2.1785 - val_branch_softmax_loss: 0.9293 - val_branch_softmax_1_loss: 0.8073 - val_branch_softmax_2_loss: 0.8014 - val_classification_accuracy: 0.9864 - val_branch_softmax_accuracy: 0.6983 - val_branch_softmax_1_accuracy: 0.7484 - val_branch_softmax_2_accuracy: 0.8153 - val_branch_softmax_evidence: 0.0125 - val_branch_softmax_mean_ev_succ: 0.1667 - val_branch_softmax_mean_ev_fail: 0.0299 - val_branch_softmax_1_evidence: 0.0277 - val_branch_softmax_1_mean_ev_succ: 0.3486 - val_branch_softmax_1_mean_ev_fail: 0.0690 - val_branch_softmax_2_evidence: 0.0827 - val_branch_softmax_2_mean_ev_succ: 1.0051 - val_branch_softmax_2_mean_ev_fail: 0.0333\n",
      "\n",
      "Epoch 00013: saving model to models\\resNet_evidence_conv2d.hdf5\n",
      "Epoch 14/30\n",
      "1406/1406 [==============================] - 683s 475ms/step - loss: 3.0544 - classification_loss: 2.1631 - branch_softmax_loss: 0.5091 - branch_softmax_1_loss: 0.3264 - branch_softmax_2_loss: 0.0558 - classification_accuracy: 0.9991 - branch_softmax_accuracy: 0.8275 - branch_softmax_1_accuracy: 0.8852 - branch_softmax_2_accuracy: 0.9817 - branch_softmax_evidence: 0.0123 - branch_softmax_mean_ev_succ: 0.1457 - branch_softmax_mean_ev_fail: 0.0223 - branch_softmax_1_evidence: 0.0179 - branch_softmax_1_mean_ev_succ: 0.2012 - branch_softmax_1_mean_ev_fail: 0.0145 - branch_softmax_2_evidence: 0.0842 - branch_softmax_2_mean_ev_succ: 0.8580 - branch_softmax_2_mean_ev_fail: 0.0098 - val_loss: 4.8808 - val_classification_loss: 2.1839 - val_branch_softmax_loss: 0.9726 - val_branch_softmax_1_loss: 0.9993 - val_branch_softmax_2_loss: 0.7249 - val_classification_accuracy: 0.9806 - val_branch_softmax_accuracy: 0.6991 - val_branch_softmax_1_accuracy: 0.7165 - val_branch_softmax_2_accuracy: 0.8221 - val_branch_softmax_evidence: 0.0138 - val_branch_softmax_mean_ev_succ: 0.1841 - val_branch_softmax_mean_ev_fail: 0.0323 - val_branch_softmax_1_evidence: 0.0311 - val_branch_softmax_1_mean_ev_succ: 0.4233 - val_branch_softmax_1_mean_ev_fail: 0.0381 - val_branch_softmax_2_evidence: 0.0765 - val_branch_softmax_2_mean_ev_succ: 0.9232 - val_branch_softmax_2_mean_ev_fail: 0.0265\n",
      "\n",
      "Epoch 00014: saving model to models\\resNet_evidence_conv2d.hdf5\n",
      "Epoch 15/30\n",
      "1406/1406 [==============================] - 685s 476ms/step - loss: 2.9802 - classification_loss: 2.1628 - branch_softmax_loss: 0.4803 - branch_softmax_1_loss: 0.2905 - branch_softmax_2_loss: 0.0466 - classification_accuracy: 0.9992 - branch_softmax_accuracy: 0.8333 - branch_softmax_1_accuracy: 0.8974 - branch_softmax_2_accuracy: 0.9853 - branch_softmax_evidence: 0.0126 - branch_softmax_mean_ev_succ: 0.1480 - branch_softmax_mean_ev_fail: 0.0205 - branch_softmax_1_evidence: 0.0190 - branch_softmax_1_mean_ev_succ: 0.2119 - branch_softmax_1_mean_ev_fail: 0.0121 - branch_softmax_2_evidence: 0.0868 - branch_softmax_2_mean_ev_succ: 0.8830 - branch_softmax_2_mean_ev_fail: 0.0093 - val_loss: 4.7877 - val_classification_loss: 2.1801 - val_branch_softmax_loss: 0.8386 - val_branch_softmax_1_loss: 0.9213 - val_branch_softmax_2_loss: 0.8477 - val_classification_accuracy: 0.9846 - val_branch_softmax_accuracy: 0.7350 - val_branch_softmax_1_accuracy: 0.7364 - val_branch_softmax_2_accuracy: 0.7999 - val_branch_softmax_evidence: 0.0097 - val_branch_softmax_mean_ev_succ: 0.1235 - val_branch_softmax_mean_ev_fail: 0.0231 - val_branch_softmax_1_evidence: 0.0177 - val_branch_softmax_1_mean_ev_succ: 0.2264 - val_branch_softmax_1_mean_ev_fail: 0.0425 - val_branch_softmax_2_evidence: 0.0587 - val_branch_softmax_2_mean_ev_succ: 0.7261 - val_branch_softmax_2_mean_ev_fail: 0.0337\n",
      "\n",
      "Epoch 00015: saving model to models\\resNet_evidence_conv2d.hdf5\n",
      "Epoch 16/30\n",
      "1406/1406 [==============================] - 686s 477ms/step - loss: 2.9573 - classification_loss: 2.1633 - branch_softmax_loss: 0.4710 - branch_softmax_1_loss: 0.2781 - branch_softmax_2_loss: 0.0448 - classification_accuracy: 0.9986 - branch_softmax_accuracy: 0.8344 - branch_softmax_1_accuracy: 0.9014 - branch_softmax_2_accuracy: 0.9846 - branch_softmax_evidence: 0.0118 - branch_softmax_mean_ev_succ: 0.1393 - branch_softmax_mean_ev_fail: 0.0168 - branch_softmax_1_evidence: 0.0183 - branch_softmax_1_mean_ev_succ: 0.2033 - branch_softmax_1_mean_ev_fail: 0.0137 - branch_softmax_2_evidence: 0.0868 - branch_softmax_2_mean_ev_succ: 0.8813 - branch_softmax_2_mean_ev_fail: 0.0082 - val_loss: 4.6502 - val_classification_loss: 2.1828 - val_branch_softmax_loss: 0.8715 - val_branch_softmax_1_loss: 0.9435 - val_branch_softmax_2_loss: 0.6523 - val_classification_accuracy: 0.9830 - val_branch_softmax_accuracy: 0.7244 - val_branch_softmax_1_accuracy: 0.7394 - val_branch_softmax_2_accuracy: 0.8375 - val_branch_softmax_evidence: 0.0106 - val_branch_softmax_mean_ev_succ: 0.1405 - val_branch_softmax_mean_ev_fail: 0.0166 - val_branch_softmax_1_evidence: 0.0373 - val_branch_softmax_1_mean_ev_succ: 0.4876 - val_branch_softmax_1_mean_ev_fail: 0.0585 - val_branch_softmax_2_evidence: 0.0760 - val_branch_softmax_2_mean_ev_succ: 0.9027 - val_branch_softmax_2_mean_ev_fail: 0.0152\n",
      "\n",
      "Epoch 00016: saving model to models\\resNet_evidence_conv2d.hdf5\n",
      "Epoch 17/30\n",
      "1406/1406 [==============================] - 681s 473ms/step - loss: 2.9017 - classification_loss: 2.1629 - branch_softmax_loss: 0.4510 - branch_softmax_1_loss: 0.2555 - branch_softmax_2_loss: 0.0323 - classification_accuracy: 0.9991 - branch_softmax_accuracy: 0.8421 - branch_softmax_1_accuracy: 0.9088 - branch_softmax_2_accuracy: 0.9902 - branch_softmax_evidence: 0.0136 - branch_softmax_mean_ev_succ: 0.1589 - branch_softmax_mean_ev_fail: 0.0179 - branch_softmax_1_evidence: 0.0187 - branch_softmax_1_mean_ev_succ: 0.2058 - branch_softmax_1_mean_ev_fail: 0.0089 - branch_softmax_2_evidence: 0.0957 - branch_softmax_2_mean_ev_succ: 0.9681 - branch_softmax_2_mean_ev_fail: 0.0102 - val_loss: 5.5383 - val_classification_loss: 2.1909 - val_branch_softmax_loss: 1.3049 - val_branch_softmax_1_loss: 1.2004 - val_branch_softmax_2_loss: 0.8422 - val_classification_accuracy: 0.9748 - val_branch_softmax_accuracy: 0.6404 - val_branch_softmax_1_accuracy: 0.6929 - val_branch_softmax_2_accuracy: 0.8071 - val_branch_softmax_evidence: 0.0341 - val_branch_softmax_mean_ev_succ: 0.4688 - val_branch_softmax_mean_ev_fail: 0.1158 - val_branch_softmax_1_evidence: 0.0113 - val_branch_softmax_1_mean_ev_succ: 0.1526 - val_branch_softmax_1_mean_ev_fail: 0.0347 - val_branch_softmax_2_evidence: 0.1136 - val_branch_softmax_2_mean_ev_succ: 1.3988 - val_branch_softmax_2_mean_ev_fail: 0.0315\n",
      "\n",
      "Epoch 00017: saving model to models\\resNet_evidence_conv2d.hdf5\n",
      "Epoch 18/30\n",
      "1406/1406 [==============================] - 701s 487ms/step - loss: 2.8598 - classification_loss: 2.1626 - branch_softmax_loss: 0.4343 - branch_softmax_1_loss: 0.2337 - branch_softmax_2_loss: 0.0291 - classification_accuracy: 0.9994 - branch_softmax_accuracy: 0.8495 - branch_softmax_1_accuracy: 0.9173 - branch_softmax_2_accuracy: 0.9909 - branch_softmax_evidence: 0.0130 - branch_softmax_mean_ev_succ: 0.1509 - branch_softmax_mean_ev_fail: 0.0209 - branch_softmax_1_evidence: 0.0215 - branch_softmax_1_mean_ev_succ: 0.2359 - branch_softmax_1_mean_ev_fail: 0.0124 - branch_softmax_2_evidence: 0.0993 - branch_softmax_2_mean_ev_succ: 1.0018 - branch_softmax_2_mean_ev_fail: 0.0084 - val_loss: 5.3765 - val_classification_loss: 2.1853 - val_branch_softmax_loss: 1.0584 - val_branch_softmax_1_loss: 1.4018 - val_branch_softmax_2_loss: 0.7309 - val_classification_accuracy: 0.9810 - val_branch_softmax_accuracy: 0.6977 - val_branch_softmax_1_accuracy: 0.6721 - val_branch_softmax_2_accuracy: 0.8251 - val_branch_softmax_evidence: 0.0234 - val_branch_softmax_mean_ev_succ: 0.3159 - val_branch_softmax_mean_ev_fail: 0.0443 - val_branch_softmax_1_evidence: 0.0357 - val_branch_softmax_1_mean_ev_succ: 0.5117 - val_branch_softmax_1_mean_ev_fail: 0.0511 - val_branch_softmax_2_evidence: 0.0888 - val_branch_softmax_2_mean_ev_succ: 1.0753 - val_branch_softmax_2_mean_ev_fail: 0.0354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00018: saving model to models\\resNet_evidence_conv2d.hdf5\n",
      "Epoch 19/30\n",
      "1406/1406 [==============================] - 868s 599ms/step - loss: 2.8371 - classification_loss: 2.1625 - branch_softmax_loss: 0.4217 - branch_softmax_1_loss: 0.2260 - branch_softmax_2_loss: 0.0269 - classification_accuracy: 0.9994 - branch_softmax_accuracy: 0.8553 - branch_softmax_1_accuracy: 0.9175 - branch_softmax_2_accuracy: 0.9913 - branch_softmax_evidence: 0.0133 - branch_softmax_mean_ev_succ: 0.1537 - branch_softmax_mean_ev_fail: 0.0194 - branch_softmax_1_evidence: 0.0220 - branch_softmax_1_mean_ev_succ: 0.2395 - branch_softmax_1_mean_ev_fail: 0.0105 - branch_softmax_2_evidence: 0.1043 - branch_softmax_2_mean_ev_succ: 1.0518 - branch_softmax_2_mean_ev_fail: 0.0040 - val_loss: 5.5803 - val_classification_loss: 2.1878 - val_branch_softmax_loss: 1.5888 - val_branch_softmax_1_loss: 1.0655 - val_branch_softmax_2_loss: 0.7382 - val_classification_accuracy: 0.9782 - val_branch_softmax_accuracy: 0.6030 - val_branch_softmax_1_accuracy: 0.7183 - val_branch_softmax_2_accuracy: 0.8315 - val_branch_softmax_evidence: 0.0289 - val_branch_softmax_mean_ev_succ: 0.4327 - val_branch_softmax_mean_ev_fail: 0.0794 - val_branch_softmax_1_evidence: 0.0123 - val_branch_softmax_1_mean_ev_succ: 0.1687 - val_branch_softmax_1_mean_ev_fail: 0.0168 - val_branch_softmax_2_evidence: 0.0909 - val_branch_softmax_2_mean_ev_succ: 1.0878 - val_branch_softmax_2_mean_ev_fail: 0.0329\n",
      "\n",
      "Epoch 00019: saving model to models\\resNet_evidence_conv2d.hdf5\n",
      "Epoch 20/30\n",
      " 534/1406 [==========>...................] - ETA: 8:59 - loss: 2.7706 - classification_loss: 2.1623 - branch_softmax_loss: 0.3969 - branch_softmax_1_loss: 0.1869 - branch_softmax_2_loss: 0.0244 - classification_accuracy: 0.9995 - branch_softmax_accuracy: 0.8631 - branch_softmax_1_accuracy: 0.9350 - branch_softmax_2_accuracy: 0.9919 - branch_softmax_evidence: 0.0133 - branch_softmax_mean_ev_succ: 0.1534 - branch_softmax_mean_ev_fail: 0.0123 - branch_softmax_1_evidence: 0.0227 - branch_softmax_1_mean_ev_succ: 0.2436 - branch_softmax_1_mean_ev_fail: 0.0076 - branch_softmax_2_evidence: 0.0967 - branch_softmax_2_mean_ev_succ: 0.9735 - branch_softmax_2_mean_ev_fail: 0.0025"
     ]
    }
   ],
   "source": [
    "model = brevis.trainTransfer(30, loss=loss_fn, optimizer=tf.optimizers.SGD(), transfer=False, customOptions=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = tf.keras.models.load_model('models/resNet_evidence_conv2d.hdf5', custom_objects={\"CrossEntropyEndpoint\":CrossEntropyEndpoint,\"cross_entropy_evidence\":loss_function()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acc\n",
       "0  0.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    True\n",
       "Name: acc, dtype: bool"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectEvidence_branches(model,test_ds, evidence=True):\n",
    "    num_outputs = len(model.outputs) # the number of output layers for the purpose of providing labels\n",
    "    print(\"outputs\",num_outputs)\n",
    "#     train_ds, test_ds, validation_ds = (dataset)\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    pClass = []\n",
    "    predictions=[]\n",
    "    pEvidence = []\n",
    "    pUncertainty=[]\n",
    "    pOverlap=[]\n",
    "\n",
    "    Outputs = pd.DataFrame()\n",
    "    pAcc=[]\n",
    "    for i in range(num_outputs):\n",
    "        pClass.append([])\n",
    "        predictions.append([])\n",
    "        pEvidence.append([])\n",
    "        pUncertainty.append([])\n",
    "        pAcc.append([])\n",
    "        pOverlap.append([])\n",
    "        # pOutputs.append([])\n",
    "\n",
    "    for i, (x,y) in enumerate(test_ds):\n",
    "        # if i > 10:\n",
    "            # break\n",
    "        print(\"prediction: {} of {}\".format(i,len(test_ds)),end='\\r')\n",
    "        if evidence: \n",
    "            result = model.test_on_batch(x,y)\n",
    "#             print(result)\n",
    "            for j in range(num_outputs):\n",
    "#                 print(\"output\",j)\n",
    "                pClass[j].append(tf.argmax(y[0]).numpy())\n",
    "#                 print(\"class\",pClass[j][i])\n",
    "                pAcc[j].append(result[j+(num_outputs+1)])  \n",
    "#                 print(\"acc\",pAcc[j][i])\n",
    "                if j ==0:\n",
    "                    pEvidence[j].append(0)\n",
    "                else:\n",
    "#                     print(\"evid Number\",((num_outputs * 2)+1), \" \", ((j-1)*3))\n",
    "                    pEvidence[j].append(result[((num_outputs * 2) + 1)+((j-1)*3)])\n",
    "#                 print(\"evid\",pEvidence[j][i])\n",
    "\n",
    "                pOverlap[j].append(pAcc[0][i] - pAcc[j][i])\n",
    "#                 print(\"overlap\",pOverlap[j][i])\n",
    "        else:\n",
    "            result = model.predict(x)[0]\n",
    "            # print(result)\n",
    "\n",
    "            for j in range(num_outputs):\n",
    "                pClass[j].append(tf.argmax(y[0]).numpy())\n",
    "                # print(pClass[j])\n",
    "                # print(result)\n",
    "                prediction = np.argmax(result[j])\n",
    "                if prediction == pClass[j][i]:\n",
    "                    pAcc[j].append(1)  \n",
    "                else:\n",
    "                    pAcc[j].append(0)  \n",
    "                # print(branching.utils.calcEntropy_Tensors(result[j]).numpy())\n",
    "                pEvidence[j].append(branching.utils.calcEntropy_Tensors(result[j]).numpy()[0])\n",
    "\n",
    "                pOverlap[j].append(pAcc[0][i] - pAcc[j][i])\n",
    "        '''\n",
    "        overlap\n",
    "        if zero, both match, if else they don't match\n",
    "        TT 1-1 =0\n",
    "        TF 1-0 =1\n",
    "\n",
    "        FT 0-1 = -1\n",
    "        FF 0-0 =0\n",
    "        \n",
    "        '''\n",
    "    Outputs=[]\n",
    "    for j in range(num_outputs):\n",
    "        Predictions = pd.DataFrame({\"label\":pClass[j],\"evidence\":pEvidence[j],\"Acc\":pAcc[j], \"overlap\":pOverlap[j]})\n",
    "        Outputs.append(Predictions)\n",
    "    return Outputs\n",
    "\n",
    "def displayEvidence(branch_predictions, output_names=[\"main_exit\",\"branch_1\",\"branch_2\",\"branch_3\"], Evidence = True):\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "    fig = plt.figure()\n",
    "    series=[]\n",
    "    fig, axs = plt.subplots(2, 2)\n",
    "    fig.tight_layout()\n",
    "    Outputs=pd.DataFrame()\n",
    "    for i, Predictions in enumerate(branch_predictions):\n",
    "        Predictions[\"Acc\"]=Predictions[\"Acc\"].astype('bool') ##sometime the predictions can come back with 0.5 acc, this should be rounded to 1.\n",
    "        # Predictions[\"evidence\"]=Predictions[\"evidence\"].()[0]\n",
    "        acc = Predictions[\"Acc\"].value_counts()\n",
    "        # print(acc)\n",
    "        # print((acc.loc[True] , acc.loc[False]))\n",
    "        mean = Predictions.loc[(Predictions['Acc'] == False)].groupby(\"Acc\")[\"evidence\"].mean().iloc[0]\n",
    "        std = Predictions.loc[(Predictions['Acc'] == False)].groupby(\"Acc\")[\"evidence\"].std().iloc[0]\n",
    "        \n",
    "        correct_rows = Predictions.loc[Predictions['Acc'] == True]\n",
    "        incorrect_rows = Predictions.loc[Predictions['Acc'] == False]\n",
    "        if Evidence:\n",
    "            E_threshold = mean + std\n",
    "            Incorrects_overlap = Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"evidence\"] > E_threshold) & (Predictions[\"overlap\"] == 0)].count().iloc[0]\n",
    "            Outputs = Outputs.append(pd.DataFrame({\"Branch Name\":output_names[i],\n",
    "                    \"Accuracy\":(acc.loc[True] /  (acc.loc[True] + acc.loc[False])),\n",
    "                    \"E_Threshold\":E_threshold,\n",
    "                    # \"Overlap_Threshold\":non_overlapping_incorrects_threshold,\n",
    "                    \"acceptance_rate\":Predictions.loc[(Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0]/(Predictions.count().iloc[0]),\n",
    "                    \"accepted_correct\":Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                    \"accepted_incorrect\":Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                    \"accepted_accuracy\":(Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0])/ Predictions.loc[(Predictions[\"evidence\"] > E_threshold)].count()[0],\n",
    "                    \"overlap_adjusted_accuracy\":(Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0] + Incorrects_overlap) / Predictions.loc[(Predictions[\"evidence\"] > E_threshold)].count()[0],\n",
    "                    \"rejected_correct\":Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                    \"rejected_incorrect\":Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                    \"Incorrects_overlap\":Incorrects_overlap,\n",
    "                    },index=[i]))\n",
    "        else:\n",
    "            print(\"mean\",mean , \" std\",std)\n",
    "            E_threshold = mean - std\n",
    "            Incorrects_overlap = Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"evidence\"] < E_threshold) & (Predictions[\"overlap\"] == 0)].count().iloc[0]\n",
    "            # if i ==1 or i == 0 :\n",
    "                # print(Predictions)\n",
    "                # print(Predictions.loc[ (Predictions['Acc'] == True)  & (Predictions[\"overlap\"] == 0) ])\n",
    "            # print(Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] < E_threshold) ].count())\n",
    "            Outputs = Outputs.append(pd.DataFrame({\"Branch Name\":output_names[i],\n",
    "                    \"Accuracy\":(acc.loc[True] /  (acc.loc[True] + acc.loc[False])),\n",
    "                    \"E_Threshold\":E_threshold,\n",
    "                    # \"Overlap_Threshold\":non_overlapping_incorrects_threshold,\n",
    "                    \"acceptance_rate\":Predictions.loc[(Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0]/(Predictions.count().iloc[0]),\n",
    "                    \"accepted_correct\":Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                    \"accepted_incorrect\":Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                    \"accepted_accuracy\":(Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0])/ Predictions.loc[(Predictions[\"evidence\"] < E_threshold)].count()[0],\n",
    "                    \"overlap_adjusted_accuracy\":(Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0] + Incorrects_overlap) / Predictions.loc[(Predictions[\"evidence\"] < E_threshold)].count()[0],\n",
    "                    \"rejected_correct\":Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                    \"rejected_incorrect\":Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                    \"Incorrects_overlap\":Incorrects_overlap,\n",
    "                    },index=[i]))\n",
    "        axs[round(int(i/2)), round(i%2)]\n",
    "    # fig, axs = plt.subplots(1, 2)\n",
    "        # axs[round(int(i/2)), round(i%2)].suptitle('Horizontally stacked subplots')\n",
    "        axs[round(int(i/2)), round(i%2)].scatter(correct_rows['label'],correct_rows['evidence'],c ='r',marker='+')\n",
    "        axs[round(int(i/2)), round(i%2)].scatter(incorrect_rows['label']+.3,incorrect_rows['evidence'],c ='k',marker='x')\n",
    "        axs[round(int(i/2)), round(i%2)].plot(np.repeat(E_threshold,11),'b--')\n",
    "        axs[round(int(i/2)), round(i%2)].title.set_text(\"evidence\")\n",
    "    \n",
    "    for ax in fig.axes:\n",
    "            # ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "            axLine, axLabel = ax.get_legend_handles_labels()\n",
    "            lines=(axLine)\n",
    "            labels=(axLabel)\n",
    "    fig.text(0.5, 0.01, 'Items Exit at Branch', ha='center', va='center')\n",
    "    fig.text(0.01, 0.5, 'Accuracy %', ha='center', va='center', rotation='vertical')\n",
    "    # fig.legend(lines, labels,bbox_to_anchor=(1., 1), loc=2,borderaxespad=0.,frameon=True)\n",
    "    # fig.set_size_inches(10, 10)\n",
    "    plt.show()\n",
    "    return Outputs\n",
    "\n",
    "\n",
    "def evidenceHistogram(branch_predictions, output_names=[\"main_exit\",\"branch_1\",\"branch_2\",\"branch_3\"], Evidence = True):\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "    fig = plt.figure()\n",
    "    series=[]\n",
    "    fig, axs = plt.subplots(2, 2)\n",
    "    fig.tight_layout()\n",
    "    Outputs=pd.DataFrame()\n",
    "    for i, Predictions in enumerate(branch_predictions):\n",
    "        Predictions[\"Acc\"]=Predictions[\"Acc\"].astype('bool')\n",
    "        # Predictions[\"evidence\"]=Predictions[\"evidence\"].()[0]\n",
    "        acc = Predictions[\"Acc\"].value_counts()\n",
    "        # print(acc)\n",
    "        # print((acc.loc[True] , acc.loc[False]))\n",
    "        mean = Predictions.loc[(Predictions['Acc'] == False)].groupby(\"Acc\")[\"evidence\"].mean().iloc[0]\n",
    "        std = Predictions.loc[(Predictions['Acc'] == False)].groupby(\"Acc\")[\"evidence\"].std().iloc[0]\n",
    "        \n",
    "        correct_rows = Predictions.loc[Predictions['Acc'] == True]\n",
    "        incorrect_rows = Predictions.loc[Predictions['Acc'] == False]\n",
    "        if Evidence:\n",
    "            # E_threshold = mean + std + einsumfunc\n",
    "\n",
    "            Accepted = Predictions.loc[(Predictions[\"evidence\"] <= E_threshold)]\n",
    "            Rejected = Predictions.loc[(Predictions[\"evidence\"] > E_threshold)]\n",
    "            Incorrects_overlap = Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"evidence\"] > E_threshold) & (Predictions[\"overlap\"] == 0)].count().iloc[0]\n",
    "            Outputs = Outputs.append(pd.DataFrame({\"Branch Name\":output_names[i],\n",
    "                    \"Accuracy\":(acc.loc[True] /  (acc.loc[True] + acc.loc[False])),\n",
    "                    \"E_Threshold\":E_threshold,\n",
    "                    # \"Overlap_Threshold\":non_overlapping_incorrects_threshold,\n",
    "                    \"acceptance_rate\":Predictions.loc[(Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0]/(Predictions.count().iloc[0]),\n",
    "                    \"accepted_correct\":Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                    \"accepted_incorrect\":Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                    \"accepted_accuracy\":(Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0])/ Predictions.loc[(Predictions[\"evidence\"] > E_threshold)].count()[0],\n",
    "                    \"overlap_adjusted_accuracy\":(Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0] + Incorrects_overlap) / Predictions.loc[(Predictions[\"evidence\"] > E_threshold)].count()[0],\n",
    "                    \"T_F\":Accepted.loc[Accepted['overlap']==1],\n",
    "                    \"F_T\":Accepted.loc[Accepted['overlap']==-1],\n",
    "                    \"Incorrects_overlap\":Incorrects_overlap,\n",
    "                    },index=[i]))\n",
    "        else:\n",
    "            print(\"mean\",mean , \" std\",std)\n",
    "            E_threshold = mean - std\n",
    "            Incorrects_overlap = Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"evidence\"] < E_threshold) & (Predictions[\"overlap\"] == 0)].count().iloc[0]\n",
    "            # if i ==1 or i == 0 :\n",
    "                # print(Predictions)\n",
    "                # print(Predictions.loc[ (Predictions['Acc'] == True)  & (Predictions[\"overlap\"] == 0) ])\n",
    "            # print(Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] < E_threshold) ].count())\n",
    "           \n",
    "            Outputs = Outputs.append(pd.DataFrame({\"Branch Name\":output_names[i],\n",
    "                    \"Accuracy\":(acc.loc[True] /  (acc.loc[True] + acc.loc[False])),\n",
    "                    \"E_Threshold\":E_threshold,\n",
    "                    # \"Overlap_Threshold\":non_overlapping_incorrects_threshold,\n",
    "                    \"acceptance_rate\":Predictions.loc[(Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0]/(Predictions.count().iloc[0]),\n",
    "                    \"accepted_correct\":Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                    \"accepted_incorrect\":Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                    \"accepted_accuracy\":(Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0])/ Predictions.loc[(Predictions[\"evidence\"] < E_threshold)].count()[0],\n",
    "                    \"overlap_adjusted_accuracy\":(Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0] + Incorrects_overlap) / Predictions.loc[(Predictions[\"evidence\"] < E_threshold)].count()[0],\n",
    "                    \"rejected_correct\":Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                    \"rejected_incorrect\":Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                    \"Incorrects_overlap\":Incorrects_overlap,\n",
    "                    },index=[i]))\n",
    "        axs[round(int(i/2)), round(i%2)]\n",
    "    # fig, axs = plt.subplots(1, 2)\n",
    "        # axs[round(int(i/2)), round(i%2)].suptitle('Horizontally stacked subplots')\n",
    "        axs[round(int(i/2)), round(i%2)].scatter(correct_rows['label'],correct_rows['evidence'],c ='r',marker='+')\n",
    "        axs[round(int(i/2)), round(i%2)].scatter(incorrect_rows['label']+.3,incorrect_rows['evidence'],c ='k',marker='x')\n",
    "        axs[round(int(i/2)), round(i%2)].plot(np.repeat(E_threshold,11),'b--')\n",
    "        axs[round(int(i/2)), round(i%2)].title.set_text(\"evidence\")\n",
    "    \n",
    "    for ax in fig.axes:\n",
    "            # ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "            axLine, axLabel = ax.get_legend_handles_labels()\n",
    "            lines=(axLine)\n",
    "            labels=(axLabel)\n",
    "    fig.text(0.5, 0.01, 'Items Exit at Branch', ha='center', va='center')\n",
    "    fig.text(0.01, 0.5, 'Accuracy %', ha='center', va='center', rotation='vertical')\n",
    "    # fig.legend(lines, labels,bbox_to_anchor=(1., 1), loc=2,borderaxespad=0.,frameon=True)\n",
    "    # fig.set_size_inches(10, 10)\n",
    "    plt.show()\n",
    "    return Outputs\n",
    "\n",
    "def displayEvidence_cascade(branch_predictions, thresholds=None, output_names=[\"branch_1\",\"branch_2\",\"branch_3\",\"Main_Exit\"], Evidence = True):\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "    fig = plt.figure()\n",
    "    series=[]\n",
    "    fig, axs = plt.subplots(2, 2)\n",
    "    fig.tight_layout()\n",
    "    Outputs=pd.DataFrame()\n",
    "    #lets reorder the predictions so that the final layer is at the end\n",
    "    # _branch_predictions.copy()\n",
    "    _branch_predictions = branch_predictions.copy()\n",
    "    # print(_branch_predictions)\n",
    "    _branch_predictions.append(_branch_predictions.pop(0))\n",
    "    # print(_branch_predictions)\n",
    "    rollOver_indices = pd.Index([])\n",
    "    for i, Predictions in enumerate(_branch_predictions):\n",
    "        #check if rollover is active, if so, select only the predictions whose indexes match the rollover list\n",
    "        # print(rollOver_indices)\n",
    "        test_acc = Predictions[\"Acc\"].astype('bool').value_counts()\n",
    "        test_accuracy = (test_acc.loc[True] /  (test_acc.loc[True] + test_acc.loc[False]))\n",
    "        if len(rollOver_indices)>0:\n",
    "            print(\"rollover enabled, {} predictions provided\".format(len(rollOver_indices)))\n",
    "            Predictions = Predictions.iloc[rollOver_indices]\n",
    "        # print(Predictions.shape)\n",
    "        Predictions[\"Acc\"]=Predictions[\"Acc\"].astype('bool')\n",
    "        # Predictions[\"evidence\"]=Predictions[\"evidence\"].()[0]\n",
    "        acc = Predictions[\"Acc\"].value_counts()\n",
    "        # print(acc)\n",
    "        # print((acc.loc[True] , acc.loc[False]))\n",
    "        _Incorrects_missed = Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"overlap\"] == 1)] #all the predictions that the main exit got true and the branch got wrong\n",
    "        if len(_Incorrects_missed) > 0 :\n",
    "            mean = _Incorrects_missed.groupby(\"Acc\")[\"evidence\"].mean().iloc[0]\n",
    "            std = _Incorrects_missed.groupby(\"Acc\")[\"evidence\"].std().iloc[0]\n",
    "        else:\n",
    "            mean = Predictions.loc[(Predictions['Acc'] == False)].groupby(\"Acc\")[\"evidence\"].mean().iloc[0]\n",
    "            std = Predictions.loc[(Predictions['Acc'] == False)].groupby(\"Acc\")[\"evidence\"].std().iloc[0]\n",
    "\n",
    "        print(\"mean\",mean , \" std\",std)\n",
    "        \n",
    "        correct_rows = Predictions.loc[Predictions['Acc'] == True]\n",
    "        incorrect_rows = Predictions.loc[Predictions['Acc'] == False]\n",
    "        \n",
    "        E_threshold = -1 #-1 is null for threshold\n",
    "        if thresholds is not None:\n",
    "            try:\n",
    "                E_threshold = thresholds[i]\n",
    "            except:\n",
    "                print(\"threshold not supplied for branch {}, using test data\".format(i))\n",
    "                \n",
    "        if Evidence:\n",
    "            if E_threshold ==-1:\n",
    "                E_threshold = mean + std\n",
    "            Accepted = Predictions.loc[(Predictions[\"evidence\"] >= E_threshold)]\n",
    "            Rejected = Predictions.loc[(Predictions[\"evidence\"] < E_threshold)]\n",
    "        else: \n",
    "            if E_threshold ==-1:\n",
    "                E_threshold = mean - std\n",
    "            Accepted = Predictions.loc[(Predictions[\"evidence\"] <= E_threshold)]\n",
    "            Rejected = Predictions.loc[(Predictions[\"evidence\"] > E_threshold)]\n",
    "        \n",
    "        rollOver_indices = Rejected.index\n",
    "        Incorrects_overlap = Accepted.loc[(Accepted['Acc'] == False) & (Accepted[\"overlap\"] == 0)].count().iloc[0]\n",
    "        Outputs = Outputs.append(pd.DataFrame({\"Branch Name\":output_names[i],\n",
    "                \"Predictions\": len(Predictions.index),\n",
    "                \"test_accuracy\": test_accuracy,\n",
    "                \"Accuracy\":(acc.loc[True] /  (acc.loc[True] + acc.loc[False])),\n",
    "                \"E_Threshold\":E_threshold,\n",
    "                # \"Overlap_Threshold\":non_overlapping_incorrects_threshold,\n",
    "                \"acceptance_rate\":Accepted.shape[0]/(Predictions.shape[0]),\n",
    "                \"accepted_correct\":Accepted.loc[(Predictions['Acc'] == True)].shape[0],\n",
    "                \"accepted_incorrect\":Accepted.loc[(Predictions['Acc'] == False)].shape[0],\n",
    "                \"accepted_accuracy\":(Accepted.loc[(Accepted['Acc'] == True)].shape[0])/ Accepted.shape[0],\n",
    "                \"overlap_adjusted_accuracy\":(Accepted.loc[(Accepted['Acc'] == True)].count()[0] + Incorrects_overlap) / Predictions.loc[(Predictions[\"evidence\"] >E_threshold)].count()[0],\n",
    "                \"M(T) B(F)\":Accepted.loc[(Accepted[\"overlap\"] == 1)].count().iloc[0],\n",
    "                \"M(F) B(T)\":Accepted.loc[(Accepted[\"overlap\"] ==-1)].count().iloc[0],\n",
    "                \"M(F) B(F) overlap\":Incorrects_overlap,\n",
    "                },index=[i]))\n",
    "#         print(\"TT\",Accepted.loc[(Accepted[\"Acc\"] ==True) & (Accepted[\"overlap\"] == 0)])\n",
    "#         print(\"TF\",Accepted.loc[(Accepted[\"overlap\"] == 1)])\n",
    "#         print(\"FT\",Accepted.loc[(Accepted[\"overlap\"] == -1)])\n",
    "#         print(\"FF\",Accepted.loc[(Accepted[\"Acc\"] ==False) & (Accepted[\"overlap\"] == 0)])\n",
    "        axs[round(int(i/2)), round(i%2)]\n",
    "    # fig, axs = plt.subplots(1, 2)\n",
    "        # axs[round(int(i/2)), round(i%2)].suptitle('Horizontally stacked subplots')\n",
    "        axs[round(int(i/2)), round(i%2)].scatter(correct_rows['label'],correct_rows['evidence'],c ='r',marker='+')\n",
    "        axs[round(int(i/2)), round(i%2)].scatter(incorrect_rows['label']+.3,incorrect_rows['evidence'],c ='k',marker='x')\n",
    "        axs[round(int(i/2)), round(i%2)].plot(np.repeat(E_threshold,11),'b--')\n",
    "        axs[round(int(i/2)), round(i%2)].title.set_text(output_names[i])\n",
    "    \n",
    "    for ax in fig.axes:\n",
    "            # ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "            axLine, axLabel = ax.get_legend_handles_labels()\n",
    "            lines=(axLine)\n",
    "            labels=(axLabel)\n",
    "    fig.text(0.5, 0.01, 'Items Exit at Branch', ha='center', va='center')\n",
    "    fig.text(0.01, 0.5, 'Accuracy %', ha='center', va='center', rotation='vertical')\n",
    "    # fig.legend(lines, labels,bbox_to_anchor=(1., 1), loc=2,borderaxespad=0.,frameon=True)\n",
    "    # fig.set_size_inches(10, 10)\n",
    "    plt.show()\n",
    "    return Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs 2\n",
      "prediction: 9999 of 10000\r"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# print(y_train)\n",
    "K= 10 # number of classes\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels,10)\n",
    "shuffle_size = 22500\n",
    "batch_size=1\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "\n",
    "def augment_images(image, label,input_size=(224,224), channel_first = False):\n",
    "            image = tf.image.resize(image,input_size)\n",
    "            if channel_first:\n",
    "                image = tf.transpose(image, [2, 0, 1])\n",
    "            return image, label\n",
    "test_ds_size = len(list(test_ds))\n",
    "test_ds = (test_ds.map(augment_images))\n",
    "t_target = tf.data.Dataset.from_tensor_slices((test_labels))\n",
    "test_ds = tf.data.Dataset.zip((test_ds,t_target))\n",
    "test_ds = (test_ds.batch(batch_size=1, drop_remainder=True))\n",
    "# Predictions = collectEvidence_branches(model,test_ds)\n",
    "Outputs = collectEvidence_branches(model,test_ds, True)\n",
    "# print(Outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 0.002511918346159191  std 0.01912148500026213\n",
      "rollover enabled, 8737 predictions provided\n",
      "mean 0  std 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:257: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:305: RuntimeWarning: divide by zero encountered in longlong_scalars\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbMAAAEvCAYAAADPSS+/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XtYVNX6B/DvACIIhimVpgd/yonE1BCqU5qimelJ854gipaWpuW91DyJhIRoaqmpx0taoR4hK4+XczyFqaSV5Sh4GyXRMNMUUcDhzsz6/THMNDPMhdseZsP38zw8sPeatdfLhjXvrL3X3lshhBAgIiKSMZe6DoCIiKimmMyIiEj2mMyIiEj2mMyIiEj2mMyIiEj2mMyIiEj2mMyIiEj2mMyc1LFjxzBw4ECHtvnll19i0qRJ1a6/cuVKxMTE1GJERDUjp3703XffYdiwYRg8eDCGDh2KI0eOSBBd/eVW1wGQ/P3xxx+Ii4tDSkoKhg0bVtfhEMnO3bt38eabb2Lr1q146KGHcP78eYwZMwaHDh2Ct7d3XYcnC0xmTqygoADTpk1DZmYm7rnnHsTExGD9+vXIycnBb7/9hl69emHEiBGIiYlBfn4+srKy0KFDB3z44Ydo3LgxOnfujIkTJ+Lo0aO4efMmXnnlFURERAAA1q9fj6+++gpubm5o27Yt4uPjAQBZWVmYOHEirl+/DldXVyxfvhz+/v4249y5cyeeeOIJ+Pv7Izc3V/L9QlQVcuhHpaWlWLhwIR566CEAwF//+lcIIXDnzh0ms8oS5JR+/PFH0aFDB6FUKoUQQuzYsUOMGDFCzJ07V4wbN87wuvj4eLFr1y4hhBAlJSVi4MCBYv/+/UIIIQICAkRCQoIQQojTp0+LTp06iaKiIpGcnCyee+45kZOTI4QQIi4uTqxdu1Z88cUX4rHHHhO//vqrEEKIRYsWibfffrvSMa9atUq8++67Nf7diWqLHPuREEIsX75cDBs2rEa/e0PDc2ZO7OGHH0ZwcDAAYOjQoThz5gzu3r2LkJAQw2veeustNG/eHBs3bkR0dDRu3ryJgoICQ3mfPn0AAI888ghKSkpQUFCAH374Af3794ePjw8A4O2338bkyZMBAF26dEHbtm0BAIGBgbh9+7ZDflciqcipH5WVlSE2Nhb79+/H6tWra/7LNyA8zOjEXFxMP2soFAq4ubmhSZMmhnWzZs2CRqPB3//+d/Tq1QvXr1+HMLp3dOPGjQ11AUAIAVdXV8MyAOTl5SEvLw8A4Ob257+EQqEw2RaRHMmlH+Xm5mLatGkQQiAxMRH33ntvNX7bhosjMyd24cIFqFQqAEBiYiJCQkLg6elp8pojR47g9ddfx/PPPw8ASEtLg0ajsbndbt264ZtvvoFarQYArF69Gp988knt/wJETkAO/Uij0WDixIlo06YNNm/ezERWDRyZObH27dvjo48+wm+//YYWLVogPj6+wqGHmTNn4vXXX0eTJk3g7e2Nxx9/HFeuXLG53dDQUFy8eBGjRo0CoDvZvGjRInz99deS/S5EdUUO/ei///0vUlNTUVBQgOHDhxvWL126FA8//HCVt9cQKQSPIxERkcxxZEZ2xcXF4dixYxbL3n77bTz55JMOjohIftiPpMWRGRERyR4ngBARkezJ4jCjUqms6xCIKsX42iVnxL5EclHVviSLZAbY/sVUKhUCAwMdGE3lOWtszhoX4Lyx2YtLLolCjn3JWeMCnDc2Z40LkKYv8TAjERHJHpMZERHJXsNOZr166b6IiEjWGnYyIyKiesFhE0DS0tKwbNkyJCQkmKzfsmULdu7ciebNmwMA3n33XbRv317aYPSjscOHTZcPHZK2XSIikoRDktnGjRuxe/fuCjf3BICzZ89iyZIl6NSpkyNCISKiesghyczPzw+rV6/GnDlzKpSdPXsWGzZsQFZWFnr16oVJkyZJH5B+BMYRGRFRveCQZNavXz9cvXrVYtmAAQMQEREBb29vvPHGGzh48CB69+5d4XX6RzhYUlRUZLPcGr/yh+9dqUbdyqpubFJz1rgA543NWeMiojq+aFoIgXHjxqFp06YAdI9UOHfunMVkZusCu2pfHPjTT7ptV71mpTnrhYvOGhfgvLHVl4umieqjOp3NqFarMXDgQOTn50MIgWPHjvHcGRERVVmdjMz27NmDgoIChIWFYebMmRg7dizc3d3x1FNPITQ0tC5CooaA50iJ6i2HJbM2bdogKSkJAPDCCy8Y1g8ZMgRDhgxxVBim+OZGRFQvyOZGw0TVxusKieq9hpnM+OZGRFSvNMxkRg2LzK4r1Gq1iI6OxoULF+Du7o7Y2Fi0bdvWUJ6UlIQdO3bAzc0NkydPRu/evXHt2jXMnz8fGo0GQgjExMRIfycdIifSMJOZzN7cqGFJTk5GSUkJEhMTkZqaivj4eKxbtw4AkJWVhYSEBHzxxRcoLi5GREQEunfvjpUrV2LMmDF49tln8d1332HFihX46KOP6vg3IXKchpnMqGGSyYcWpVKJHj16AACCgoJw5swZQ9mpU6fQtWtXuLu7w93dHX5+fjh//jzmzp1ruF5To9GgcePGdRI7UV1p2MlMJm9u1LCo1Wp4e3sbll1dXVFWVgY3Nzeo1WpD0gIALy8vqNVqw426L126hCVLlmDNmjVWty/F3XSk5qxxAc4bm7PGBUgTW8NOZkROyNvbG/n5+YZlrVYLNzc3i2X5+fmG5Pbjjz/i3XffxdKlS22eL5PkbjoSc9a4AOeNzVnjAqS5mw6fZ0bkZIKDg5GSkgIASE1NRUBAgKGsS5cuUCqVKC4uxt27d5GRkYGAgAD8+OOPeO+997Bp0yZ07ty5rkInqjMcmRE5mb59++Lo0aMIDw+HEAJxcXHYsmUL/Pz80KdPH0RGRiIiIgJCCMycORONGzdGXFwcSktLMW/ePABAu3btEBMTU8e/CZHjMJkRORkXF5cKicjf39/w88iRIzFy5EiT8t27dzskNiJnxcOMREQke0xmREQke0xmREQke0xmREQke0xmREQkew07mfXq9ef9GYmISLYadjIjIqJ6oWFeZ8bnmTVM/DsT1VscmRERkew1zJGZ/pN5s2amy1Q/cSROVO9xZEZERLLXMEdm+k/mubmmy/ykXj/xyeJE9R5HZkREJHsNc2TGT+oNE//ORPWWw0ZmaWlpiIyMrLD+22+/xfDhwxEWFoakpCRHhaOTmqr7IiIiWXPIyGzjxo3YvXs3PD09TdaXlpZi8eLF2LlzJzw9PTFq1Cj07t0b9913nyPCAoKCHNMOERFJyiEjMz8/P6xevbrC+oyMDPj5+cHHxwfu7u4ICQnB8ePHpQ9Ifxurw4d1X7ytFRGRrDlkZNavXz9cvXq1wnq1Wo2mTZsalr28vKBWqy1uQ6VSWd1+UVGRzXJzfgUFuvbKl/PLl69UYRuVVdXYHMVZ4wKkiy3gb38DAKQfO1at+s68z4gaujqdAOLt7Y38/HzDcn5+vklyMxYYGGh1OyqVymZ5BT/9pPtePhrzKp8YUIUtVFqVY3MQZ40LkDC28g8t1d22vbiUSmW1tktENVenU/P9/f2RmZmJnJwclJSU4Pjx4+jatavjAuAEkIahWTPdl0aj+9IvE1G9UScjsz179qCgoABhYWGYN28eJkyYACEEhg8fjgceeMBxgXACSMNgfujayqFsIpIvhyWzNm3aGKbev/DCC4b1zzzzDJ555hlHhaHDe/U1LN7euu/6O77ol4mo3miYF01Tw6Ifges/vHBETlTvNMxkph+BKRSmy1Q/6f++bm6my0RUbzTMZGZ+TVlDO8zYq5fu8gT9rE4iIplrmMnsyBHby1S/6D+saDSmyw3lwwtRA9Awk1lDnRBgNPHFy3i5vr+pm19+wcsxiOqdhpnMOCGgYeHfm6je4/PMGpJDh3RfoaHIf/zxP5eJzFy/ft3msj23b9+2uWzLyZMnbS7bs337dpvLtly+fNnmsi3/+c9/bC7bU5N9funSJZvL9vzxxx82l2355ZdfbC47SsMcmenfwPV3geAbev3Gw4yVo1CgA4DyOb64du0aWrVqhevXr+PBBx8EAAghrNYtfwEU5T9nZ2ejefPmuH37Nlq0aFGp+vq2T5w4ga5du+LkyZMIDg6uctsAEBERge3bt2P06NEYPXq05foW6l66dAnt2rXD5cuX0b59e7ttG++zffv24fnnn8d//vMfDBgwoMpxV2ef69vOyMhA+/btcenSJfj7+1e57evXr6Nly5b4448/0KpVK+v1LdRNT0/HQw89hF9++QUBAQG225ZIwx6ZqdUN824Qhw7hyqef1nUUZIVWq0VUVBTCwsIQGRmJzMxMk/KkpCQMGzYMI0eOxMGDBwHoRj7jx49HREQEZsyYgcLCwmq1bTwWePDBB03eVAH7owXjEViLFi1MEpl5uTnj8VdwcLBJIgPsj9CMR2CjR482JDJL5eaMR2Dt27c3SWTm5eaMx18DBgwwSWSA/RGa8T6t6j43Hn/5+/ubJDLA/gjNeATWqlUrk0RmXm7OeAQWEBBgksjMyx2hYY7MOLuNnFhycjJKSkqQmJiI1NRUxMfHY926dQCArKwsJCQk4IsvvkBxcTEiIiLQvXt3rF27FgMHDsSwYcOwYcMGJCYm4qWXXqpcg8ajGRzEUwB+KF9+8MELACYDWIeLF69h1KhWpnUPH8JL+AQvAbiFFhjR4hS64yCOlhe3aHEKwEgASTh16g6GDWtWof5sLMcLAJogACFYD/3tmoODcwEcBBCLbdvGQ6HoanpVzeFDAIA4PIVu+AH/N/ojBOIg9M810OWxgwBmYNu2Obj//og/65fXBQ5iPSbh4fbtsRED8SpmAwDat88srwscOdIe7dr5ITERKP8zmNTfiRHYh2wMwDgAL0GXx3R1O3fujF69dMl87VogKcm0LgAcevBBXAPwIGYDGFi+z3VlvXs/iVatPAAAixYBBw6Y1m+BbGRgBPzL94S//xVD3U6dOiMqqgW2btW9esYMIHWladsBrXbjOgDdX3U9WrU6byh76qluiI93x4cf6mqMUWzFVbQxlCPgd0xEHDZgvm4x4JSh7IknnsCrrzZBnz7AggW6l//974D+M5ZhP9aihpnMeNipYZHZvRmVSiV69OgBAAgKCsKZM2cMZadOnULXrl3h7u4Od3d3+Pn54fz581AqlZg0aRIAoGfPnlixYoXVZGb+GJsO5d/1Kc0dMEloAHDgwAHk5uaioOAek7pNAJgfTHIDEBTUFampf46kjhw5gqysLBQUNLJZ3xtACADj5w+8/fbbCAxsjkuXLqGg4AGTusYEgPsB5Pu1xZUrf45mX3nlVXTt2hXff5+JggJfm3U7d+6M06dPG9Z37twZxcW3oVKp8PvvTVFQcK/F+n8HMAPAh0br2rf3h4eHB86fPw9PT4E//rgXBQVNLbbdEsCkSZOwfv3vhvWPPvooSkvLDH+vrCxfFBQ0qVC/HYCLAP5qtK5Tp85o3Ngdubm5UKmuAQBu365431sB4AEA3377LZ555s+R1KOPPoqyslLcvq2GSnWjQj29ewH8+9//xuDBg43a7gQhBAoK8pGVVQCV6hYAQK3+C4qLdf9lkjxOScjA8ePHbZafO3euahv08dF9Abov/bIEqhybgzhrXEJIEJurq+5L//fWL9dyXPb+Tytr/vz54tChQ4bl0NBQUVpaKoQQYteuXWLp0qWGsrfeekscPXpUPPvss6KwsFAIIcSVK1dEeHh41WMEhBYQ165dE+XvcyZf165ds1lXlL+dZGdnW6yfnZ1tt/6JEycs1t22bVul2t62bVvV6hvVvXTpksW6ly5dsrvP9u3bZ7Huvn37KhV3TfZ5RkaGxbp79+6tVNvXr1+3WP/69et266anp1usm56ebr1tIU1fapjnzHJz/7zGzNIyUR0yf86fVquFW/mtuKw9A9B4fX5+Pu65x3QEVVnXAZPzNdeuXTP8rD+fY4v5ObLs7GzDz/pzaNacBEzOkZ04ccLw8+jRoyt1zsz4HNm2bdtM6ts7Z2Z8jsz4XJP+HJo1/wFMzpHt27fP8LP+HJot5ufIqrLPLwEm58gyMjIMPw8cOLBS58yMz5EZt6U/h2aN+Tmy9PR0w8/6c2iO1DCTGZETCw4ORkpKCgAgNTXV5A2jS5cuUCqVKC4uxt27d5GRkYGAgAAEBwfjcPl1dCkpKQgJCal6w0Ig99w5w6J+Zp3xm6vxG595XQiB5s2bG1bpZzMaJzTjcvP6XY1mv+lnMxonNKvPOixvOyIiwrBq27ZtiIiIMEloxuXmddu1a2dYpZ/NaJwIjMvN67c32mf62YzGCe3555+3GbfxPq3qPm9vtM/0sxmNE5pxgrbUdsuWLQ2r9LMZjROacbl53YceesiwSj+b0TihGZc7RJXHcnWg1g8zGv4cZl8ScNbDeTWKKzRU9yWRhn6YUaPRiAULFoiwsDAxcuRIcfHiRbF582aRnJwshBAiMTFRDBs2TAwdOlTs379fCCFEVlaWGD9+vAgLCxOvvfaayM/Pr1aM+t/R/PCWzcNdFpgfUrR5iNHMiRMnKixX5X/C/JCizUOUZswPKdo8xFhOH5v5IUWbhxgtqMk+z8jIqLBclX1mfkjR6iFGC8wPKdo7xCiENH2JyYzJrOrqKplVt12ZJTMp1XpfchBnjUsI543NWeMSQpq+1DBnM7q66r7rp+brl8m2un6oaXVvCP3007rv+rj1y0RUbzTMZKZPYtaWSTrVSYC8LpCI7GiYyYwjs+qpq4dc1vSRPfoRmbVlIpK9hpnMODJzvJocoqzpI3v44YWo3muYyay2NLTDXfobM+uTgn45J0fadvXb1992qart8cMLUb3HZEaOoU/4De0DABE5RMNMZjU97FTXs/rqSm085LI698E0ubssGs7+JqJKa5jJjIed5EWiG0MLs+dfmS8TkXxInsy0Wi2io6Nx4cIFuLu7IzY2Fm3btjWUx8bG4sSJE/Dy8gIArF27Fk2bNpU6rJrhIbOq0+8r/SQOR+47CyPxaK0WOTNn4oMPPoBCoYAQAjNnzkSzZs0QHR0tfUxEVKskT2a2ns0EAGfPnsWmTZus37NNChLNbrP0SZ/K1WR0VdPDm2azIYWXF3KKirBy5UoAwAcffICZM2di5cqVmD59OkdoRDIkeTKz9WwmrVaLzMxMREVF4datWxgxYgRGjBghdUi1x2hUER0djZycnAqf9EtLS7FmzZq6i7E26X9f/SzGqoyqapKQ9O3oE0xVR3NmT0RQ5OXhAwCYPh0rV640JLXp06cb/n5EJC+SJzO1Wg1vo+uCXF1dUVZWBjc3NxQUFGDMmDF4+eWXodFoMHbsWHTq1AkdOnSosB1bD3IzftBbZc6DdCgfkenXivLl89V8WJwQApcuXUJCQgJu376NefPmIT4+HgkJCRg1ahTOnTvndG+QNXk4XoBWCwBIr0r98tF4wN/+pqurH51b2IZ5bPo6+vGzpvzxJunHjlWqafOHT+rHyxMnTjQkMv3y+fPnrW5HkgcKElGtkDyZ2Xo2k6enJ8aOHQtPT08AwJNPPonz589bTGaBgYFW21CpVAgMDLQ6OrJ3HkT/JmerDXs+/fRTNG/eHCtXrkRCQgIA3Sf9iRMnomPHjtXerlT0+6xK9Oe57t4FAAROnqxbrspIqfx5VZX5exq4mD6pyLV8ubp/LwV0CW3Dhg0m6zds2GBzZGZvnymVSqtlRCQtyZ9nZuvZTL/++isiIiKg0WhQWlqKEydO4JFHHqlWO0II5OTkYOXKlZg5c6Yhka1cuRI5OTmSn79SKBT44IMPTNbxkJUFhw5V/TBhUJDpYUnz5SoSAGYChnNkWq0W08sPOer/d4hIXiQfmfXt2xdHjx5FeHg4hBCIi4vDli1b4Ofnhz59+uCFF17AyJEj0ahRIwwePLjaD3QzTiZ1cR5EnzyNzZw5ExMnTpS0XdmpzizGWp6arwDQDKb/G/r/nWbNmvEDCJEMSZ7MXFxcEBMTY7LO+DHfr776Kl599dVaaUv/pmR8HsSRiUz/Sd94dtzt27fx6aef8g2yJtRq28vVEA1AGP1v6P93+Hcikqd6ddG0tdGR1G9SCoUCzZo1s/hJv7S0lG+QQM3umiLRRe7mfxf+nYjkq94kM1ujI8BshCbBdWbR0dEmMyf1Cc3W7DjZkehOHERENVVvkpmt0VGF8yAN/ZN+s2a66fV5eVWrJ8Hhvkrx8dF9118vpl8mIipXb5IZYH105LRJRW5q+lwxIiKJ1KtkBshodFQX9HfuyM3VXYDsqOeR1ZTZHTwqLBNRg1fvkhlJqCaHGXm+jYgkxGTmJBzyOBL9CMzNDQKAoqojsqef1n3Xz0jUL1dGbTwLjYjICiYzJ1Dd23BVmX46vEaju4VXVS9grqvRlURPOSCi+kPy21mRbXV9G64qUatNDy2aL9uSmmqa/MyXbdFoTGecmi9Xk/m+dap9TURVwmRWxxQKBXx8fBAUFISVK1fCxcUFK1euRFBQEHx8fGr3UKPRfRGF2XKlSJRU6kI0YHIfRv2HCD6Yk0iemMzqmBACubm5SDUbpaSmpiI3N7d2RwvNmhlmMCrMliVXk1FdLRMAcgB5jIaJqFJ4zqyulJ+vUhw6hBUrVuDw4cMmCS0oKAgrVqyo3ZFZTS96rsnFy050jZoC4MM5ieoZ+Y/MevWC37hxhkWHngfp1evPSRTVJITArFmzLI7MZs2aVbvxWzlMqC1/2Kae+XJ9pACwYsUKk3W1/uGBiBymXo3MajorUKvVwsXoQZDmyxUcOVL1IM1uuKvo3RsnT56Er68vbt26ZXiZr68vTp48Wak315pM6+8FICc4GCdOnICLiwu0Wi2Cg4PRrFkzHDI/n1aTkZ2TXfi8EMDukBCTdSEhIRg0aBDefffdugkKuqdZv/XWW8jOzoaXlxeWLFmC5s2bm7zmo48+wqFDh+Dm5ob58+ejS5cuUKlUWLRoEVxdXeHu7o4lS5bA19e3jn4LIseT78hMPyo6fBheP/8MERqKnE2bqn0epBd0DxLVj0r0b+q9LI289G3rRzo1GKFptVrkaTS4desWgoKCoNFoEBQUhFu3biEvL8/uKCk6OhozZswwmcgwY8YMy8nb1dVkWrtWocB5AGlpaYbfPTg4GGlpaTh//rzTj9CqOwrXAtgN3ejXeJ+npqZi9+7ddfp7/+tf/0JAQAC2b9+OIUOGYO3atSblZ8+exU8//YTPP/8cK1asMCTe9957DwsWLEBCQgL69u2LjRs31kX4RHVGvsnMjEKhgI+ra7VmBWqBqr2pHzliOiozX7ZFP4OwPLG4pKTgnpAQ+Pr6IjU1Fa6urkhNTYWvry/uuecemyNDIQT279+PVatWGRLajBkzsGrVKuzfv7/im7vZYUaFEAgr/zktLQ2urq5IS0sDAISFhVXcZ040mzEa1Z+N6AJgEGBIYPp9HhQUhEGDBtkejUtMqVSiR48eAICePXvihx9+qFD+9NNPQ6FQ4MEHH4RGo8Ht27exYsUKBAYGAgA0Gg0aN27s8NiJ6pJ8DzPqD4E1awaNVguXgweRO3MmUo0ezAnoPn2HhobaPPSmABAGYBX+fFPXs/qmbmvZFqMLlwFAhIaia0YGUowOMQLArVu30LVrV7uHDP/2t7/h2LFjWLVqFVatWmWy3h4FgA8BYNo0k7rTpk3Dhx9+WLlDnOXbMSxX8c4llg6RVqZN/WxEACaP+5k+fXqlYngXwEKl0uRvrVQqHZrIPv/8c3z66acm61q0aIGmTZsCALy8vHD37l2TcrVajWZGM1D1r2nbti0A4MSJE9i6dSu2bdtmtV2VSmW1rKioyGZ5XXHWuADnjc1Z4wIkik3IwPHjxyuuDA3VfQG6r9BQoenRQzz66KMCuvc7AUA8+uijQqPRmNbV1zH6iip/rXndqKioim1bqC+s7Mpz586ZrvDx0X3p6/j4CE3TppWL24KoqCgRFBRkUjcoKKjScWsA0aVLF5P6Xbp0sdy2Wd2FgJgGCK1WK4QQQqvVimnTpomFCxdWqu2FgJg+fbpJ/enTp4spU6bYrastr2sct/G2KlN/6tSpJvWnTp1quX65Cn9LMxb/T6vo9ddfF2lpaUIIIfLy8sSAAQNMyj/99FOxYcMGw/LgwYNFdna2EEKIffv2iYEDB4orV65UO0Z7v2Ndcda4hHDe2Jw1LiGk6Uv15jCjEALdUlMNh8n00tLS0K1bN5uf+AWATeWvNa+7adOm2p1RGBRkcl9C8eij8Csutti2n5+f7bjL7x5iaSZkZc4TagG0AnDq1CmT9adOnUKrVq1snjsSAPZDN5qt1CFOC/WtXet19+5du/VrMhtRAPAAsHr1akydOhVarRZTp07F6tWr4eHhUafXmQUHB+Nw+eSglJQUhJhNUgkODsaRI0eg1Wpx7do1aLVaNG/eHP/+97+xdetWJCQk4C9/+UtdhE5Ut6qc/upAZUZm2p49RWt3d5NP2vqv1q1bm37iNvuUXgoIhYV6AIRCoRClpaWmbbu66r702yhfNv9Ur9Vq7Y7MNE2bCi8rbXt5eVkfnYWGCm3PnqJVq1YW67Zq1ariKMPCqEzfdlBQkNBoNIZRnsW2zUY206zEPW3aNLttG7YxbVqFumfPnrVbN6o8ZuO6lR2RlhrV8fDwEKWlpcLDw8OwrsLfu5wjRmYFBQVi6tSpIjw8XERGRoqbN28KIYRYsmSJYcS2atUqMWLECDFs2DDx888/i7KyMvH444+LQYMGiTFjxogxY8aIlStXVitGZ/0076xxCeG8sTlrXEJI05fke87MjBACvm5u+L2kpEKZr6+v3XNmtlSoZ+EC4OiiIuTMnFnhsoDS0lKsWbPG5va9AORbWu/lZb1Saiq0Gg2yioosFmdlZUGr1ZqcEzLnAiAEwDmjySeAbn917NjR5vkjBYBd0I1wjCPw8PDArl27DOezbLE2AX7NmjU295n5bESlUomQkBDDCHXhwoU2Y3cBcB+ALOiO3Tdq1MhQdt9999XpBBBPT0+T85d6c+bMMfw8depUTJ061aT8p59+kjw2ImdWbw4zuri4wMfNrcI1Oc2bN4ePj4/dN7dt2t1SAAAgAElEQVRWVspatWpVsW5ursl1UiI3FznFxZU7ZJaTY/IwTEVuLm5Zie3WrVsVE6n+MoDcXLio1dCUlVmsq9Fo7L4pCwDF5e2Yt1tcXGzzcJsGwC2YJjJAlxxu3boFjZ1JMQLAHaDCG/eqVauQl5dns20XAPdAN1nCeDZiixYt7M4ABXSJuL2Vsvbt2/PCaSIZku/ITP9crHLi8GH8AKDU7GW3b9/GDz/8YHNkJgDctNLMzZs37c6OUwD4qvxn49sjAUBycrJpXTfTXa5xcYG1M1NarRYajQZuxnWMzo+VlcduiRACZWVlJqMOS362tv5nayU6CgAFVsoKCgokTQgCwI8ASrKzTdZnZ2fjxx9/rNRsxmPW1h+zVkJEzkzykZlWq0VUVBTCwsIQGRmJzMxMk/KkpCQMGzYMI0eOxMGDB6vdThkqJjK90tJSlFkZwQC6UYa10rKyMrujDA2AK1bKrl+/blrf7Nos61H92b4Jo1GhvQsC7MVdCthMpKWl1vao9X1tKLdRF9Alw4oH03S2bt1qMxlpAFQ8mKxTUlJi9/cutFkKFBbaewURORvJR2bJyckoKSlBYmIiUlNTER8fj3Xr1gHQnddJSEjAF198geLiYkRERKB79+5wd3evUhu9cBCHK6xNArAOgCeA/8Dd/ShCQ3uVlx3ES/gEL+FT3EILPImdFra6rnwbbRAYeANt2rQxKjuI2ViOF7AXFxCADlhvoX4sgAMAHoWb23cmbQNAHOajG36AJ54CEGeh/gwAafD0HIjQ0GSTtgFgPSahA9IBDAQw20L9SHh6emLHDoHy3W2oCwA7MQL3IRvAOAAvWaj/PBo3bow1awSSkirWP4ze5T/NLo/BWKFhVuCiRcCBA6Z1WyAbX2JE+VIcgKfM6l81nHecMQNIhemHnAKkA5hUvrQeQIBJeWjoSRw9+jgAYMwY4KpZ/SL8AGB++dJOAC1Myp977jscOdIPAPD3vwP63PbnfiQiZyP5yMz4jgZBQUE4c+aMoezUqVPo2rUr3N3d0bRpU/j5+eH8+fPVaifUXrkhmVTUxmpJeXmb1jVs2/or7N035Ouvv7FaZu+mS/Zuy1ST+lUeUdZi20EAHrNS5u3dFI8//rjNbfey0/Zzzz1n5xVE5GwkH5mp1Wp4Gz3uw9XVFWVlZXBzc4NarTbc7QDQzd5TW7l5rfnV4h3KvysAHEJvaAFMB/BRhZqFiIjYiH/8437DoasOHXsbSn2RjW/RG08BsDQfrHPne7F2rcrksJdx/YeRjoPojSjoxmLmXnnlccyadb5CXf3WnsAPcCmP35xCoUDLlmewbp2bxfq6dLG3/KuiM2fOoEsXN8OIwrxtLYAQfAolPq1Qt2PHjlCpVOjdW4HevSvWFwCaACjAcgDLTep6eHjgwgUlFAoFRowARoyo2LYAEAUgxjBC+tPEiRNx/rzu+qpJk4AOKyvGPR3Acd0rTOoOHjwaEyfOh0qle/U//gF02Fax/gFD/REm9R955BGMGJFkqG98KZsz31GBqMGr7Bz+X3/9VahUqirP/Y+LixP79u0zLPfo0cPwc3JyssndIqZMmSJOnTpVYRs2rzkov16ptLTU4jVPsHXtUPl1R2VlZTbrlpWVWW272vXL6xYXF9usW1xcbLXtQhv1AIjCwkKb+6ykpMRm/ZKSEqv1i+20bStuUf5vZ6u+rbrV+lvXwj53xHVmUuN1ZrXPWWNz1riEqMM7gHz88cf47LPPsHPnTkyfPr0yVQyCg4ORkpICQHddUEDAn+c3unTpAqVSieLiYty9excZGRkm5VVhb9aerXLza5rMr5Gyd52Ym5vtAa6tcns3hLVV7mmzpu6aJVvsnZu0VW7vNrb2fi97sw1tlS9btsxkefHixTbLzUVFRZksz50712Y5EcmAtSy3ceNGwyfUBQsWiDt37ojc3FwxYsSIKmVLjUYjFixYIMLCwsTIkSPFxYsXxebNm0VycrIQQojExEQxbNgwMXToULF//36L26jsp0mYfbI3X7ZF/zr9nRNWrlxZ6bq11bYj69bmPqtO3dpqe/HixUIIIRYvXlyttufOnSuEEGLu3Ll263NkVnecNS4hnDc2Z41LCGn6ktWee/z4cTFt2jSxd+9e8csvv4hZs2aJKVOmiO+++67KjdRUVTqg+ZtRZd/chBAVbgFk7ZZA1lhqu7L/UDWJuzp1a2uf1aSutfqV3Wf6RGZt2R59IrO2bI7JrO44a1xCOG9szhqXEA6+nVVISAhCQkKwZ88efPTRR4iMjKxw01NnJMzuHGG+bMu0adNsLlen7cpOGKhJ3DWp64xtV3afzZs3z+ayPfHx8TaXiUg+rJ4zS09Px3vvvYeLFy/irbfeglKpxPz58/Hbb785Mj4iIiK7rCazqKgoDB8+HD179sSHH36IiRMnYvbs2RUeJkhERFTXFMLKcaFx48ahT58+KCgowK1bt/DOO+84OjYDpVJZZ20TVYWzH4pnXyK5qGpfsprMCgoKcPToUTRp0gTdunXjncSJiMhpWU1mREREclFvnmdGREQNl917M5aWltq9u4ajaLVaREdH48KFC3B3d0dsbCzatm1rKE9KSsKOHTvg5uaGyZMno3fv3ja2VntKS0sxf/58/P777ygpKcHkyZPRp08fQ/mWLVuwc+dOw4ND3333XbRvb+3xkLVvyJAhhntgtmnTxuSOGXW1z7788kt89ZXuKXDFxcVQqVQ4evQo7rnnHgBAbGwsTpw4YXja9tq1a03u4ymVtLQ0LFu2DAkJCcjMzMS8efOgUCjw0EMPVXiCdVFREd566y1kZ2fDy8sLS5YsqfBwWGfkrP0IcO6+5Iz9CHDOvlQn/cjehWgDBw4UsbGx4sKFC1W+iK22/e9//zNc2Hry5Enx2muvGcpu3rwpBg4cKIqLi0VeXp7hZ0fYuXOniI2NFUIIcfv2bREaGmpSPnv2bHH69GmHxGKuqKhIDB482GJZXe4zY9HR0WLHjh0m68LDw0V2drZD49iwYYMYOHCgePHFF4UQQkyaNEn8+OOPQgjdXXC+/vprk9dv3rxZrFq1SgghxN69e8WiRYscGm91OWs/EsJ5+5Ic+pEQztGX6qof2T3M+O9//xtPP/204cLpzz//HPn5+VXPmrXAUY+Tqar+/fub3LPS1dXVpPzs2bPYsGEDRo0ahfXrLT37TDrnz59HYWEhxo8fj7FjxyLV6EnVdbnP9E6fPo2LFy8iLCzMsE6r1SIzMxNRUVEIDw/Hzp2WnjdX+/z8/LB69WrD8tmzZ/HEE08AAHr27Invv//e5PXG/489e/bEDz/84JA4a8pZ+xHgvH3J2fsR4Dx9qa76kd3DjC4uLujZsycAYOfOnYaHaQ4dOtRkpzlCbT1Oprbph+9qtRrTpk3DjBkzTMoHDBiAiIgIeHt744033sDBgwcddhjCw8MDEyZMwIsvvohff/0Vr776Kvbv31/n+0xv/fr1eP31103WFRQUYMyYMXj55Zeh0WgwduxYdOrUCR06dLCyldrRr18/XL161bAshDDM4vXy8sLdu3dNXm+8/yyVOytn7Uf69vQxOlNfcvZ+BDhPX6qrfmR3ZLZ06VL0798fycnJePXVV7F7925s374d//rXv6rVYE14e3ubjAq1Wq3hjvTmZfn5+Q45x6J3/fp1jB07FoMHD8YLL7xgWC+EwLhx49C8eXO4u7sjNDQU586dc1hc7dq1w6BBg6BQKNCuXTs0a9YMWVlZAOp+n+Xl5eHSpUt48sknTdZ7enpi7Nix8PT0hLe3N5588sk6+aRrfFw/Pz/fcA5Cz3j/WSp3Vs7cjwDn7EvO3I8A5+5LjupHdpPZ//3f/+Grr77CokWLEBgYaAjuo48qPgZTao56nExV3bp1C+PHj8dbb72FESNMH/aoVqsxcOBA5OfnQwiBY8eOoVOnTg6JC9CNpvX3HLxx4wbUajXuu+8+AHW7zwDg559/Rrdu3Sqs//XXXxEREQGNRoPS0lKcOHECjzzyiMPi0uvYsSOOHTsGAEhJScFjj5k+3zo4OBiHDx82lDv7BdN6ztqPAOftS87cjwDn7kuO6kd2rzNLTExERkYG5s+fj/Hjx2PQoEEYMmRItRqrKf0srPT0dAghEBcXh5SUFPj5+aFPnz5ISkpCYmIihBCYNGkS+vXr55C4YmNj8d///tdkVtWLL76IwsJChIWFYdeuXUhISIC7uzueeuqpKt/AuCZKSkrw9ttv49q1a1AoFHjzzTeRlpZW5/sMADZt2gQ3Nze89NJLAHQz1fRxbdy4Efv370ejRo0wePBgjBo1yiExXb16FbNmzUJSUhIuX76MBQsWoLS0FO3bt0dsbCxcXV0xfvx4/POf/4RGo8HcuXORlZWFRo0aYfny5YY3OGfmrP0IcN6+5Mz9CHC+vlQX/chuMhs6dCh27NiBxo0bo7S0FGPGjEFiYmK1f0kiIqLaZvcwo4uLi+GpwY0aNeJtrYiIyOnYnc3Yp08fREREoEuXLjh79iyeeeYZR8RFRERUaZW6N6NKpcLly5fRvn17yadHExERVZXdZJaZmYn9+/ejtLQUAHDz5k3ExMQ4JDgiIqLKsHvObO7cuQCAEydO4OrVq8jJyZE8KCIioqqwm8w8PDwwadIkPPDAA4iPj8etW7ccERcREVGl2U1mQghkZWWhoKAABQUFyM3NdURcRERElWY3mb3xxhtITk7GoEGD0KdPH8N9GomIiJyF3QkgH3/8MSZMmOCoeIiIiKrM7sjs8OHD0Gg0joiFiIioWuxeNH3nzh306NEDbdq0gUKhgEKhwI4dOxwRGxERUaXYPcz4+++/V1jXunVryQIiIiKqKruHGb/66qsKX9WRlpaGyMjICuu//fZbDB8+HGFhYUhKSqrWtokaCvYjIsvsHmb09fUFoJuif+7cOWi12io3snHjRuzevRuenp4m60tLS7F48WLs3LkTnp6eGDVqFHr37i2Lx2gQORr7EZF1dkdm4eHhCA8Px6hRo7Bo0SLcuHGjyo34+flh9erVFdZnZGTAz88PPj4+cHd3R0hICI4fP17l7RM1BOxHRNbZHZldvnzZ8HNWVhauX79e5Ub69euHq1evVlivVqtNHi/u5eUFtVpd4XVKpbLKbRLVBSmfNl3TfgSwL5F8VLUv2U1mUVFRUCgUEELAw8MDc+bMqXZw5ry9vZGfn29Yzs/PN+mUxpzhkfQqlQqBgYF1HQbjcNI46ipRVKUfAexLjMP546hOX7KbzDZt2oSMjAx07NgRycnJ6NatW7WCs8Tf3x+ZmZnIyclBkyZNcPz4cV6gTVRF7EdElUhmb731Fp566il07NgRly9fxn//+18sX768Ro3u2bMHBQUFCAsLw7x58zBhwgQIITB8+HA88MADNdo2UUPBfkT0J7vJ7MaNGxg1ahQA4NVXX7U4Lbgy2rRpY5gy/MILLxjWP/PMM3x6NVElsR8RWWZ3NiPw5ySQK1euVGtqPhERkZTsjszmz5+PGTNmIDs7G/fffz/effddR8RFRERUaXaTWWBgIBYvXmyYANKhQwdHxEVERFRpdg8zvvnmm0hLSwOgO9w4b948yYMiIiKqCrvJzHwCyM2bNyUPioiIqCqqNAEkMzOTE0CIiMjpVGkCiIeHB4YOHeqIuIiIiCrN7sjs0UcfxaJFi9CtWzcUFhYiOzvbEXERERFVmtWRWUlJCfbt24dt27bB3d0darUaBw4cgIeHhyPjIyIissvqyOyZZ57BhQsXsGzZMmzfvh33338/ExkRETklqyOzsWPHYu/evfj9998xYsQICCEcGRcREVGlWR2ZTZw4Ebt370ZkZCT27t2LM2fO4P3330d6eroj4yMiIrLL7gSQJ554Au+//z6++eYbtGzZslafZ0ZERFQbKnWdGQDcc889iIyMxK5du6SMh4iIqMoqncyIiIicleTJTKvVIioqCmFhYYiMjERmZqZJ+ccff4xhw4Zh+PDh+Oabb6QOh0i22JeIrLN7B5CaSk5ORklJCRITE5Gamor4+HisW7cOAJCXl4eEhAR8/fXXKCwsxJAhQ9C3b1+pQyKSJfYlIuskT2ZKpRI9evQAAAQFBeHMmTOGMk9PTzz44IMoLCxEYWEhFAqF1e2oVCqpQ7WrqKiIcTCOOsO+xDgaShzVIXkyU6vV8Pb2Niy7urqirKwMbm66plu1aoUBAwZAo9Fg0qRJVrcTGBgodah2qVQqxsE4rFIqlZJun32JcTSUOKrTlyQ/Z+bt7Y38/HzDslarNXS+lJQU3Lx5EwcOHMChQ4eQnJyMU6dOSR0SkSyxLxFZJ3kyCw4ORkpKCgAgNTUVAQEBhjIfHx94eHjA3d0djRs3RtOmTZGXlyd1SESyxL5EZJ3khxn79u2Lo0ePIjw8HEIIxMXFYcuWLfDz80OfPn3w/fffY+TIkXBxcUFwcDC6d+8udUhEssS+RGSd5MnMxcUFMTExJuv8/f0NP0+bNg3Tpk2TOgwi2WNfIrKOF00TEZHsMZkREZHsMZkREZHsMZkREZHsMZkREZHsMZkREZHsMZkREZHsMZkREZHsMZkREZHsMZkREZHsMZkREZHsMZkREZHsMZkREZHsMZkREZHsSf4IGK1Wi+joaFy4cAHu7u6IjY1F27ZtDeWHDx/GmjVrAAAdO3bEwoULoVAopA6LSHbYl4isk3xklpycjJKSEiQmJmL27NmIj483lKnVarz//vv45z//iaSkJLRu3Rp37tyROiQiWWJfIrJO8mSmVCrRo0cPAEBQUBDOnDljKDt58iQCAgKwZMkSREREwNfXF82bN5c6JCJZYl8isk7yw4xqtRre3t6GZVdXV5SVlcHNzQ137tzBsWPHsGvXLjRp0gSjR49GUFAQ2rVrV2E7KpVK6lDtKioqYhyMo86wLzGOhhJHdUiezLy9vZGfn29Y1mq1cHPTNdusWTN07twZ9913HwDgscceg0qlstgBAwMDpQ7VLpVKxTgYh1VKpVLS7bMvMY6GEkd1+pLkhxmDg4ORkpICAEhNTUVAQIChrFOnTkhPT8ft27dRVlaGtLQ0/PWvf5U6JCJZYl8isk7ykVnfvn1x9OhRhIeHQwiBuLg4bNmyBX5+fujTpw9mz56NV155BQDQv39/kw5KRH9iXyKyTvJk5uLigpiYGJN1/v7+hp8HDBiAAQMGSB0GkeyxLxFZx4umiYhI9pjMiIhI9pjMiIhI9pjMiIhI9pjMiIhI9pjMiIhI9pjMiIhI9pjMiIhI9pjMiIhI9pjMiIhI9pjMiIhI9pjMiIhI9pjMiIhI9pjMiIhI9iRPZlqtFlFRUQgLC0NkZCQyMzMtvuaVV17Bv/71L6nDIZIt9iUi6yRPZsnJySgpKUFiYiJmz56N+Pj4Cq/58MMPkZubK3UoRLLGvkRkneTJTKlUokePHgCAoKAgnDlzxqR8//79UCgU6Nmzp9ShEMka+xKRdZI/aVqtVsPb29uw7OrqirKyMri5uSE9PR179+7FqlWrsGbNGpvbUalUUodqV1FREeNgHHWGfYlxNJQ4qkPyZObt7Y38/HzDslarhZubrtldu3bhxo0bGDduHH7//Xc0atQIrVu3tvjJMjAwUOpQ7VKpVIyDcVilVCol3T77EuNoKHFUpy9JnsyCg4Nx8OBBPP/880hNTUVAQIChbM6cOYafV69eDV9fXx4iIbKCfYnIOsmTWd++fXH06FGEh4dDCIG4uDhs2bIFfn5+6NOnj9TNE9Ub7EtE1kmezFxcXBATE2Oyzt/fv8Lrpk6dKnUoRLLGvkRkHS+aJiIi2WMyIyIi2WMyIyIi2WMyIyIi2WMyIyIi2WMyIyIi2WMyIyIi2WMyIyIi2WMyIyIi2WMyIyIi2WMyIyIi2WMyIyIi2WMyIyIi2WMyIyIi2WMyIyIi2ZP8eWZarRbR0dG4cOEC3N3dERsbi7Zt2xrKP/nkE+zbtw8AEBoaijfeeEPqkIhkiX2JyDrJR2bJyckoKSlBYmIiZs+ejfj4eEPZb7/9ht27d2PHjh1ITEzEkSNHcP78ealDIpIl9iUi6yQfmSmVSvTo0QMAEBQUhDNnzhjKWrZsiU2bNsHV1RUAUFZWhsaNG0sdEpEssS8RWSd5MlOr1fD29jYsu7q6oqysDG5ubmjUqBGaN28OIQSWLl2Kjh07ol27dha3o1KppA7VrqKiIsbBOOoM+xLjaChxVIfkyczb2xv5+fmGZa1WCze3P5stLi7G/Pnz4eXlhYULF1rdTmBgoKRxVoZKpWIcjMMqpVIp6fbZlxhHQ4mjOn1J8nNmwcHBSElJAQCkpqYiICDAUCaEwJQpU/Dwww8jJibGcIiEiCpiXyKyTvKRWd++fXH06FGEh4dDCIG4uDhs2bIFfn5+0Gq1+Omnn1BSUoLvvvsOADBr1ix07dpV6rCIZId9icg6yZOZi4sLYmJiTNb5+/sbfj59+rTUIRDVC+xLRNbxomkiIpI9JjMiIpI9JjMiIpI9JjMiIpI9JjMiIpI9JjMiIpI9JjMiIpI9JjMiIpI9JjMiIpI9JjMiIpI9JjMiIpI9JjMiIpI9JjMiIpI9JjMiIpI9yZOZVqtFVFQUwsLCEBkZiczMTJPypKQkDBs2DCNHjsTBgwelDodIttiXiKyT/HlmycnJKCkpQWJiIlJTUxEfH49169YBALKyspCQkIAvvvgCxcXFiIiIQPfu3eHu7i51WESyw75EZJ3kIzOlUokePXoAAIKCgnDmzBlD2alTp9C1a1e4u7ujadOm8PPzw/nz56UOiUiW2JeIrJN8ZKZWq+Ht7W1YdnV1RVlZGdzc3KBWq9G0aVNDmZeXF9RqtcXtKJVKqUOtFMZhinE4DvuSNBiHKWeJo6okT2be3t7Iz883LGu1Wri5uVksy8/PN+mQeiEhIVKHSeT02JeIrJP8MGNwcDBSUlIAAKmpqQgICDCUdenSBUqlEsXFxbh79y4yMjJMyonoT+xLRNYphBBCyga0Wi2io6ORnp4OIQTi4uKQkpICPz8/9OnTB0lJSUhMTIQQApMmTUK/fv2kDIdIttiXiKyTPJlVhb6zXrhwAe7u7oiNjUXbtm0N5UlJSdixYwfc3NwwefJk9O7d2+ExfPLJJ9i3bx8AIDQ0FG+88Uatx1CZOPSvmThxIvr06YNRo0bVSRyHDx/GmjVrAAAdO3bEwoULoVAoHB7Hxx9/jH379kGhUOC1115D3759az0GY2lpaVi2bBkSEhJM1n/77bdYs2YN3NzcMHz4cIwcOVLSOCxxhn5UmTjYl9iXgFrsS8KJ/O9//xNz584VQghx8uRJ8dprrxnKbt68KQYOHCiKi4tFXl6e4WdHxnDlyhUxdOhQUVZWJjQajQgLCxMqlarWY7AXh97y5cvFiBEjxPbt2yWJwV4cd+/eFQMGDBDZ2dlCCCE2bNhg+NmRceTm5orQ0FBRXFwscnJyRK9evSSJQW/Dhg1i4MCB4sUXXzRZX1JSIp599lmRk5MjiouLxbBhw8TNmzcljcUSZ+hH9uJgX2JfEqJ2+5JT3QHEGaYe24qhZcuW2LRpE1xdXeHi4oKysjI0bty41mOwFwcA7N+/HwqFAj179pSk/crEcfLkSQQEBGDJkiWIiIiAr68vmjdv7vA4PD098eCDD6KwsBCFhYWSfJo15ufnh9WrV1dYn5GRAT8/P/j4+MDd3R0hISE4fvy4pLFY4gz9yF4c7EvsS0Dt9iXJZzNWRW1NPZYqhkaNGqF58+YQQmDp0qXo2LEj2rVrV+sx2IsjPT0de/fuxapVqwyHJaRiK447d+7g2LFj2LVrF5o0aYLRo0cjKChIkn1iKw4AaNWqFQYMGACNRoNJkybVevvG+vXrh6tXr1qM0RH/o/Y4Qz+yFwf7EvsSULt9yamSWW1MPZYyBgAoLi7G/Pnz4eXlhYULF9Z6+5WJY9euXbhx4wbGjRuH33//HY0aNULr1q0l+WRpK45mzZqhc+fOuO+++wAAjz32GFQqlSQd0FYcKSkpuHnzJg4cOAAAmDBhAoKDg9GlS5daj6MqMUr1P1rVOOqiH9mLA2BfYl+qfIyV+T91qsOMzjD12FYMQghMmTIFDz/8MGJiYuDq6lrr7Vcmjjlz5uDzzz9HQkIChg4dipdeekmyQyS24ujUqRPS09Nx+/ZtlJWVIS0tDX/9618dHoePjw88PDzg7u6Oxo0bo2nTpsjLy5MkDlv8/f2RmZmJnJwclJSU4Pjx4+jatavD43CGfmQvDvYl9iVbqtOXnGpk1rdvXxw9ehTh4eGGqcdbtmwxTD2OjIxEREQEhBCYOXOmJMfYbcWg1Wrx008/oaSkBN999x0AYNasWZK8YdnbF45iL47Zs2fjlVdeAQD0799fsjdGe3F8//33GDlyJFxcXBAcHIzu3btLEocle/bsQUFBAcLCwjBv3jxMmDABQggMHz4cDzzwgMPi0HOGfmQvDvYl9iVLatKXnGpqPhERUXU41WFGIiKi6mAyIyIi2WMyIyIi2WMyIyIi2WMyIyIi2WMyo3rj6tWrhpuRXrhwAT///LOk7XXq1AmRkZEmXzdu3LD42i+//NJwIerWrVsr3cY333xTYZvHjh3DU089hcjISIwZMwbh4eHIyMio/i9ihfH+JHJ2TnWdGVFt+frrr+Hr64vHH39csjZ8fHwq3OnbmmHDhhl+XrduHcaMGVOpep999hmio6MrXGPz5JNP4oMPPgAAHDlyBEuXLsX69esrGTlR/cNkRvXOjRs38NVXX6FRo0Z45JFHUFRUhA8++ACurq74y1/+gpiYGOzZswcHDx5EUVERsrKyMHbsWBw4cAC//PIL5syZg2effRbz5s3DlStXUFxcjAkTJuD555+vVPtLlixBo0aNMGPGDLz88st4+eWXcfr0afj6+iInJwe5ubmIjo5GdHS0oU56ejri4+Oh1WqRl5eHd955BwgzNDcAAAP+SURBVHl5eVCpVJg7dy62b98Od3d3i+3l5eWhdevWAIDIyEjce++9yMvLw+rVq/HOO+/g7t27uHPnDl588UVEREQgMjISHTp0wC+//AK1Wo2VK1eidevWWLt2LZKTk6HRaDBq1Cg8/fTTuH37NqZMmYKsrCw8/PDDiI2NrfHfh0gKTGZU7zzwwAMYOnQofH190blzZ/Tv3x/bt29HixYt8OGHH+Krr76Cm5sb8vPzsXnzZuzbtw+ffPIJkpKScOzYMXz22Wd48skncezYMXzxxRcAgKNHj1ZoJzc3F5GRkYbl+++/H8uXL8esWbMwevRozJ07F126dEGvXr1w+vRpAMDkyZOxdetWk0QGABcvXsTcuXPx8MMPY8+ePfjyyy8RGxuLwMBAREdHV0hkP/74IyIjI1FSUoILFy6YjMpeeOEF9O3bF2fPnsWAAQPw3HPP4caNG4Y7fwC621r94x//wAcffIB9+/bh6aefRkpKCj7//HOUlJRg+fLl6N69O9RqNRYvXoymTZuib9++yM7ORosWLWrl70RUm5jMqF67ffs2bt68iRkzZgAAioqK0L17d/j5+SEwMBAA0LRpU/j7+0OhUMDHxwfFxcXw9vbGggULsGDBAqjVagwaNKjCtq0dZmzUqBHGjRuHuXPn4uDBg5WK8/7778fatWvh4eGB/Px8k7uaW2J8mPHSpUsIDw833G9Pf3NaX19ffPrpp/j666/h7e2NsrIyQ/2OHTsC0D2K5datW7h8+TK6dOkCV1dXeHp64p133sHVq1fxl7/8BT4+PgCAFi1aoLCwsFK/D5GjcQII1UsKhQJarRb33nsvWrZsibVr1yIhIQGvvfYa/va3vxleY83Nmzdx9uxZrFmzBhs2bMD7779vkgxsyc3NxT//+U/MmzcPCxYsqFBu6Q5y7733HqZNm4YlS5YgICDA8BqFQmHx9cZ8fX1NlvW/1+bNmxEUFIRly5ahf//+NrfTvn17nDt3DlqtFqWlpXj55ZdRUlIi+fOsiGoLR2ZUL3Xq1AlLly6Fv78//vGPf2DixIkQQsDLywtLly7F9evXbda/7777kJWVhSFDhqBJkyYYP368yeNLgIqHGQHdzXI//vhjvPLKKxg8eDDOnDmDzz77zOQ1/v7+ePPNN7Fs2TLDukGDBmHKlClo0aIFWrZsiTt37gAAunbtijlz5mDz5s1o1qyZ4fX6w4wuLi7Iz8/HvHnz4OHhYdJO7969ER0djT179qBZs2ZwdXVFSUmJxd83MDAQPXr0wKhRo6DVajFq1Cir5+iInBFvNExERLLHw4xERCR7TGZERCR7TGZERCR7TGZERCR7TGZERCR7TGZERCR7TGZERCR7/w8tG5dIFLgEBwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Branch Name</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>E_Threshold</th>\n",
       "      <th>acceptance_rate</th>\n",
       "      <th>accepted_correct</th>\n",
       "      <th>accepted_incorrect</th>\n",
       "      <th>accepted_accuracy</th>\n",
       "      <th>overlap_adjusted_accuracy</th>\n",
       "      <th>M(T) B(F)</th>\n",
       "      <th>M(F) B(T)</th>\n",
       "      <th>M(F) B(F) overlap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>branch_1</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.6599</td>\n",
       "      <td>0.659900</td>\n",
       "      <td>0.021633</td>\n",
       "      <td>0.1263</td>\n",
       "      <td>1187</td>\n",
       "      <td>76</td>\n",
       "      <td>0.939826</td>\n",
       "      <td>0.948535</td>\n",
       "      <td>65</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>branch_2</td>\n",
       "      <td>8737</td>\n",
       "      <td>0.9572</td>\n",
       "      <td>0.953188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>8328</td>\n",
       "      <td>409</td>\n",
       "      <td>0.953188</td>\n",
       "      <td>inf</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Branch Name  Predictions  test_accuracy  Accuracy  E_Threshold  \\\n",
       "0    branch_1        10000         0.6599  0.659900     0.021633   \n",
       "1    branch_2         8737         0.9572  0.953188     0.000000   \n",
       "\n",
       "   acceptance_rate  accepted_correct  accepted_incorrect  accepted_accuracy  \\\n",
       "0           0.1263              1187                  76           0.939826   \n",
       "1           1.0000              8328                 409           0.953188   \n",
       "\n",
       "   overlap_adjusted_accuracy  M(T) B(F)  M(F) B(T)  M(F) B(F) overlap  \n",
       "0                   0.948535         65          8                 11  \n",
       "1                        inf          0          0                409  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "displayEvidence_cascade(Outputs, Evidence = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''     overlap\n",
    "        if zero, both match, if else they don't match\n",
    "        TT 1-1 =0\n",
    "        TF 1-0 =1\n",
    "\n",
    "        FT 0-1 = -1\n",
    "        FF 0-0 =0\n",
    "        \n",
    "        '''\n",
    "# print(Outputs[1])\n",
    "displayEvidence(Outputs, Evidence = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 227,227 sigmoid evidence cifar10 v2\n",
    "# print(Outputs[0])\n",
    "\n",
    "displayEvidence(Outputs, Evidence = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 227,227 sigmoid evidence cifar10\n",
    "displayEvidence(Predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 227,227 sigmoid cifar10\n",
    "displayEvidence(Predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 32,32 crossEvidence cifar10\n",
    "displayEvidence(Predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "displayEvidence(Predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayEvidence(Predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = tf.keras.models.load_model('alexNetv6_evidence_test.hdf5',\n",
    "    custom_objects={\"CrossEntropyEndpoint\":CrossEntropyEndpoint,\"crossEntropy_loss\":loss_function()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictions_2 = collectEvidence(model_2,test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayEvidence(Predictions_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectEntropy(model,test_ds):\n",
    "    num_outputs = len(model.outputs) # the number of output layers for the purpose of providing labels\n",
    "#     train_ds, test_ds, validation_ds = (dataset)\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    iterator = iter(test_ds)\n",
    "    print(len(test_ds))\n",
    "    item = iterator.get_next()\n",
    "#     print(item)\n",
    "\n",
    "    pClass = []\n",
    "    predictions=[]\n",
    "    pEvidence = []\n",
    "    pUncertainty=[]\n",
    "    Outputs = pd.DataFrame()\n",
    "    output_names=[\"mainExit\"]\n",
    "    pAcc=[]\n",
    "    for i, (x,y) in enumerate(test_ds):\n",
    "#     for i in range(100):\n",
    "        print(\"prediction: {} of {}\".format(i,len(test_ds)),end='\\r')\n",
    "        result = model.predict(x)\n",
    "        pClass.append(tf.argmax(y,1).numpy()[0])\n",
    "        pred= (tf.nn.softmax(result)[0])\n",
    "\n",
    "        pEvidence.append(calcEntropy_Tensors(pred).numpy())\n",
    "        if np.argmax(pred) == np.argmax(y):\n",
    "            pAcc.append(1)       \n",
    "        else:\n",
    "            pAcc.append(0)\n",
    "    Predictions = pd.DataFrame({\"label\":pClass,\"evidence\":pEvidence,\"Acc\":pAcc,\"overlap\":0})\n",
    "    return Predictions\n",
    "\n",
    "def displayEntropy(Predictions):\n",
    "    output_names=[\"mainExit\"]\n",
    "    Outputs=pd.DataFrame()\n",
    "    Predictions[\"Acc\"]=Predictions[\"Acc\"].astype('bool')\n",
    "    acc = Predictions[\"Acc\"].value_counts()\n",
    "    print(acc)\n",
    "    print((acc.loc[True] , acc.loc[False]))\n",
    "    mean = Predictions.loc[(Predictions['Acc'] == False)].groupby(\"Acc\")[\"evidence\"].mean().iloc[0]\n",
    "    std = Predictions.loc[(Predictions['Acc'] == False)].groupby(\"Acc\")[\"evidence\"].std().iloc[0]\n",
    "    E_threshold = mean - std\n",
    "    correct_rows = Predictions.loc[Predictions['Acc'] == True]\n",
    "    incorrect_rows = Predictions.loc[Predictions['Acc'] == False]\n",
    "    # Incorrects_overlap = Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"evidence\"] > E_threshold) & (Predictions[\"overlap\"] == 0)].count().iloc[0]\n",
    "    print(acc)\n",
    "    for i,name in enumerate(output_names):\n",
    "        Outputs = Outputs.append(pd.DataFrame({\"Branch Name\":output_names[i],\n",
    "                \"Accuracy\":(acc.loc[True] /  (acc.loc[True] + acc.loc[False])),\n",
    "                \"E_Threshold\":E_threshold,\n",
    "                # \"Overlap_Threshold\":non_overlapping_incorrects_threshold,\n",
    "                \"acceptance_rate\":Predictions.loc[(Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0]/(Predictions.count().iloc[0]),\n",
    "                \"accepted_correct\":Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                \"accepted_incorrect\":Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                \"accepted_accuracy\":(Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0])/ Predictions.loc[(Predictions[\"evidence\"] < E_threshold)].count()[0],\n",
    "                # \"overlap_adjusted_accuracy\":(Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0] + Incorrects_overlap) / Predictions.loc[(Predictions[\"evidence\"] > E_threshold)].count()[0],\n",
    "                \"rejected_correct\":Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                \"rejected_incorrect\":Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                # \"Incorrects_overlap\":Incorrects_overlap,\n",
    "                },index=[i]))\n",
    "\n",
    "    # fig, axs = plt.subplots(1, 2)\n",
    "    plt.suptitle('Horizontally stacked subplots')\n",
    "    plt.scatter(correct_rows['label'],correct_rows['evidence'],c ='r',marker='+')\n",
    "    plt.scatter(incorrect_rows['label']+.3,incorrect_rows['evidence'],c ='k',marker='x')\n",
    "    plt.plot(np.repeat(E_threshold,11),'b--')\n",
    "    plt.title(\"evidence\")\n",
    "\n",
    "\n",
    "    # fig.set_size_inches(10, 10)\n",
    "    plt.show()\n",
    "    return Outputs\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entropy_predictions = collectEntropy(model_2,test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayEntropy(Entropy_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
    "test_images = test_images.reshape(10000, 32,32,3).astype(\"float32\") / 255\n",
    "\n",
    "# print(y_train)\n",
    "K= 10 # number of classes\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels,10)\n",
    "shuffle_size = 22500\n",
    "batch_size=1\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "\n",
    "def augment_images(image, label,input_size=(227,227), channel_first = False):\n",
    "            image = tf.image.resize(image,input_size)\n",
    "            if channel_first:\n",
    "                image = tf.transpose(image, [2, 0, 1])\n",
    "            return image, label\n",
    "test_ds_size = len(list(test_ds))\n",
    "# test_ds = (test_ds.map(augment_images))\n",
    "t_target = tf.data.Dataset.from_tensor_slices((test_labels))\n",
    "test_ds = tf.data.Dataset.zip((test_ds,t_target))\n",
    "test_ds = (test_ds.batch(batch_size=1, drop_remainder=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictions_mse = collectEvidence(model,test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayEvidence(Predictions_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sum entropy \n",
    "import pandas as pd\n",
    "def entropy(x):\n",
    "    return -(x * math.log(x))\n",
    "# Data for plotting\n",
    "t = np.arange(0.00001, 1, 0.01)\n",
    "print(t.shape)\n",
    "t_ = np.full((100,), .1)\n",
    "df = pd.DataFrame([t,t,t_,t,t])\n",
    "# print(df.transpose())\n",
    "p = df.apply(calcEntropy,axis=0)\n",
    "# print(p)\n",
    "# print(p)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(t, p)\n",
    "ax.set(xlabel='Probability of Outcome',ylabel='Entropy of event')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [0]\n",
    "y_pred = [.99,.01, .01, .0, .01, .01]\n",
    "# Using 'auto'/'sum_over_batch_size' reduction type.  \n",
    "scce = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "crossE = scce(y_true, y_pred).numpy()\n",
    "print(\"crossE: \",crossE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [0,1,0,0,0,0]\n",
    "y_pred = [.99,.01, .01, .0, .01, .01]\n",
    "# Using 'auto'/'sum_over_batch_size' reduction type.  \n",
    "scce = tf.keras.losses.CategoricalCrossentropy()\n",
    "crossE = scce(y_true, y_pred).numpy()\n",
    "print(\"crossE: \",crossE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [0]\n",
    "y_pred = [.0,.01, .9, .0, .0, .0]\n",
    "ent = calcEntropy(y_pred)\n",
    "print(\"Entropy: \",ent)\n",
    "loss = ent *1\n",
    "print(\"Loss: \",loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [[0],[0],[0]]\n",
    "y_pred = [[.9,.5, .6, .5, .5, .5],[.8,.5, .6, .5, .5, .5],[.7,.5, .6, .5, .5, .5]]\n",
    "y_pred = [[.9,.0,.0,.0,.0,.0,],[.8,.5, .6, .5, .5, .5],[.7,.5, .6, .5, .5, .5]]\n",
    "# y_pred = [.1,.1, .1, .1, .1, .1]\n",
    "# Using 'auto'/'sum_over_batch_size' reduction type.  \n",
    "scce = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "crossE = scce(y_true, y_pred).numpy()\n",
    "print(\"crossE: \",crossE)\n",
    "\n",
    "''' When the answer is correct, CrossE goes down\n",
    "    When \n",
    "    When its wrong, Entropy High\n",
    "    When its right, Entropy Low\n",
    "    \n",
    "    so penalize being right with low entropy and reward being right with high entropy\n",
    "    \n",
    "    \n",
    "    OORRRR train a second model for a branch to determine if you are going to get it right or not?\n",
    "    Isn't that what ResNet Did? you calculate if the blocks will contribute, was it block drop?\n",
    "    Binary classification,\n",
    "    could be done at the branch end as a separate evaulator, using the entropy score and the input to the branch as inputs?\n",
    "'''\n",
    "\n",
    "\n",
    "ent = calcEntropy(y_pred)\n",
    "print(\"Entropy: \",ent)\n",
    "loss = crossE + ent\n",
    "print(\"combined Loss: \",loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[.1,.1, .675, .1091, .4311, .1875,.121,.143,.2,.5]]\n",
    "x = tf.constant([[2, 20, 30, 3, 6], [3, 11, 16, 1, 8],\n",
    "                 [14, 45, 23, 5, 27]])\n",
    "\n",
    "print(list(map(np.argmax,np.array(x))))\n",
    "def foo(y_pred):\n",
    "    y_pred = y_pred.numpy()\n",
    "    pred_label = list(map(np.argmax,np.array(y_pred)))\n",
    "    return pred_label\n",
    "%timeit foo(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_true = tf.constant([[2],[2],[0]])\n",
    "A = tf.constant([.1,.1, .675, .1091, .4311, .1875,.121,.143,.2,.5])\n",
    "B = tf.constant([[2, 20, 30, 3, 6], [3, 11, 16, 1, 8],\n",
    "                 [14, 45, 23, 5, 27]])\n",
    "\n",
    "y_pred = tf.constant([[.9,.5, .6, .5, .5, .5],[.8,.5, .6, .5, .5, .5],[.7,.5, .6, .5, .5, .5]])\n",
    "\n",
    "# new_list = new_list = [list(range(10)) for _ in range(10)]\n",
    "\n",
    "print(tf.math.argmax(y_pred,1))\n",
    "pred_labels = tf.math.argmax(y_pred,1)\n",
    "print(tf.reshape(y_true,pred_labels.shape))\n",
    "indexes = tf.where(tf.math.equal(pred_labels, tf.cast(tf.reshape(y_true,pred_labels.shape),'int64')))\n",
    "indexes = tf.reshape(indexes,[-1])\n",
    "# print(tf.gather(B,indexes))\n",
    "CorrectE = tf.gather(y_pred,indexes)\n",
    "print(CorrectE)\n",
    "# print(calcEntropy(CorrectE[0]))\n",
    "\n",
    "\n",
    "results = tf.map_fn(calcEntropy,tf.cast(CorrectE,'float'))\n",
    "print(\"results: \",results)\n",
    "\n",
    "\n",
    "\n",
    "%timeit tf.map_fn(calcEntropy,tf.cast(CorrectE,'float'))\n",
    "\n",
    "\n",
    "crossE = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "crossE(y_true,y_pred)\n",
    "%timeit crossE(y_true,y_pred)\n",
    "# [\n",
    "#     [\n",
    "#         [ 2 20 30  3  6]\n",
    "#     ]\n",
    "#     [\n",
    "#         [ 3 11 16  1  8]\n",
    "#     ]\n",
    "# ]\n",
    "\n",
    "def entropyAddition_noCross(y_true, y_pred):\n",
    "    crossE = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    #Entropy is added to the CrossE divided by the len of inputs\n",
    "    pred_labels = tf.math.argmax(y_pred,1)\n",
    "    indexes = tf.where(tf.math.equal(pred_labels, tf.cast(tf.reshape(y_true,pred_labels.shape),'int64')))\n",
    "    indexes = tf.reshape(indexes,[-1])\n",
    "    entropies = tf.gather(y_pred,indexes)\n",
    "    if tf.equal(tf.size(entropies), 0):\n",
    "        correctEntropies = 0\n",
    "    else:\n",
    "        correctEntropies = tf.reduce_mean(tf.map_fn(calcEntropy_Tensors,tf.cast(entropies,'float')))\n",
    "    scce = crossE(y_true, y_pred)\n",
    "    loss = correctEntropies\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.constant([[1],[2],[0]])\n",
    "y_pred = tf.constant([[0,0, .6, .5, .5, .5],[.8,.5, .6, .5, .5, .5],[.9,.3, .3, .2, .1, .32]])\n",
    "crossE = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "def entropyAddition(y_true, y_pred):\n",
    "    crossE = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    #Entropy is added to the CrossE divided by the len of inputs\n",
    "    pred_labels = tf.math.argmax(y_pred,1)\n",
    "    indexes = tf.where(tf.math.equal(pred_labels, tf.cast(tf.reshape(y_true,pred_labels.shape),'int64')))\n",
    "    indexes = tf.reshape(indexes,[-1])\n",
    "    entropies = tf.gather(y_pred,indexes)\n",
    "    if tf.equal(tf.size(entropies), 0):\n",
    "        correctEntropies = 0\n",
    "    else:\n",
    "        correctEntropies = tf.reduce_mean(tf.map_fn(calcEntropy_Tensors,tf.cast(entropies,'float')))\n",
    "    scce = crossE(y_true, y_pred)\n",
    "    loss = scce + (correctEntropies * scce)\n",
    "    return loss\n",
    "\n",
    "\n",
    "print(\"normal CrossE: \",crossE(y_true ,y_pred))\n",
    "\n",
    "print(\"normal Entropy\",entropyAddition_noCross(y_true2,y_pred2))\n",
    "\n",
    "print(entropyAddition(y_true2, y_pred2))\n",
    "# %timeit entropyAddition(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.constant([1])\n",
    "y_pred = tf.constant([0,1, 0, 0, 0, 0])\n",
    "# print(crossE(y_true,y_pred))\n",
    "\n",
    "print(tf.cast(1e-8,'float')+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.constant([[1],[2],[0]])\n",
    "y_pred = tf.constant([[.9,.1, .6, .5, .5, .5],[.8,.5, .6, .5, .5, .5],[.9,.3, .3, .2, .1, .32]])\n",
    "crossE = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "def entropyMultiplication(y_true, y_pred):\n",
    "    crossE = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    #Entropy is added to the CrossE divided by the len of inputs\n",
    "    pred_labels = tf.math.argmax(y_pred,1)\n",
    "    indexes = tf.where(tf.math.equal(pred_labels, tf.cast(tf.reshape(y_true,pred_labels.shape),'int64')))\n",
    "    indexes = tf.reshape(indexes,[-1])\n",
    "    entropies = tf.gather(y_pred,indexes)\n",
    "    if tf.equal(tf.size(entropies), 0):\n",
    "        correctEntropies = 1\n",
    "    else:\n",
    "        correctEntropies = tf.reduce_mean(tf.map_fn(calcEntropy_Tensors,tf.cast(entropies,'float')))\n",
    "    scce = crossE(y_true, y_pred)\n",
    "    loss = correctEntropies * scce\n",
    "    return loss\n",
    "\n",
    "\n",
    "print(\"normal CrossE: \",crossE(y_true,y_pred))\n",
    "print(entropyAddition(y_true, y_pred))\n",
    "# %timeit entropyAddition(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.constant([[1],[2],[1]])\n",
    "y_pred = tf.constant([[.9,.1, .6, .5, .5, .5],[.8,.5, .6, .5, .5, .5],[.9,.3, .3, .2, .1, .32]])\n",
    "\n",
    "def confidenceScore(y_true, y_pred):\n",
    "        # print(y_pred)\n",
    "        # print(tf.keras.backend.get_value(y_pred))\n",
    "        \n",
    "        # y_true =y_true.numpy()\n",
    "        # y_pred = y_pred.numpy()\n",
    "        # AvgConfidence = -1\n",
    "        pred_labels = tf.math.argmax(y_pred,1)\n",
    "        # countCorrect=0\n",
    "        indexes = tf.where(tf.math.equal(pred_labels, tf.cast(tf.reshape(y_true,pred_labels.shape),'int64')))\n",
    "        indexes = tf.reshape(indexes,[-1])\n",
    "        entropies = tf.gather(y_pred,indexes)\n",
    "        if tf.equal(tf.size(entropies), 0):\n",
    "            correctEntropies = 0\n",
    "        else:\n",
    "            correctEntropies = tf.reduce_mean(tf.map_fn(calcEntropy,tf.cast(entropies,'float')))    \n",
    "        \n",
    "        return correctEntropies\n",
    "    \n",
    "print(confidenceScore(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [[2],[2],[0]]\n",
    "y_pred = [[.9,0, .6, .5, .5, .5],[.8,.5, .6, .5, .5, .5],[.7,.5, .6, .5, .5, .5]]\n",
    "\n",
    "def foo(x, y):\n",
    "    scce = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    crossE = scce(x, y).numpy()\n",
    "    return crossE\n",
    "\n",
    "print(foo(y_true,y_pred))\n",
    "%timeit foo(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Python program explaining \n",
    "# where() function \n",
    "  \n",
    "import numpy as np\n",
    "  \n",
    "# a is an array of integers.\n",
    "a = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "  \n",
    "print(a)\n",
    "  \n",
    "print ('Indices of elements <4')\n",
    "  \n",
    "b = np.where(a<5)\n",
    "print(b)\n",
    "  \n",
    "print(\"Elements which are <4\")\n",
    "print(a[b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [[0],[0],[0]]\n",
    "y_pred = [[.5,.5, .6, .5, .5, .1],[.5,.5, .6, .5, .5, .2],[.5,.5, .6, .5, .5, .3]]\n",
    "# y_pred = [[1],[1],[1]]\n",
    "# print(np.array(y_pred))\n",
    "\n",
    "####\n",
    "# Numpy confidence metric version\n",
    "y_true =np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "def argmax(x):\n",
    "    return [np.argmax(x)]\n",
    "pred_labels = list(map(argmax,np.array(y_pred)))\n",
    "x = np.where(np.equal(y_true,pred_labels) ==True)\n",
    "y = y_pred[x[0]]\n",
    "results = calcEntropy(y)\n",
    "print(results)\n",
    "if not (results):\n",
    "    print(\"A\")\n",
    "print(np.median(results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_true = [[2],[2],[0]]\n",
    "y_pred = [[.5,.5, .6, .5, .5, .5],[.5,.5, .6, .5, .5, .5],[.5,.5, .6, .5, .5, .5]]\n",
    "\n",
    "y_true = [[2]]\n",
    "y_pred = [[.1,.1, .15, .1, .1, .1]]\n",
    "def entropyAddition_loss():\n",
    "    #create a wrapper function that returns a function\n",
    "    crossE = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    def entropyAddition(y_true, y_pred):\n",
    "        #Entropy is added to the CrossE divided by the len of inputs\n",
    "        pred_labels = tf.math.argmax(y_pred,1)\n",
    "        indexes = tf.where(tf.math.equal(pred_labels, tf.cast(tf.reshape(y_true,pred_labels.shape),'int64')))\n",
    "        indexes = tf.reshape(indexes,[-1])\n",
    "        entropies = tf.gather(y_pred,indexes)\n",
    "        correctEntropies = tf.reduce_mean(tf.map_fn(calcEntropy,tf.cast(entropies,'float')))\n",
    "#         print(pred_label)\n",
    "        scce = crossE(y_true, y_pred)\n",
    "        sumEntropy = 0\n",
    "        loss = correctEntropies + scce\n",
    "        return loss\n",
    "    \n",
    "    return entropyAddition\n",
    "\n",
    "def custom_loss_multi(y_true, y_pred):\n",
    "    #CrossE is multiplied by the Entropy\n",
    "    pred_label = list(map(np.argmax,np.array(y_pred)))\n",
    "    crossE = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    sumLoss = 0\n",
    "    \n",
    "    for i in range(len(y_pred)):\n",
    "        loss = crossE(y_true[i], y_pred[i])\n",
    "#         print('crossE: ',loss)\n",
    "        if pred_label[i] == y_true[i]:\n",
    "#             print('calcEntropy ',calcEntropy(y_pred[i]))\n",
    "            loss = loss * calcEntropy(y_pred[i])\n",
    "        sumLoss += loss\n",
    "    sumLoss = sumLoss / len(y_pred)         \n",
    "    \n",
    "#     loss = crossE(y_true, y_pred)\n",
    "#     print(\"CrossE : \",loss.numpy())\n",
    "#     print(\"Loss : \",sumLoss)\n",
    "    return sumLoss\n",
    "    ### I want to reduce the entropy of correct answers\n",
    "    ### if label - pred = 0 (aka correct) then add entropy to crossE\n",
    "    \n",
    "    \n",
    "#     squared_difference = tf.square(np.array(y_true) - np.array(y_pred))\n",
    "#     return tf.reduce_mean(squared_difference, axis=-1)  # Note the `axis=-1`\n",
    "\n",
    "scce = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "crossE = scce(y_true, y_pred).numpy()\n",
    "print(\"crossEntropyLoss: \",crossE)\n",
    "\n",
    "\n",
    "crossE = custom_loss_addition(y_true, y_pred).numpy()\n",
    "print(\"customLoss_addition: \",crossE)\n",
    "\n",
    "\n",
    "crossE = custom_loss_multi(y_true, y_pred).numpy()\n",
    "print(\"customLoss_multi: \",crossE)\n",
    "\n",
    "  \n",
    "# model.compile(loss=custom_loss, optimizer='adam')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sub(x,y):\n",
    "    if x - y == 0:\n",
    "        return 1\n",
    "%timeit sub(5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sub(x,y):\n",
    "    if x == y:\n",
    "        return 0\n",
    "    \n",
    "%timeit sub(5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7483e188a462fd4248cd8d23b24bc727a5fe7a35e4044aa57ebcc92f8fe9e445"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
