{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook example for building a BrevisNet model using Inceptionv3 as a base.\n",
    "\n",
    "Things to keep in mind when running this example: \n",
    "1. That the dataset size matches the model input size\n",
    "2. That the names of the joining layer points matches what you expect\n",
    "3. That your computer has enough memory to build the model and train as well as shuffle and load the dataset. In testing I've found that if the kernel gets interupted and then continued, the ram and gpu memory allocation can get wonky when performing the fit command.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"..\") # Adds higher directory to python modules path.\n",
    "import branchingdnn as branching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (train_ds, test_ds, validation_ds) = branching.dataset.prepare.dataset(tf.keras.datasets.cifar10.load_data(),32,5000,22500,(227,227),include_targets=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcEntropy(y_hat):\n",
    "        #entropy is the sum of y * log(y) for all possible labels.\n",
    "        if isinstance(y_hat, list):\n",
    "            y_hat = np.array(y_hat)\n",
    "        sum_entropy = 0\n",
    "        if y_hat.ndim >1:\n",
    "            return list(map(calcEntropy,y_hat))\n",
    "        for i in range(len(y_hat)):\n",
    "            if y_hat[i] != 0: # log of zero is undefined, see MacKay's book \"Information Theory, Inference, and Learning Algorithms\"  for more info on this workaround reasoning.\n",
    "                entropy =y_hat[i] * math.log(y_hat[i],2)\n",
    "                sum_entropy +=  entropy\n",
    "\n",
    "        return -sum_entropy\n",
    "    \n",
    "def calcEntropy_Tensors(y_hat):\n",
    "        #entropy is the sum of y * log(y) for all possible labels.\n",
    "        #doesn't deal with cases of log(0)\n",
    "        rank = tf.rank(y_hat)\n",
    "        def calc_E(y_hat):\n",
    "            results = tf.clip_by_value((tf.math.log(y_hat)/tf.math.log(tf.constant(2, dtype=y_hat.dtype))), -1e12, 1e12)\n",
    "#             results = tf.clip_by_value(results, -1e12, 1e12)\n",
    "#             print(\"res \", results)\n",
    "            return tf.reduce_sum(y_hat * results)\n",
    "\n",
    "        sumEntropies = (tf.map_fn(calc_E,tf.cast(y_hat,'float')))\n",
    "        \n",
    "        if rank == 1:\n",
    "            sumEntropies = tf.reduce_sum(sumEntropies)\n",
    "        return -sumEntropies\n",
    "    \n",
    "def calcEntropy_Tensors2(y_hat):\n",
    "    #entropy is the sum of y * log(y) for all possible labels.\n",
    "    #doesn't deal with cases of log(0)\n",
    "#     num = tf.math.log(y_hat)\n",
    "# #     print(\"num\",num)\n",
    "#     dem = tf.math.log(tf.constant(2, dtype=y_hat.dtype))\n",
    "# #     print(\"dem\",dem)\n",
    "#     E = num / dem\n",
    "# #     print(\"E\",E)\n",
    "#     P = y_hat * E\n",
    "# #     print(\"p\",P)\n",
    "#     mean = tf.reduce_mean(tf.boolean_mask(P, tf.math.is_finite(P)))\n",
    "#     print(\"mean\",mean)\n",
    "#     sumEntropies = mean\n",
    "    val = y_hat * tf.math.log(y_hat)/tf.math.log(tf.constant(2, dtype=y_hat.dtype))\n",
    "    sumEntropies =  tf.reduce_mean(tf.boolean_mask(val,tf.math.is_finite(val)))\n",
    "    return -sumEntropies\n",
    "    \n",
    "# This function to generate evidence is used for the first example\n",
    "def relu_evidence(logits):\n",
    "    return tf.nn.relu(logits)\n",
    "\n",
    "# This one usually works better and used for the second and third examples\n",
    "# For general settings and different datasets, you may try this one first\n",
    "def exp_evidence(logits): \n",
    "    return tf.exp(tf.clip_by_value(logits,-10,10))\n",
    "\n",
    "# This one is another alternative and \n",
    "# usually behaves better than the relu_evidence \n",
    "def softplus_evidence(logits):\n",
    "    return tf.nn.softplus(logits)\n",
    "\n",
    "def KL(alpha):\n",
    "    # print(\"K:\",K)\n",
    "    beta=tf.constant(np.ones((1,K)),dtype=tf.float32)\n",
    "    S_alpha = tf.reduce_sum(alpha,axis=1,keepdims=True)\n",
    "    S_beta = tf.reduce_sum(beta,axis=1,keepdims=True)\n",
    "    lnB = tf.compat.v1.lgamma(S_alpha) - tf.reduce_sum(tf.compat.v1.lgamma(alpha),axis=1,keepdims=True)\n",
    "    lnB_uni = tf.reduce_sum(tf.compat.v1.lgamma(beta),axis=1,keepdims=True) - tf.compat.v1.lgamma(S_beta)\n",
    "\n",
    "    dg0 = tf.compat.v1.digamma(S_alpha)\n",
    "    dg1 = tf.compat.v1.digamma(alpha)\n",
    "\n",
    "    kl = tf.reduce_sum((alpha - beta)*(dg1-dg0),axis=1,keepdims=True) + lnB + lnB_uni\n",
    "    # print(\"kl\", kl)\n",
    "    return kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyEndpoint(tf.keras.layers.Layer):\n",
    "        def __init__(self, num_outputs, name=None, **kwargs):\n",
    "            super(CrossEntropyEndpoint, self).__init__(name=name)\n",
    "            self.num_outputs = num_outputs\n",
    "#             self.kl = tf.keras.losses.KLDivergence()\n",
    "            self.loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "#             self.loss_fn = tf.keras.losses.categorical_crossentropy\n",
    "            self.evidence = softplus_evidence\n",
    "#             self.evidence = tf.compat.v1.distributions.Dirichlet\n",
    "            self.temperature = 10\n",
    "            self.lmb = 0.005\n",
    "        def build(self, input_shape):\n",
    "            self.kernel = self.add_weight(\"kernel\", shape=[int(input_shape[-1]), self.num_outputs])\n",
    "        \n",
    "        def get_config(self):\n",
    "            config = super().get_config().copy()\n",
    "            config.update({\n",
    "                'num_outputs': self.num_outputs,\n",
    "                'name': self.name\n",
    "            })\n",
    "            return config\n",
    "\n",
    "        def call(self, inputs, labels,learning_rate=1):\n",
    "            outputs = tf.matmul(inputs,self.kernel)\n",
    "            softmax = tf.nn.softmax(outputs)\n",
    "            evidence = self.evidence (outputs)\n",
    "            alpha = evidence + 1\n",
    "            u = self.num_outputs / tf.reduce_sum(alpha, axis=1, keepdims=True) #uncertainty\n",
    "          \n",
    "            # prob = alpha/tf.reduce_sum(alpha, 1, keepdims=True) \n",
    "            pred = tf.argmax(outputs,1)\n",
    "            truth = tf.argmax(labels,1)\n",
    "            match = tf.reshape(tf.cast(tf.equal(pred, truth), tf.float32),(-1,1))\n",
    "            # total_evidence = tf.reduce_sum(evidence,1, keepdims=True)\n",
    "            mean_succ = tf.reduce_sum(tf.reduce_sum(evidence,1, keepdims=True)*match) / tf.reduce_sum(match+1e-20)\n",
    "            mean_fail = tf.reduce_sum(tf.reduce_sum(tf.reduce_sum(evidence,1, keepdims=True)*(1-match)) / (tf.reduce_sum(tf.abs(1-match))+1e-20) )\n",
    "            \n",
    "            self.add_metric(evidence, name=self.name+\"_evidence\",aggregation='mean')\n",
    "            self.add_metric(mean_succ, name=self.name+\"_mean_ev_succ\",aggregation='mean')\n",
    "            self.add_metric(mean_fail, name=self.name+\"_mean_ev_fail\",aggregation='mean')\n",
    "            \n",
    "            return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(annealing_rate=1, momentum=1, decay=1, global_loss=False):\n",
    "    #create a wrapper function that returns a function\n",
    "    temperature = 1\n",
    "    Classes = 10\n",
    "    keras_kl = tf.keras.losses.KLDivergence()\n",
    "    annealing_rate = annealing_rate\n",
    "    momentum_rate = momentum\n",
    "    decay_rate = decay\n",
    "\n",
    "    def cross_entropy_evidence(labels, outputs): \n",
    "        softmax = tf.nn.softmax(outputs)\n",
    "        # activated_outputs =tf.keras.activations.sigmoid(softmax)\n",
    "        evidence = softplus_evidence(outputs)\n",
    "        alpha = evidence + 1\n",
    "        S = tf.reduce_sum(alpha, axis=1, keepdims=True) \n",
    "        E = alpha - 1\n",
    "        m = alpha / S\n",
    "        A = tf.reduce_sum((labels-m)**2, axis=1, keepdims=True) \n",
    "        B = tf.reduce_sum(alpha*(S-alpha)/(S*S*(S+1)), axis=1, keepdims=True) \n",
    "\n",
    "        annealing_coef = tf.minimum(1.0,tf.cast(annealing_rate,tf.float32))\n",
    "#         annealing_coef = 1\n",
    "        alp = E*(1-labels) + 1 \n",
    "        C =  annealing_coef * KL(alp)\n",
    "        # C = keras_kl(labels,evidence)\n",
    "        loss = tf.keras.losses.categorical_crossentropy(labels, softmax)\n",
    "        pred = tf.argmax(outputs,1)\n",
    "        truth = tf.argmax(labels,1)\n",
    "        match = tf.reshape(tf.cast(tf.equal(pred, truth), tf.float32),(-1,1))\n",
    "        return loss + C\n",
    "        # return (A + B) + C\n",
    "\n",
    "    return  cross_entropy_evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10\n",
    "def loss_function(annealing_rate=1, momentum=1, decay=1, global_loss=False):\n",
    "    #create a wrapper function that returns a function\n",
    "    temperature = 1\n",
    "    Classes = 10\n",
    "    keras_kl = tf.keras.losses.KLDivergence()\n",
    "    annealing_rate = annealing_rate\n",
    "    momentum_rate = momentum\n",
    "    decay_rate = decay\n",
    "    def cross_entropy_evidence(labels, outputs): \n",
    "        softmax = tf.nn.softmax(outputs)\n",
    "        # activated_outputs =tf.keras.activations.sigmoid(softmax)\n",
    "        evidence = softplus_evidence(outputs)\n",
    "        alpha = evidence + 1\n",
    "        S = tf.reduce_sum(alpha, axis=1, keepdims=True) \n",
    "        E = alpha - 1\n",
    "        m = alpha / S\n",
    "        A = tf.reduce_sum((labels-m)**2, axis=1, keepdims=True) \n",
    "        B = tf.reduce_sum(alpha*(S-alpha)/(S*S*(S+1)), axis=1, keepdims=True) \n",
    "\n",
    "        annealing_coef = tf.minimum(1.0,tf.cast(annealing_rate,tf.float32))\n",
    "#         annealing_coef = 1\n",
    "        alp = E*(1-labels) + 1 \n",
    "        # print(\"alp\", alp)\n",
    "        C =  annealing_coef * KL(alp)\n",
    "        # C = keras_kl(labels,evidence)\n",
    "        loss = tf.keras.losses.categorical_crossentropy(labels, softmax)\n",
    "        pred = tf.argmax(outputs,1)\n",
    "        truth = tf.argmax(labels,1)\n",
    "        match = tf.reshape(tf.cast(tf.equal(pred, truth), tf.float32),(-1,1))\n",
    "        return loss + C\n",
    "        # return (A + B) + C\n",
    "    return  cross_entropy_evidence\n",
    "\n",
    "# outputs =[]\n",
    "# targets = tf.keras.Input(shape=(10,),name='targets')\n",
    "# inputs = tf.keras.Input(shape=(227,227,3))\n",
    "# x = tf.keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(227,227,3))(inputs)\n",
    "# x = tf.keras.layers.BatchNormalization()(x)\n",
    "# x = tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2),padding=\"same\")(x)\n",
    "\n",
    "\n",
    "# branchLayer = tf.keras.layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))(x)\n",
    "# branchLayer = tf.keras.layers.Dense(124, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch124\"))(branchLayer)\n",
    "# branchLayer = tf.keras.layers.Dense(64, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch64\"))(branchLayer)\n",
    "# # branchLayer = tf.keras.layers.Dense(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_output\"))(branchLayer)\n",
    "# # branch_output_1 = (CrossEntropyEndpoint(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_endpoint\"))(branchLayer,targets))\n",
    "# branch_output_1 = tf.keras.layers.Dense(10, activation=\"softmax\", name=tf.compat.v1.get_default_graph().unique_name(\"branch_endpoint\"))(branchLayer)\n",
    "\n",
    "# x = tf.keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "# x = tf.keras.layers.BatchNormalization()(x)\n",
    "# x = tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2),padding=\"same\")(x)\n",
    "\n",
    "\n",
    "# branchLayer = tf.keras.layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))(x)\n",
    "# branchLayer = tf.keras.layers.Dense(124, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch124\"))(branchLayer)\n",
    "# branchLayer = tf.keras.layers.Dense(64, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch64\"))(branchLayer)\n",
    "# # branchLayer = tf.keras.layers.Dense(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_output\"))(branchLayer)\n",
    "# # branch_output_2 = (CrossEntropyEndpoint(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_endpoint\"))(branchLayer,targets))\n",
    "# branch_output_2 = tf.keras.layers.Dense(10, activation=\"softmax\", name=tf.compat.v1.get_default_graph().unique_name(\"branch_endpoint\"))(branchLayer)\n",
    "\n",
    "# x = tf.keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "# x = tf.keras.layers.BatchNormalization()(x)\n",
    "# x = tf.keras.layers.Conv2D(filters=384, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "# x = tf.keras.layers.BatchNormalization()(x)\n",
    "# x = tf.keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "# x = tf.keras.layers.BatchNormalization()(x)\n",
    "# x = tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2),padding=\"same\")(x)\n",
    "# x = tf.keras.layers.Flatten()(x)\n",
    "# x = tf.keras.layers.Dense(4096, activation='relu')(x)\n",
    "\n",
    "\n",
    "\n",
    "# branchLayer = tf.keras.layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))(x)\n",
    "# branchLayer = tf.keras.layers.Dense(124, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch124\"))(branchLayer)\n",
    "# branchLayer = tf.keras.layers.Dense(64, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch64\"))(branchLayer)\n",
    "# # branchLayer = tf.keras.layers.Dense(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_endpoint\"))(branchLayer)\n",
    "# branch_output_3 = tf.keras.layers.Dense(10, activation=\"softmax\", name=tf.compat.v1.get_default_graph().unique_name(\"branch_endpoint\"))(branchLayer)\n",
    "# # branch_output_3 = (CrossEntropyEndpoint(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_endpoint\"))(branchLayer,targets))\n",
    "\n",
    "# x = tf.keras.layers.Dropout(0.5)(x)\n",
    "# x = tf.keras.layers.Dense(4096, activation='relu')(x)\n",
    "# x = tf.keras.layers.Dropout(0.5)(x)\n",
    "# output = tf.keras.layers.Dense(10, activation=\"softmax\", name=tf.compat.v1.get_default_graph().unique_name(\"endpoint\"))(x)\n",
    "# # output = CrossEntropyEndpoint(10, name=tf.compat.v1.get_default_graph().unique_name(\"endpoint\"))(x, targets)\n",
    "\n",
    "# model = tf.keras.Model(inputs=[inputs,targets], outputs=[output,branch_output_1,branch_output_2,branch_output_3], name=\"alexnet_branched_entropy\")\n",
    "# loss_fn = loss_function()\n",
    "# model.compile( loss=\"categorical_crossentropy\", optimizer=tf.optimizers.SGD(lr=0.001,momentum=0.9), metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# root_logdir = os.path.join(os.curdir, \"logs\\\\fit\\\\\")\n",
    "# checkpoint = tf.keras.callbacks.ModelCheckpoint(\"alexNetv6_entropy_branched_scratch_40.hdf5\", monitor='val_loss',verbose=1,save_best_only=True, mode='auto')\n",
    "# def get_run_logdir():\n",
    "#     run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "#     return os.path.join(root_logdir, run_id)\n",
    "\n",
    "# run_logdir = get_run_logdir()\n",
    "# tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "# model.fit(train_ds,\n",
    "#         epochs=40,\n",
    "#         validation_data=validation_ds,\n",
    "#         validation_freq=1,\n",
    "#         # batch_size=1,\n",
    "#         verbose=1,\n",
    "#         callbacks=[tensorboard_cb,checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augment Dataset\n",
      "targetsis : True\n",
      "adding targets to inputs\n",
      "trainSize 45000\n",
      "testSize 10000\n"
     ]
    }
   ],
   "source": [
    "dataset = branching.dataset.prepare.dataset(tf.keras.datasets.cifar10.load_data(),32,5000,22500,(224,224), include_targets=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (train_ds, validation_ds, test_ds) = dataset\n",
    "# print(train_ds.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets already present?  False\n",
      "added targets\n",
      "Matching Branchpoint by id number\n",
      "Matching Branchpoint by name\n",
      "add Branch to branch point  mixed0\n",
      "add Branch to branch point  mixed1\n",
      "add Branch to branch point  mixed6\n",
      "<branchingdnn.core.BranchingDnn.branched_model object at 0x0000014184D566A0>\n"
     ]
    }
   ],
   "source": [
    "# model  = tf.keras.models.load_model('alexNetv6_evidence_branched_contin_30.hdf5', custom_objects={\"CrossEntropyEndpoint\":CrossEntropyEndpoint,\"cross_entropy_evidence\":loss_function()})\n",
    "\n",
    "loss_fn = loss_function()\n",
    "brevis = (branching.core.branched_model(modelName=\"../models/inception_finetuned.hdf5\",saveName=\"inception_entropy_flat\",transfer=True,customOptions=\"\")\n",
    "            .add_branches(branching.branches.branch.newBranch_flatten_incept,[\"mixed0\",\"mixed1\",\"mixed6\"], target_input=True)\n",
    "            .set_dataset(dataset)\n",
    "            \n",
    "            )\n",
    "# brevis.evaluate(test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_branched\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 111, 111, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 111, 111, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 111, 111, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 109, 109, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 109, 109, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 109, 109, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 109, 109, 64) 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 109, 109, 64) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 109, 109, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 54, 54, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 54, 54, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 54, 54, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 54, 54, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 52, 52, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 52, 52, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 52, 52, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 25, 25, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 25, 25, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 25, 25, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 25, 25, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 25, 25, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 25, 25, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 25, 25, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 25, 25, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 25, 25, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 25, 25, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 25, 25, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 25, 25, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 25, 25, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 25, 25, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 25, 25, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 25, 25, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 25, 25, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 25, 25, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 25, 25, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 25, 25, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 25, 25, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 25, 25, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 25, 25, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 25, 25, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 25, 25, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 25, 25, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 25, 25, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 25, 25, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 25, 25, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 25, 25, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 25, 25, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 25, 25, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 25, 25, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 25, 25, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 25, 25, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 25, 25, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 25, 25, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 25, 25, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 25, 25, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 25, 25, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 25, 25, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 25, 25, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 25, 25, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 25, 25, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 25, 25, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 25, 25, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 25, 25, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 25, 25, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 25, 25, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 25, 25, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 25, 25, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 25, 25, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 25, 25, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 25, 25, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 25, 25, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 25, 25, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 25, 25, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 25, 25, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 25, 25, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 25, 25, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 25, 25, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 12, 12, 96)   82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 12, 12, 384)  1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 12, 12, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 12, 12, 384)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 12, 12, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 12, 12, 128)  384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 12, 12, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 12, 12, 128)  114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 12, 12, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 12, 12, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 12, 12, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 12, 12, 128)  384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 12, 12, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 12, 12, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 12, 12, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 12, 12, 128)  114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 12, 12, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 12, 12, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 12, 12, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 12, 12, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 12, 12, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 12, 12, 192)  172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 12, 12, 192)  172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 12, 12, 192)  576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 12, 12, 192)  576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 12, 12, 192)  576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 12, 12, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 12, 12, 192)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 12, 12, 192)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 12, 12, 192)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 12, 12, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 12, 12, 160)  480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 12, 12, 160)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 12, 12, 160)  179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 12, 12, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 12, 12, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 12, 12, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 12, 12, 160)  480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 12, 12, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 12, 12, 160)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 12, 12, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 12, 12, 160)  179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 12, 12, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 12, 12, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 12, 12, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 12, 12, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 12, 12, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 12, 12, 192)  215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 12, 12, 192)  215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 12, 12, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 12, 12, 192)  576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 12, 12, 192)  576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 12, 12, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 12, 12, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 12, 12, 192)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 12, 12, 192)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 12, 12, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 12, 12, 160)  480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 12, 12, 160)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 12, 12, 160)  179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 12, 12, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 12, 12, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 12, 12, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 12, 12, 160)  480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 12, 12, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 12, 12, 160)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 12, 12, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 12, 12, 160)  179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 12, 12, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 12, 12, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 12, 12, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 12, 12, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 12, 12, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 12, 12, 192)  215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 12, 12, 192)  215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 12, 12, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 12, 12, 192)  576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 12, 12, 192)  576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 12, 12, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 12, 12, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 12, 12, 192)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 12, 12, 192)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 12, 12, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 12, 12, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 12, 12, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 12, 12, 192)  258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 12, 12, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 12, 12, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 12, 12, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 12, 12, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 12, 12, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 12, 12, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 12, 12, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 12, 12, 192)  258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 12, 12, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 12, 12, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 12, 12, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 12, 12, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 12, 12, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 12, 12, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 12, 12, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 12, 12, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 12, 12, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 12, 12, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 12, 12, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 12, 12, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 12, 12, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 12, 12, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 12, 12, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 12, 12, 192)  576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 12, 12, 192)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 12, 12, 192)  258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 12, 12, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 12, 12, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 12, 12, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 12, 12, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 12, 12, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 12, 12, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 12, 12, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 5, 5, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 5, 5, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 5, 5, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 5, 5, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 5, 5, 320)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 5, 5, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 5, 5, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 5, 5, 448)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 5, 5, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 5, 5, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 5, 5, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 5, 5, 384)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 5, 5, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 5, 5, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 5, 5, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 5, 5, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 5, 5, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 5, 5, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 5, 5, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 5, 5, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 5, 5, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 5, 5, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 5, 5, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 5, 5, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 5, 5, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 5, 5, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 5, 5, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 5, 5, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 5, 5, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 5, 5, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 5, 5, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 5, 5, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 5, 5, 448)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 5, 5, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 5, 5, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 5, 5, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 5, 5, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 5, 5, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 5, 5, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 5, 5, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 5, 5, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 5, 5, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 5, 5, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 5, 5, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 5, 5, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 5, 5, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 5, 5, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 5, 5, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 5, 5, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 5, 5, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 5, 5, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 5, 5, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 5, 5, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 5, 5, 320)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 5, 5, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 5, 5, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "branch_flatten (Flatten)        (None, 160000)       0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "branch_flatten_1 (Flatten)      (None, 180000)       0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "branch_flatten_2 (Flatten)      (None, 110592)       0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "branch124 (Dense)               (None, 1024)         163841024   branch_flatten[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "branch124_1 (Dense)             (None, 1024)         184321024   branch_flatten_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "branch124_2 (Dense)             (None, 1024)         113247232   branch_flatten_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         2098176     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "branch64 (Dense)                (None, 512)          524800      branch124[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "branch64_1 (Dense)              (None, 512)          524800      branch124_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "branch64_2 (Dense)              (None, 512)          524800      branch124_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          524800      dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "branch_output (Dense)           (None, 10)           5130        branch64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "branch_output_1 (Dense)         (None, 10)           5130        branch64_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "branch_output_2 (Dense)         (None, 10)           5130        branch64_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "targets (InputLayer)            [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "classification (Dense)          (None, 10)           5130        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "branch_softmax (Softmax)        (None, 10)           0           branch_output[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "branch_softmax_1 (Softmax)      (None, 10)           0           branch_output_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "branch_softmax_2 (Softmax)      (None, 10)           0           branch_output_2[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 487,429,960\n",
      "Trainable params: 487,395,528\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "brevis.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting Main Layers  and branch layers training to true\n",
      "Model: \"model_branched\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 111, 111, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 111, 111, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 111, 111, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 109, 109, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 109, 109, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 109, 109, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 109, 109, 64) 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 109, 109, 64) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 109, 109, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 54, 54, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 54, 54, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 54, 54, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 54, 54, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 52, 52, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 52, 52, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 52, 52, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 25, 25, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 25, 25, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 25, 25, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 25, 25, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 25, 25, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 25, 25, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 25, 25, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 25, 25, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 25, 25, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 25, 25, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 25, 25, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 25, 25, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 25, 25, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 25, 25, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 25, 25, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 25, 25, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 25, 25, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 25, 25, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 25, 25, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 25, 25, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 25, 25, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 25, 25, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 25, 25, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 25, 25, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 25, 25, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 25, 25, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 25, 25, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 25, 25, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 25, 25, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 25, 25, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 25, 25, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 25, 25, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 25, 25, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 25, 25, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 25, 25, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 25, 25, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 25, 25, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 25, 25, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 25, 25, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 25, 25, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 25, 25, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 25, 25, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 25, 25, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 25, 25, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 25, 25, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 25, 25, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 25, 25, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 25, 25, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 25, 25, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 25, 25, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 25, 25, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 25, 25, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 25, 25, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 25, 25, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 25, 25, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 25, 25, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 25, 25, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 25, 25, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 25, 25, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 25, 25, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 25, 25, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 12, 12, 96)   82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 12, 12, 384)  1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 12, 12, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 12, 12, 384)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 12, 12, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 12, 12, 128)  384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 12, 12, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 12, 12, 128)  114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 12, 12, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 12, 12, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 12, 12, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 12, 12, 128)  384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 12, 12, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 12, 12, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 12, 12, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 12, 12, 128)  114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 12, 12, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 12, 12, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 12, 12, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 12, 12, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 12, 12, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 12, 12, 192)  172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 12, 12, 192)  172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 12, 12, 192)  576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 12, 12, 192)  576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 12, 12, 192)  576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 12, 12, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 12, 12, 192)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 12, 12, 192)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 12, 12, 192)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 12, 12, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 12, 12, 160)  480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 12, 12, 160)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 12, 12, 160)  179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 12, 12, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 12, 12, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 12, 12, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 12, 12, 160)  480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 12, 12, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 12, 12, 160)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 12, 12, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 12, 12, 160)  179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 12, 12, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 12, 12, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 12, 12, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 12, 12, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 12, 12, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 12, 12, 192)  215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 12, 12, 192)  215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 12, 12, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 12, 12, 192)  576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 12, 12, 192)  576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 12, 12, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 12, 12, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 12, 12, 192)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 12, 12, 192)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 12, 12, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 12, 12, 160)  480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 12, 12, 160)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 12, 12, 160)  179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 12, 12, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 12, 12, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 12, 12, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 12, 12, 160)  480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 12, 12, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 12, 12, 160)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 12, 12, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 12, 12, 160)  179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 12, 12, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 12, 12, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 12, 12, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 12, 12, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 12, 12, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 12, 12, 192)  215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 12, 12, 192)  215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 12, 12, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 12, 12, 192)  576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 12, 12, 192)  576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 12, 12, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 12, 12, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 12, 12, 192)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 12, 12, 192)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 12, 12, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 12, 12, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 12, 12, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 12, 12, 192)  258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 12, 12, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 12, 12, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 12, 12, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 12, 12, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 12, 12, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 12, 12, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 12, 12, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 12, 12, 192)  258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 12, 12, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 12, 12, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 12, 12, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 12, 12, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 12, 12, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 12, 12, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 12, 12, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 12, 12, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 12, 12, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 12, 12, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 12, 12, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 12, 12, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 12, 12, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 12, 12, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 12, 12, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 12, 12, 192)  576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 12, 12, 192)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 12, 12, 192)  258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 12, 12, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 12, 12, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 12, 12, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 12, 12, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 12, 12, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 12, 12, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 12, 12, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 5, 5, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 5, 5, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 5, 5, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 5, 5, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 5, 5, 320)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 5, 5, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 5, 5, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 5, 5, 448)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 5, 5, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 5, 5, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 5, 5, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 5, 5, 384)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 5, 5, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 5, 5, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 5, 5, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 5, 5, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 5, 5, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 5, 5, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 5, 5, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 5, 5, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 5, 5, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 5, 5, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 5, 5, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 5, 5, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 5, 5, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 5, 5, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 5, 5, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 5, 5, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 5, 5, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 5, 5, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 5, 5, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 5, 5, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 5, 5, 448)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 5, 5, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 5, 5, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 5, 5, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 5, 5, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 5, 5, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 5, 5, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 5, 5, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 5, 5, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 5, 5, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 5, 5, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 5, 5, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 5, 5, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 5, 5, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 5, 5, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 5, 5, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 5, 5, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 5, 5, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 5, 5, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 5, 5, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 5, 5, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 5, 5, 320)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 5, 5, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 5, 5, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "branch_flatten (Flatten)        (None, 160000)       0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "branch_flatten_1 (Flatten)      (None, 180000)       0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "branch_flatten_2 (Flatten)      (None, 110592)       0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "branch124 (Dense)               (None, 1024)         163841024   branch_flatten[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "branch124_1 (Dense)             (None, 1024)         184321024   branch_flatten_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "branch124_2 (Dense)             (None, 1024)         113247232   branch_flatten_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         2098176     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "branch64 (Dense)                (None, 512)          524800      branch124[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "branch64_1 (Dense)              (None, 512)          524800      branch124_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "branch64_2 (Dense)              (None, 512)          524800      branch124_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          524800      dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "branch_output (Dense)           (None, 10)           5130        branch64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "branch_output_1 (Dense)         (None, 10)           5130        branch64_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "branch_output_2 (Dense)         (None, 10)           5130        branch64_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "targets (InputLayer)            [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "classification (Dense)          (None, 10)           5130        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "branch_softmax (Softmax)        (None, 10)           0           branch_output[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "branch_softmax_1 (Softmax)      (None, 10)           0           branch_output_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "branch_softmax_2 (Softmax)      (None, 10)           0           branch_output_2[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 487,429,960\n",
      "Trainable params: 487,395,528\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "customOption: Other\n",
      "https://app.neptune.ai/cailen01/branchingDNN/e/BRAN-338\n",
      "Remember to stop your run once youve finished logging your metadata (https://docs.neptune.ai/api-reference/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n",
      "Epoch 1/12\n",
      "1406/1406 [==============================] - 537s 368ms/step - loss: 11.0903 - classification_loss: 2.1802 - branch_softmax_loss: 3.1945 - branch_softmax_1_loss: 3.1898 - branch_softmax_2_loss: 2.5258 - classification_accuracy: 0.9890 - branch_softmax_accuracy: 0.0963 - branch_softmax_1_accuracy: 0.1010 - branch_softmax_2_accuracy: 0.6927 - val_loss: 10.8150 - val_classification_loss: 2.1664 - val_branch_softmax_loss: 3.1897 - val_branch_softmax_1_loss: 3.1867 - val_branch_softmax_2_loss: 2.2722 - val_classification_accuracy: 0.9974 - val_branch_softmax_accuracy: 0.1012 - val_branch_softmax_1_accuracy: 0.1038 - val_branch_softmax_2_accuracy: 0.9050\n",
      "\n",
      "Epoch 00001: saving model to models\\inception_entropy_flat.hdf5\n",
      "Epoch 2/12\n",
      "1406/1406 [==============================] - 538s 372ms/step - loss: 10.8050 - classification_loss: 2.1718 - branch_softmax_loss: 3.1933 - branch_softmax_1_loss: 3.1909 - branch_softmax_2_loss: 2.2490 - classification_accuracy: 0.9937 - branch_softmax_accuracy: 0.0980 - branch_softmax_1_accuracy: 0.1001 - branch_softmax_2_accuracy: 0.9292 - val_loss: 10.7806 - val_classification_loss: 2.1670 - val_branch_softmax_loss: 3.1897 - val_branch_softmax_1_loss: 3.1867 - val_branch_softmax_2_loss: 2.2372 - val_classification_accuracy: 0.9968 - val_branch_softmax_accuracy: 0.1012 - val_branch_softmax_1_accuracy: 0.1038 - val_branch_softmax_2_accuracy: 0.9373\n",
      "\n",
      "Epoch 00002: saving model to models\\inception_entropy_flat.hdf5\n",
      "Epoch 3/12\n",
      "1406/1406 [==============================] - 535s 371ms/step - loss: 10.7657 - classification_loss: 2.1687 - branch_softmax_loss: 3.1896 - branch_softmax_1_loss: 3.1933 - branch_softmax_2_loss: 2.2141 - classification_accuracy: 0.9950 - branch_softmax_accuracy: 0.1012 - branch_softmax_1_accuracy: 0.0980 - branch_softmax_2_accuracy: 0.9567 - val_loss: 10.7854 - val_classification_loss: 2.1672 - val_branch_softmax_loss: 3.1897 - val_branch_softmax_1_loss: 3.1867 - val_branch_softmax_2_loss: 2.2418 - val_classification_accuracy: 0.9960 - val_branch_softmax_accuracy: 0.1012 - val_branch_softmax_1_accuracy: 0.1038 - val_branch_softmax_2_accuracy: 0.9317\n",
      "\n",
      "Epoch 00003: saving model to models\\inception_entropy_flat.hdf5\n",
      "Epoch 4/12\n",
      "1406/1406 [==============================] - 533s 370ms/step - loss: 10.7432 - classification_loss: 2.1664 - branch_softmax_loss: 3.1909 - branch_softmax_1_loss: 3.1918 - branch_softmax_2_loss: 2.1941 - classification_accuracy: 0.9969 - branch_softmax_accuracy: 0.1001 - branch_softmax_1_accuracy: 0.0994 - branch_softmax_2_accuracy: 0.9740 - val_loss: 10.7771 - val_classification_loss: 2.1667 - val_branch_softmax_loss: 3.1897 - val_branch_softmax_1_loss: 3.1867 - val_branch_softmax_2_loss: 2.2340 - val_classification_accuracy: 0.9966 - val_branch_softmax_accuracy: 0.1012 - val_branch_softmax_1_accuracy: 0.1038 - val_branch_softmax_2_accuracy: 0.9391\n",
      "\n",
      "Epoch 00004: saving model to models\\inception_entropy_flat.hdf5\n",
      "Epoch 5/12\n",
      "1406/1406 [==============================] - 533s 370ms/step - loss: 10.7349 - classification_loss: 2.1649 - branch_softmax_loss: 3.1917 - branch_softmax_1_loss: 3.1933 - branch_softmax_2_loss: 2.1850 - classification_accuracy: 0.9978 - branch_softmax_accuracy: 0.0994 - branch_softmax_1_accuracy: 0.0981 - branch_softmax_2_accuracy: 0.9822 - val_loss: 10.7725 - val_classification_loss: 2.1672 - val_branch_softmax_loss: 3.1897 - val_branch_softmax_1_loss: 3.1867 - val_branch_softmax_2_loss: 2.2289 - val_classification_accuracy: 0.9958 - val_branch_softmax_accuracy: 0.1012 - val_branch_softmax_1_accuracy: 0.1038 - val_branch_softmax_2_accuracy: 0.9431\n",
      "\n",
      "Epoch 00005: saving model to models\\inception_entropy_flat.hdf5\n",
      "Epoch 6/12\n",
      "1406/1406 [==============================] - 536s 371ms/step - loss: 10.7252 - classification_loss: 2.1642 - branch_softmax_loss: 3.1906 - branch_softmax_1_loss: 3.1912 - branch_softmax_2_loss: 2.1791 - classification_accuracy: 0.9982 - branch_softmax_accuracy: 0.1004 - branch_softmax_1_accuracy: 0.0998 - branch_softmax_2_accuracy: 0.9861 - val_loss: 10.7709 - val_classification_loss: 2.1658 - val_branch_softmax_loss: 3.1897 - val_branch_softmax_1_loss: 3.1867 - val_branch_softmax_2_loss: 2.2286 - val_classification_accuracy: 0.9966 - val_branch_softmax_accuracy: 0.1012 - val_branch_softmax_1_accuracy: 0.1038 - val_branch_softmax_2_accuracy: 0.9437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00006: saving model to models\\inception_entropy_flat.hdf5\n",
      "Epoch 7/12\n",
      "1406/1406 [==============================] - 538s 373ms/step - loss: 10.7202 - classification_loss: 2.1635 - branch_softmax_loss: 3.1918 - branch_softmax_1_loss: 3.1910 - branch_softmax_2_loss: 2.1740 - classification_accuracy: 0.9988 - branch_softmax_accuracy: 0.0994 - branch_softmax_1_accuracy: 0.1000 - branch_softmax_2_accuracy: 0.9905 - val_loss: 10.7615 - val_classification_loss: 2.1657 - val_branch_softmax_loss: 3.1897 - val_branch_softmax_1_loss: 3.1867 - val_branch_softmax_2_loss: 2.2194 - val_classification_accuracy: 0.9966 - val_branch_softmax_accuracy: 0.1012 - val_branch_softmax_1_accuracy: 0.1038 - val_branch_softmax_2_accuracy: 0.9503\n",
      "\n",
      "Epoch 00007: saving model to models\\inception_entropy_flat.hdf5\n",
      "Epoch 8/12\n",
      "1406/1406 [==============================] - 540s 374ms/step - loss: 10.7181 - classification_loss: 2.1632 - branch_softmax_loss: 3.1916 - branch_softmax_1_loss: 3.1926 - branch_softmax_2_loss: 2.1708 - classification_accuracy: 0.9987 - branch_softmax_accuracy: 0.0995 - branch_softmax_1_accuracy: 0.0987 - branch_softmax_2_accuracy: 0.9929 - val_loss: 10.7632 - val_classification_loss: 2.1664 - val_branch_softmax_loss: 3.1897 - val_branch_softmax_1_loss: 3.1867 - val_branch_softmax_2_loss: 2.2203 - val_classification_accuracy: 0.9964 - val_branch_softmax_accuracy: 0.1012 - val_branch_softmax_1_accuracy: 0.1038 - val_branch_softmax_2_accuracy: 0.9501\n",
      "\n",
      "Epoch 00008: saving model to models\\inception_entropy_flat.hdf5\n",
      "Epoch 9/12\n",
      "1406/1406 [==============================] - 539s 374ms/step - loss: 10.7157 - classification_loss: 2.1630 - branch_softmax_loss: 3.1924 - branch_softmax_1_loss: 3.1906 - branch_softmax_2_loss: 2.1698 - classification_accuracy: 0.9989 - branch_softmax_accuracy: 0.0988 - branch_softmax_1_accuracy: 0.1004 - branch_softmax_2_accuracy: 0.9936 - val_loss: 10.7599 - val_classification_loss: 2.1661 - val_branch_softmax_loss: 3.1897 - val_branch_softmax_1_loss: 3.1867 - val_branch_softmax_2_loss: 2.2174 - val_classification_accuracy: 0.9968 - val_branch_softmax_accuracy: 0.1012 - val_branch_softmax_1_accuracy: 0.1038 - val_branch_softmax_2_accuracy: 0.9523\n",
      "\n",
      "Epoch 00009: saving model to models\\inception_entropy_flat.hdf5\n",
      "Epoch 10/12\n",
      "1406/1406 [==============================] - 542s 376ms/step - loss: 10.7142 - classification_loss: 2.1634 - branch_softmax_loss: 3.1894 - branch_softmax_1_loss: 3.1920 - branch_softmax_2_loss: 2.1694 - classification_accuracy: 0.9984 - branch_softmax_accuracy: 0.1014 - branch_softmax_1_accuracy: 0.0991 - branch_softmax_2_accuracy: 0.9936 - val_loss: 10.7615 - val_classification_loss: 2.1669 - val_branch_softmax_loss: 3.1897 - val_branch_softmax_1_loss: 3.1867 - val_branch_softmax_2_loss: 2.2181 - val_classification_accuracy: 0.9954 - val_branch_softmax_accuracy: 0.1012 - val_branch_softmax_1_accuracy: 0.1038 - val_branch_softmax_2_accuracy: 0.9507\n",
      "\n",
      "Epoch 00010: saving model to models\\inception_entropy_flat.hdf5\n",
      "Epoch 11/12\n",
      "1406/1406 [==============================] - 564s 391ms/step - loss: 10.7130 - classification_loss: 2.1625 - branch_softmax_loss: 3.1914 - branch_softmax_1_loss: 3.1909 - branch_softmax_2_loss: 2.1682 - classification_accuracy: 0.9994 - branch_softmax_accuracy: 0.0997 - branch_softmax_1_accuracy: 0.1001 - branch_softmax_2_accuracy: 0.9944 - val_loss: 10.7588 - val_classification_loss: 2.1670 - val_branch_softmax_loss: 3.1897 - val_branch_softmax_1_loss: 3.1867 - val_branch_softmax_2_loss: 2.2154 - val_classification_accuracy: 0.9952 - val_branch_softmax_accuracy: 0.1012 - val_branch_softmax_1_accuracy: 0.1038 - val_branch_softmax_2_accuracy: 0.9537\n",
      "\n",
      "Epoch 00011: saving model to models\\inception_entropy_flat.hdf5\n",
      "Epoch 12/12\n",
      "1406/1406 [==============================] - 574s 398ms/step - loss: 10.7121 - classification_loss: 2.1624 - branch_softmax_loss: 3.1915 - branch_softmax_1_loss: 3.1906 - branch_softmax_2_loss: 2.1677 - classification_accuracy: 0.9993 - branch_softmax_accuracy: 0.0996 - branch_softmax_1_accuracy: 0.1004 - branch_softmax_2_accuracy: 0.9949 - val_loss: 10.7578 - val_classification_loss: 2.1666 - val_branch_softmax_loss: 3.1897 - val_branch_softmax_1_loss: 3.1867 - val_branch_softmax_2_loss: 2.2149 - val_classification_accuracy: 0.9958 - val_branch_softmax_accuracy: 0.1012 - val_branch_softmax_1_accuracy: 0.1038 - val_branch_softmax_2_accuracy: 0.9543\n",
      "\n",
      "Epoch 00012: saving model to models\\inception_entropy_flat.hdf5\n",
      "<tensorflow.python.keras.callbacks.History object at 0x00000141A1DA2470>\n",
      "312/312 - 38s - loss: 10.8198 - classification_loss: 2.2003 - branch_softmax_loss: 3.1911 - branch_softmax_1_loss: 3.1908 - branch_softmax_2_loss: 2.2376 - classification_accuracy: 0.9666 - branch_softmax_accuracy: 0.1000 - branch_softmax_1_accuracy: 0.1002 - branch_softmax_2_accuracy: 0.9333\n",
      "overall loss: 10.819804191589355\n"
     ]
    }
   ],
   "source": [
    "model = brevis.trainTransfer(12, loss=loss_fn, optimizer=tf.optimizers.SGD(), transfer=False, customOptions=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = tf.keras.models.load_model('models/resNet_evidence_conv2d.hdf5', custom_objects={\"CrossEntropyEndpoint\":CrossEntropyEndpoint,\"cross_entropy_evidence\":loss_function()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00083896]0 of 10000\n",
      "[7.151839e-11]\n",
      "[2.0296731e-07]\n",
      "[8.259097e-06]\n",
      "[3.3166983e-05]f 10000\n",
      "[1.8667558e-10]\n",
      "[6.529984e-07]\n",
      "[1.7076405e-07]\n",
      "[0.0046518] 2 of 10000\n",
      "[3.0780214e-10]\n",
      "[1.3892072e-06]\n",
      "[0.00113143]\n",
      "[8.713578e-06]of 10000\n",
      "[2.1461434e-10]\n",
      "[2.3392245e-06]\n",
      "[0.0025667]\n",
      "[1.0987212e-05]f 10000\n",
      "[2.328939e-10]\n",
      "[2.4208194e-07]\n",
      "[1.8940967e-10]\n",
      "[1.421237e-05]of 10000\n",
      "[4.35895e-11]\n",
      "[6.988656e-08]\n",
      "[1.4752194e-08]\n",
      "[0.00679772]6 of 10000\n",
      "[1.2298647e-10]\n",
      "[9.103585e-08]\n",
      "[0.04800895]\n",
      "[0.000107]: 7 of 10000\n",
      "[2.1143362e-10]\n",
      "[8.265552e-07]\n",
      "[8.717765e-09]\n",
      "[3.991278e-05]of 10000\n",
      "[1.3871476e-10]\n",
      "[1.3303542e-06]\n",
      "[1.9958297e-06]\n",
      "[0.00191137]9 of 10000\n",
      "[7.5639134e-11]\n",
      "[1.0618908e-06]\n",
      "[0.00170626]\n",
      "[9.620666e-06] of 10000\n",
      "[7.12661e-11]\n",
      "[7.5594344e-06]\n",
      "[9.352855e-08]\n"
     ]
    }
   ],
   "source": [
    "evidence=False\n",
    "num_outputs=4\n",
    "predictions = []\n",
    "labels = []\n",
    "pClass = []\n",
    "predictions=[]\n",
    "pEvidence = []\n",
    "pUncertainty=[]\n",
    "pOverlap=[]\n",
    "\n",
    "Outputs = pd.DataFrame()\n",
    "pAcc=[]\n",
    "for i in range(num_outputs):\n",
    "    pClass.append([])\n",
    "    predictions.append([])\n",
    "    pEvidence.append([])\n",
    "    pUncertainty.append([])\n",
    "    pAcc.append([])\n",
    "    pOverlap.append([])\n",
    "    # pOutputs.append([])\n",
    "for i, (x,y) in enumerate(test_ds):\n",
    "        if i > 10:\n",
    "            break\n",
    "        print(\"prediction: {} of {}\".format(i,len(test_ds)),end='\\r')\n",
    "        if evidence: \n",
    "            result = model.model.test_on_batch(x,y)\n",
    "#             print(result)\n",
    "            for j in range(num_outputs):\n",
    "#                 print(\"output\",j)\n",
    "                pClass[j].append(tf.argmax(y[0]).numpy())\n",
    "#                 print(\"class\",pClass[j][i])\n",
    "                pAcc[j].append(result[j+(num_outputs+1)])  \n",
    "#                 print(\"acc\",pAcc[j][i])\n",
    "                if j ==0:\n",
    "                    pEvidence[j].append(0)\n",
    "                else:\n",
    "#                     print(\"evid Number\",((num_outputs * 2)+1), \" \", ((j-1)*3))\n",
    "                    pEvidence[j].append(result[((num_outputs * 2) + 1)+((j-1)*3)])\n",
    "#                 print(\"evid\",pEvidence[j][i])\n",
    "\n",
    "                pOverlap[j].append(pAcc[0][i] - pAcc[j][i])\n",
    "#                 print(\"overlap\",pOverlap[j][i])\n",
    "        else:\n",
    "            result = model.model.predict(x)[0]\n",
    "#             print(result)\n",
    "\n",
    "            for j in range(num_outputs):\n",
    "                pClass[j].append(tf.argmax(y[0]).numpy())\n",
    "                # print(pClass[j])\n",
    "                # print(result)\n",
    "                prediction = np.argmax(result[j])\n",
    "                if prediction == pClass[j][i]:\n",
    "                    pAcc[j].append(1)  \n",
    "                else:\n",
    "                    pAcc[j].append(0)  \n",
    "                print(branching.utils.calcEntropy_Tensors(result[j]).numpy())\n",
    "                pEvidence[j].append(branching.utils.calcEntropy_Tensors(result[j]).numpy()[0])\n",
    "\n",
    "                pOverlap[j].append(pAcc[0][i] - pAcc[j][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectEvidence_branches(model,test_ds, evidence=True):\n",
    "    num_outputs = len(model.outputs) # the number of output layers for the purpose of providing labels\n",
    "    print(\"outputs\",num_outputs)\n",
    "#     train_ds, test_ds, validation_ds = (dataset)\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    pClass = []\n",
    "    predictions=[]\n",
    "    pEvidence = []\n",
    "    pUncertainty=[]\n",
    "    pOverlap=[]\n",
    "\n",
    "    Outputs = pd.DataFrame()\n",
    "    pAcc=[]\n",
    "    for i in range(num_outputs):\n",
    "        pClass.append([])\n",
    "        predictions.append([])\n",
    "        pEvidence.append([])\n",
    "        pUncertainty.append([])\n",
    "        pAcc.append([])\n",
    "        pOverlap.append([])\n",
    "        # pOutputs.append([])\n",
    "\n",
    "    for i, (x,y) in enumerate(test_ds):\n",
    "        # if i > 10:\n",
    "            # break\n",
    "        print(\"prediction: {} of {}\".format(i,len(test_ds)),end='\\r')\n",
    "        if evidence: \n",
    "            result = model.test_on_batch(x,y)\n",
    "#             print(result)\n",
    "            for j in range(num_outputs):\n",
    "#                 print(\"output\",j)\n",
    "                pClass[j].append(tf.argmax(y[0]).numpy())\n",
    "#                 print(\"class\",pClass[j][i])\n",
    "                pAcc[j].append(result[j+(num_outputs+1)])  \n",
    "#                 print(\"acc\",pAcc[j][i])\n",
    "                if j ==0:\n",
    "                    pEvidence[j].append(0)\n",
    "                else:\n",
    "#                     print(\"evid Number\",((num_outputs * 2)+1), \" \", ((j-1)*3))\n",
    "                    pEvidence[j].append(result[((num_outputs * 2) + 1)+((j-1)*3)])\n",
    "#                 print(\"evid\",pEvidence[j][i])\n",
    "\n",
    "                pOverlap[j].append(pAcc[0][i] - pAcc[j][i])\n",
    "#                 print(\"overlap\",pOverlap[j][i])\n",
    "        else:\n",
    "            result = model.predict(x)[0]\n",
    "            # print(result)\n",
    "\n",
    "            for j in range(num_outputs):\n",
    "                pClass[j].append(tf.argmax(y[0]).numpy())\n",
    "                # print(pClass[j])\n",
    "                # print(result)\n",
    "                prediction = np.argmax(result[j])\n",
    "                if prediction == pClass[j][i]:\n",
    "                    pAcc[j].append(1)  \n",
    "                else:\n",
    "                    pAcc[j].append(0)  \n",
    "                # print(branching.utils.calcEntropy_Tensors(result[j]).numpy())\n",
    "                pEvidence[j].append(branching.utils.calcEntropy_Tensors(result[j]).numpy()[0])\n",
    "\n",
    "                pOverlap[j].append(pAcc[0][i] - pAcc[j][i])\n",
    "        '''\n",
    "        overlap\n",
    "        if zero, both match, if else they don't match\n",
    "        TT 1-1 =0\n",
    "        TF 1-0 =1\n",
    "\n",
    "        FT 0-1 = -1\n",
    "        FF 0-0 =0\n",
    "        \n",
    "        '''\n",
    "    Outputs=[]\n",
    "    for j in range(num_outputs):\n",
    "        Predictions = pd.DataFrame({\"label\":pClass[j],\"evidence\":pEvidence[j],\"Acc\":pAcc[j], \"overlap\":pOverlap[j]})\n",
    "        Outputs.append(Predictions)\n",
    "    return Outputs\n",
    "\n",
    "def displayEvidence(branch_predictions, output_names=[\"main_exit\",\"branch_1\",\"branch_2\",\"branch_3\"], Evidence = True):\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "    fig = plt.figure()\n",
    "    series=[]\n",
    "    fig, axs = plt.subplots(2, 2)\n",
    "    fig.tight_layout()\n",
    "    Outputs=pd.DataFrame()\n",
    "    for i, Predictions in enumerate(branch_predictions):\n",
    "        Predictions[\"Acc\"]=Predictions[\"Acc\"].astype('bool') ##sometime the predictions can come back with 0.5 acc, this should be rounded to 1.\n",
    "        # Predictions[\"evidence\"]=Predictions[\"evidence\"].()[0]\n",
    "        acc = Predictions[\"Acc\"].value_counts()\n",
    "        # print(acc)\n",
    "        # print((acc.loc[True] , acc.loc[False]))\n",
    "        mean = Predictions.loc[(Predictions['Acc'] == False)].groupby(\"Acc\")[\"evidence\"].mean().iloc[0]\n",
    "        std = Predictions.loc[(Predictions['Acc'] == False)].groupby(\"Acc\")[\"evidence\"].std().iloc[0]\n",
    "        \n",
    "        correct_rows = Predictions.loc[Predictions['Acc'] == True]\n",
    "        incorrect_rows = Predictions.loc[Predictions['Acc'] == False]\n",
    "        if Evidence:\n",
    "            E_threshold = mean + std\n",
    "            Incorrects_overlap = Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"evidence\"] > E_threshold) & (Predictions[\"overlap\"] == 0)].count().iloc[0]\n",
    "            Outputs = Outputs.append(pd.DataFrame({\"Branch Name\":output_names[i],\n",
    "                    \"Accuracy\":(acc.loc[True] /  (acc.loc[True] + acc.loc[False])),\n",
    "                    \"E_Threshold\":E_threshold,\n",
    "                    # \"Overlap_Threshold\":non_overlapping_incorrects_threshold,\n",
    "                    \"acceptance_rate\":Predictions.loc[(Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0]/(Predictions.count().iloc[0]),\n",
    "                    \"accepted_correct\":Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                    \"accepted_incorrect\":Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                    \"accepted_accuracy\":(Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0])/ Predictions.loc[(Predictions[\"evidence\"] > E_threshold)].count()[0],\n",
    "                    \"overlap_adjusted_accuracy\":(Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0] + Incorrects_overlap) / Predictions.loc[(Predictions[\"evidence\"] > E_threshold)].count()[0],\n",
    "                    \"rejected_correct\":Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                    \"rejected_incorrect\":Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                    \"Incorrects_overlap\":Incorrects_overlap,\n",
    "                    },index=[i]))\n",
    "        else:\n",
    "            print(\"mean\",mean , \" std\",std)\n",
    "            E_threshold = mean - std\n",
    "            Incorrects_overlap = Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"evidence\"] < E_threshold) & (Predictions[\"overlap\"] == 0)].count().iloc[0]\n",
    "            # if i ==1 or i == 0 :\n",
    "                # print(Predictions)\n",
    "                # print(Predictions.loc[ (Predictions['Acc'] == True)  & (Predictions[\"overlap\"] == 0) ])\n",
    "            # print(Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] < E_threshold) ].count())\n",
    "            Outputs = Outputs.append(pd.DataFrame({\"Branch Name\":output_names[i],\n",
    "                    \"Accuracy\":(acc.loc[True] /  (acc.loc[True] + acc.loc[False])),\n",
    "                    \"E_Threshold\":E_threshold,\n",
    "                    # \"Overlap_Threshold\":non_overlapping_incorrects_threshold,\n",
    "                    \"acceptance_rate\":Predictions.loc[(Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0]/(Predictions.count().iloc[0]),\n",
    "                    \"accepted_correct\":Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                    \"accepted_incorrect\":Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                    \"accepted_accuracy\":(Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0])/ Predictions.loc[(Predictions[\"evidence\"] < E_threshold)].count()[0],\n",
    "                    \"overlap_adjusted_accuracy\":(Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0] + Incorrects_overlap) / Predictions.loc[(Predictions[\"evidence\"] < E_threshold)].count()[0],\n",
    "                    \"rejected_correct\":Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                    \"rejected_incorrect\":Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                    \"Incorrects_overlap\":Incorrects_overlap,\n",
    "                    },index=[i]))\n",
    "        axs[round(int(i/2)), round(i%2)]\n",
    "    # fig, axs = plt.subplots(1, 2)\n",
    "        # axs[round(int(i/2)), round(i%2)].suptitle('Horizontally stacked subplots')\n",
    "        axs[round(int(i/2)), round(i%2)].scatter(correct_rows['label'],correct_rows['evidence'],c ='r',marker='+')\n",
    "        axs[round(int(i/2)), round(i%2)].scatter(incorrect_rows['label']+.3,incorrect_rows['evidence'],c ='k',marker='x')\n",
    "        axs[round(int(i/2)), round(i%2)].plot(np.repeat(E_threshold,11),'b--')\n",
    "        axs[round(int(i/2)), round(i%2)].title.set_text(\"evidence\")\n",
    "    \n",
    "    for ax in fig.axes:\n",
    "            # ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "            axLine, axLabel = ax.get_legend_handles_labels()\n",
    "            lines=(axLine)\n",
    "            labels=(axLabel)\n",
    "    fig.text(0.5, 0.01, 'Items Exit at Branch', ha='center', va='center')\n",
    "    fig.text(0.01, 0.5, 'Accuracy %', ha='center', va='center', rotation='vertical')\n",
    "    # fig.legend(lines, labels,bbox_to_anchor=(1., 1), loc=2,borderaxespad=0.,frameon=True)\n",
    "    # fig.set_size_inches(10, 10)\n",
    "    plt.show()\n",
    "    return Outputs\n",
    "\n",
    "\n",
    "def evidenceHistogram(branch_predictions, output_names=[\"main_exit\",\"branch_1\",\"branch_2\",\"branch_3\"], Evidence = True):\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "    fig = plt.figure()\n",
    "    series=[]\n",
    "    fig, axs = plt.subplots(2, 2)\n",
    "    fig.tight_layout()\n",
    "    Outputs=pd.DataFrame()\n",
    "    for i, Predictions in enumerate(branch_predictions):\n",
    "        Predictions[\"Acc\"]=Predictions[\"Acc\"].astype('bool')\n",
    "        # Predictions[\"evidence\"]=Predictions[\"evidence\"].()[0]\n",
    "        acc = Predictions[\"Acc\"].value_counts()\n",
    "        # print(acc)\n",
    "        # print((acc.loc[True] , acc.loc[False]))\n",
    "        mean = Predictions.loc[(Predictions['Acc'] == False)].groupby(\"Acc\")[\"evidence\"].mean().iloc[0]\n",
    "        std = Predictions.loc[(Predictions['Acc'] == False)].groupby(\"Acc\")[\"evidence\"].std().iloc[0]\n",
    "        \n",
    "        correct_rows = Predictions.loc[Predictions['Acc'] == True]\n",
    "        incorrect_rows = Predictions.loc[Predictions['Acc'] == False]\n",
    "        if Evidence:\n",
    "            # E_threshold = mean + std + einsumfunc\n",
    "\n",
    "            Accepted = Predictions.loc[(Predictions[\"evidence\"] <= E_threshold)]\n",
    "            Rejected = Predictions.loc[(Predictions[\"evidence\"] > E_threshold)]\n",
    "            Incorrects_overlap = Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"evidence\"] > E_threshold) & (Predictions[\"overlap\"] == 0)].count().iloc[0]\n",
    "            Outputs = Outputs.append(pd.DataFrame({\"Branch Name\":output_names[i],\n",
    "                    \"Accuracy\":(acc.loc[True] /  (acc.loc[True] + acc.loc[False])),\n",
    "                    \"E_Threshold\":E_threshold,\n",
    "                    # \"Overlap_Threshold\":non_overlapping_incorrects_threshold,\n",
    "                    \"acceptance_rate\":Predictions.loc[(Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0]/(Predictions.count().iloc[0]),\n",
    "                    \"accepted_correct\":Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                    \"accepted_incorrect\":Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                    \"accepted_accuracy\":(Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0])/ Predictions.loc[(Predictions[\"evidence\"] > E_threshold)].count()[0],\n",
    "                    \"overlap_adjusted_accuracy\":(Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0] + Incorrects_overlap) / Predictions.loc[(Predictions[\"evidence\"] > E_threshold)].count()[0],\n",
    "                    \"T_F\":Accepted.loc[Accepted['overlap']==1],\n",
    "                    \"F_T\":Accepted.loc[Accepted['overlap']==-1],\n",
    "                    \"Incorrects_overlap\":Incorrects_overlap,\n",
    "                    },index=[i]))\n",
    "        else:\n",
    "            print(\"mean\",mean , \" std\",std)\n",
    "            E_threshold = mean - std\n",
    "            Incorrects_overlap = Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"evidence\"] < E_threshold) & (Predictions[\"overlap\"] == 0)].count().iloc[0]\n",
    "            # if i ==1 or i == 0 :\n",
    "                # print(Predictions)\n",
    "                # print(Predictions.loc[ (Predictions['Acc'] == True)  & (Predictions[\"overlap\"] == 0) ])\n",
    "            # print(Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] < E_threshold) ].count())\n",
    "           \n",
    "            Outputs = Outputs.append(pd.DataFrame({\"Branch Name\":output_names[i],\n",
    "                    \"Accuracy\":(acc.loc[True] /  (acc.loc[True] + acc.loc[False])),\n",
    "                    \"E_Threshold\":E_threshold,\n",
    "                    # \"Overlap_Threshold\":non_overlapping_incorrects_threshold,\n",
    "                    \"acceptance_rate\":Predictions.loc[(Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0]/(Predictions.count().iloc[0]),\n",
    "                    \"accepted_correct\":Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                    \"accepted_incorrect\":Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                    \"accepted_accuracy\":(Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0])/ Predictions.loc[(Predictions[\"evidence\"] < E_threshold)].count()[0],\n",
    "                    \"overlap_adjusted_accuracy\":(Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0] + Incorrects_overlap) / Predictions.loc[(Predictions[\"evidence\"] < E_threshold)].count()[0],\n",
    "                    \"rejected_correct\":Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                    \"rejected_incorrect\":Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                    \"Incorrects_overlap\":Incorrects_overlap,\n",
    "                    },index=[i]))\n",
    "        axs[round(int(i/2)), round(i%2)]\n",
    "    # fig, axs = plt.subplots(1, 2)\n",
    "        # axs[round(int(i/2)), round(i%2)].suptitle('Horizontally stacked subplots')\n",
    "        axs[round(int(i/2)), round(i%2)].scatter(correct_rows['label'],correct_rows['evidence'],c ='r',marker='+')\n",
    "        axs[round(int(i/2)), round(i%2)].scatter(incorrect_rows['label']+.3,incorrect_rows['evidence'],c ='k',marker='x')\n",
    "        axs[round(int(i/2)), round(i%2)].plot(np.repeat(E_threshold,11),'b--')\n",
    "        axs[round(int(i/2)), round(i%2)].title.set_text(\"evidence\")\n",
    "    \n",
    "    for ax in fig.axes:\n",
    "            # ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "            axLine, axLabel = ax.get_legend_handles_labels()\n",
    "            lines=(axLine)\n",
    "            labels=(axLabel)\n",
    "    fig.text(0.5, 0.01, 'Items Exit at Branch', ha='center', va='center')\n",
    "    fig.text(0.01, 0.5, 'Accuracy %', ha='center', va='center', rotation='vertical')\n",
    "    # fig.legend(lines, labels,bbox_to_anchor=(1., 1), loc=2,borderaxespad=0.,frameon=True)\n",
    "    # fig.set_size_inches(10, 10)\n",
    "    plt.show()\n",
    "    return Outputs\n",
    "\n",
    "def displayEvidence_cascade(branch_predictions, thresholds=None, output_names=[\"branch_1\",\"branch_2\",\"branch_3\",\"Main_Exit\"], Evidence = True):\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "    fig = plt.figure()\n",
    "    series=[]\n",
    "    fig, axs = plt.subplots(2, 2)\n",
    "    fig.tight_layout()\n",
    "    Outputs=pd.DataFrame()\n",
    "    #lets reorder the predictions so that the final layer is at the end\n",
    "    # _branch_predictions.copy()\n",
    "    _branch_predictions = branch_predictions.copy()\n",
    "    # print(_branch_predictions)\n",
    "    _branch_predictions.append(_branch_predictions.pop(0))\n",
    "    # print(_branch_predictions)\n",
    "    rollOver_indices = pd.Index([])\n",
    "    for i, Predictions in enumerate(_branch_predictions):\n",
    "        #check if rollover is active, if so, select only the predictions whose indexes match the rollover list\n",
    "        # print(rollOver_indices)\n",
    "        test_acc = Predictions[\"Acc\"].astype('bool').value_counts()\n",
    "        test_accuracy = (test_acc.loc[True] /  (test_acc.loc[True] + test_acc.loc[False]))\n",
    "        if len(rollOver_indices)>0:\n",
    "            print(\"rollover enabled, {} predictions provided\".format(len(rollOver_indices)))\n",
    "            Predictions = Predictions.iloc[rollOver_indices]\n",
    "        # print(Predictions.shape)\n",
    "        Predictions[\"Acc\"]=Predictions[\"Acc\"].astype('bool')\n",
    "        # Predictions[\"evidence\"]=Predictions[\"evidence\"].()[0]\n",
    "        acc = Predictions[\"Acc\"].value_counts()\n",
    "        # print(acc)\n",
    "        # print((acc.loc[True] , acc.loc[False]))\n",
    "        _Incorrects_missed = Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"overlap\"] == 1)] #all the predictions that the main exit got true and the branch got wrong\n",
    "        if len(_Incorrects_missed) > 0 :\n",
    "            mean = _Incorrects_missed.groupby(\"Acc\")[\"evidence\"].mean().iloc[0]\n",
    "            std = _Incorrects_missed.groupby(\"Acc\")[\"evidence\"].std().iloc[0]\n",
    "        else:\n",
    "            mean = Predictions.loc[(Predictions['Acc'] == False)].groupby(\"Acc\")[\"evidence\"].mean().iloc[0]\n",
    "            std = Predictions.loc[(Predictions['Acc'] == False)].groupby(\"Acc\")[\"evidence\"].std().iloc[0]\n",
    "\n",
    "        print(\"mean\",mean , \" std\",std)\n",
    "        \n",
    "        correct_rows = Predictions.loc[Predictions['Acc'] == True]\n",
    "        incorrect_rows = Predictions.loc[Predictions['Acc'] == False]\n",
    "        \n",
    "        E_threshold = -1 #-1 is null for threshold\n",
    "        if thresholds is not None:\n",
    "            try:\n",
    "                E_threshold = thresholds[i]\n",
    "            except:\n",
    "                print(\"threshold not supplied for branch {}, using test data\".format(i))\n",
    "                \n",
    "        if Evidence:\n",
    "            if E_threshold ==-1:\n",
    "                E_threshold = mean + std\n",
    "            Accepted = Predictions.loc[(Predictions[\"evidence\"] >= E_threshold)]\n",
    "            Rejected = Predictions.loc[(Predictions[\"evidence\"] < E_threshold)]\n",
    "        else: \n",
    "            if E_threshold ==-1:\n",
    "                E_threshold = mean - std\n",
    "            Accepted = Predictions.loc[(Predictions[\"evidence\"] <= E_threshold)]\n",
    "            Rejected = Predictions.loc[(Predictions[\"evidence\"] > E_threshold)]\n",
    "        \n",
    "        rollOver_indices = Rejected.index\n",
    "        Incorrects_overlap = Accepted.loc[(Accepted['Acc'] == False) & (Accepted[\"overlap\"] == 0)].count().iloc[0]\n",
    "        Outputs = Outputs.append(pd.DataFrame({\"Branch Name\":output_names[i],\n",
    "                \"Predictions\": len(Predictions.index),\n",
    "                \"test_accuracy\": test_accuracy,\n",
    "                \"Accuracy\":(acc.loc[True] /  (acc.loc[True] + acc.loc[False])),\n",
    "                \"E_Threshold\":E_threshold,\n",
    "                # \"Overlap_Threshold\":non_overlapping_incorrects_threshold,\n",
    "                \"acceptance_rate\":Accepted.shape[0]/(Predictions.shape[0]),\n",
    "                \"accepted_correct\":Accepted.loc[(Predictions['Acc'] == True)].shape[0],\n",
    "                \"accepted_incorrect\":Accepted.loc[(Predictions['Acc'] == False)].shape[0],\n",
    "                \"accepted_accuracy\":(Accepted.loc[(Accepted['Acc'] == True)].shape[0])/ Accepted.shape[0],\n",
    "                \"overlap_adjusted_accuracy\":(Accepted.loc[(Accepted['Acc'] == True)].count()[0] + Incorrects_overlap) / Predictions.loc[(Predictions[\"evidence\"] >E_threshold)].count()[0],\n",
    "                \"M(T) B(F)\":Accepted.loc[(Accepted[\"overlap\"] == 1)].count().iloc[0],\n",
    "                \"M(F) B(T)\":Accepted.loc[(Accepted[\"overlap\"] ==-1)].count().iloc[0],\n",
    "                \"M(F) B(F) overlap\":Incorrects_overlap,\n",
    "                },index=[i]))\n",
    "#         print(\"TT\",Accepted.loc[(Accepted[\"Acc\"] ==True) & (Accepted[\"overlap\"] == 0)])\n",
    "#         print(\"TF\",Accepted.loc[(Accepted[\"overlap\"] == 1)])\n",
    "#         print(\"FT\",Accepted.loc[(Accepted[\"overlap\"] == -1)])\n",
    "#         print(\"FF\",Accepted.loc[(Accepted[\"Acc\"] ==False) & (Accepted[\"overlap\"] == 0)])\n",
    "        axs[round(int(i/2)), round(i%2)]\n",
    "    # fig, axs = plt.subplots(1, 2)\n",
    "        # axs[round(int(i/2)), round(i%2)].suptitle('Horizontally stacked subplots')\n",
    "        axs[round(int(i/2)), round(i%2)].scatter(correct_rows['label'],correct_rows['evidence'],c ='r',marker='+')\n",
    "        axs[round(int(i/2)), round(i%2)].scatter(incorrect_rows['label']+.3,incorrect_rows['evidence'],c ='k',marker='x')\n",
    "        axs[round(int(i/2)), round(i%2)].plot(np.repeat(E_threshold,11),'b--')\n",
    "        axs[round(int(i/2)), round(i%2)].title.set_text(output_names[i])\n",
    "    \n",
    "    for ax in fig.axes:\n",
    "            # ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "            axLine, axLabel = ax.get_legend_handles_labels()\n",
    "            lines=(axLine)\n",
    "            labels=(axLabel)\n",
    "    fig.text(0.5, 0.01, 'Items Exit at Branch', ha='center', va='center')\n",
    "    fig.text(0.01, 0.5, 'Accuracy %', ha='center', va='center', rotation='vertical')\n",
    "    # fig.legend(lines, labels,bbox_to_anchor=(1., 1), loc=2,borderaxespad=0.,frameon=True)\n",
    "    # fig.set_size_inches(10, 10)\n",
    "    plt.show()\n",
    "    return Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs 4\n",
      "prediction: 4999 of 5000\r"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
    "K= 10 # number of classes\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels,10)\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels,10)\n",
    "shuffle_size = 22500\n",
    "batch_size=1\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "def augment_images(image, label,input_size=(224,224), channel_first = False):\n",
    "            image = tf.image.resize(image,input_size)\n",
    "            if channel_first:\n",
    "                image = tf.transpose(image, [2, 0, 1])\n",
    "            return image, label\n",
    "test_ds_size = len(list(test_ds))\n",
    "test_ds = (test_ds.map(augment_images))\n",
    "t_target = tf.data.Dataset.from_tensor_slices((test_labels))\n",
    "test_ds = tf.data.Dataset.zip((test_ds,t_target))\n",
    "test_ds = (test_ds.batch(batch_size=1, drop_remainder=True))\n",
    "\n",
    "validation_size = 5000\n",
    "validation_images, validation_labels = train_images[:validation_size], train_labels[:validation_size] #get the first 5k training samples as validation set\n",
    "shuffle_size = 22500\n",
    "batch_size=1\n",
    "validation_ds = tf.data.Dataset.from_tensor_slices((validation_images, validation_labels))\n",
    "validation_ds_size = len(list(validation_ds))\n",
    "validation_ds = (validation_ds.map(augment_images))\n",
    "v_target = tf.data.Dataset.from_tensor_slices((validation_labels))\n",
    "validation_ds = tf.data.Dataset.zip((validation_ds,v_target))\n",
    "validation_ds = (validation_ds.batch(batch_size=1, drop_remainder=True))\n",
    "\n",
    "\n",
    "Outputs = collectEvidence_branches(model.model,validation_ds, evidence=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs 2\n",
      "prediction: 9999 of 10000\r"
     ]
    }
   ],
   "source": [
    "# (train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# # print(y_train)\n",
    "# K= 10 # number of classes\n",
    "# test_labels = tf.keras.utils.to_categorical(test_labels,10)\n",
    "# shuffle_size = 22500\n",
    "# batch_size=1\n",
    "# test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "\n",
    "# def augment_images(image, label,input_size=(224,224), channel_first = False):\n",
    "#             image = tf.image.resize(image,input_size)\n",
    "#             if channel_first:\n",
    "#                 image = tf.transpose(image, [2, 0, 1])\n",
    "#             return image, label\n",
    "# test_ds_size = len(list(test_ds))\n",
    "# test_ds = (test_ds.map(augment_images))\n",
    "# t_target = tf.data.Dataset.from_tensor_slices((test_labels))\n",
    "# test_ds = tf.data.Dataset.zip((test_ds,t_target))\n",
    "# test_ds = (test_ds.batch(batch_size=1, drop_remainder=True))\n",
    "# # Predictions = collectEvidence_branches(model,test_ds)\n",
    "# Outputs = collectEvidence_branches(model,test_ds, evidence=False)\n",
    "# # print(Outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2656\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2657\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-a73701d2fc71>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdisplayEvidence_cascade\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mOutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEvidence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-30-14d513ebdc36>\u001b[0m in \u001b[0;36mdisplayEvidence_cascade\u001b[1;34m(branch_predictions, thresholds, output_names, Evidence)\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[0m_branch_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbranch_predictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;31m# print(_branch_predictions)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m     \u001b[0m_branch_predictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_branch_predictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m     \u001b[1;31m# print(_branch_predictions)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[0mrollOver_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIndex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mpop\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    807\u001b[0m         \u001b[1;36m3\u001b[0m  \u001b[0mmonkey\u001b[0m        \u001b[0mNaN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    808\u001b[0m         \"\"\"\n\u001b[1;32m--> 809\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    810\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2926\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2927\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2928\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2657\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2659\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2661\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displayEvidence_cascade(Outputs, Evidence = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''     overlap\n",
    "        if zero, both match, if else they don't match\n",
    "        TT 1-1 =0\n",
    "        TF 1-0 =1\n",
    "\n",
    "        FT 0-1 = -1\n",
    "        FF 0-0 =0\n",
    "        \n",
    "        '''\n",
    "# print(Outputs[1])\n",
    "displayEvidence(Outputs, Evidence = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 227,227 sigmoid evidence cifar10 v2\n",
    "# print(Outputs[0])\n",
    "\n",
    "displayEvidence(Outputs, Evidence = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 227,227 sigmoid evidence cifar10\n",
    "displayEvidence(Predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 227,227 sigmoid cifar10\n",
    "displayEvidence(Predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 32,32 crossEvidence cifar10\n",
    "displayEvidence(Predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "displayEvidence(Predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayEvidence(Predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = tf.keras.models.load_model('alexNetv6_evidence_test.hdf5',\n",
    "    custom_objects={\"CrossEntropyEndpoint\":CrossEntropyEndpoint,\"crossEntropy_loss\":loss_function()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictions_2 = collectEvidence(model_2,test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayEvidence(Predictions_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectEntropy(model,test_ds):\n",
    "    num_outputs = len(model.outputs) # the number of output layers for the purpose of providing labels\n",
    "#     train_ds, test_ds, validation_ds = (dataset)\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    iterator = iter(test_ds)\n",
    "    print(len(test_ds))\n",
    "    item = iterator.get_next()\n",
    "#     print(item)\n",
    "\n",
    "    pClass = []\n",
    "    predictions=[]\n",
    "    pEvidence = []\n",
    "    pUncertainty=[]\n",
    "    Outputs = pd.DataFrame()\n",
    "    output_names=[\"mainExit\"]\n",
    "    pAcc=[]\n",
    "    for i, (x,y) in enumerate(test_ds):\n",
    "#     for i in range(100):\n",
    "        print(\"prediction: {} of {}\".format(i,len(test_ds)),end='\\r')\n",
    "        result = model.predict(x)\n",
    "        pClass.append(tf.argmax(y,1).numpy()[0])\n",
    "        pred= (tf.nn.softmax(result)[0])\n",
    "\n",
    "        pEvidence.append(calcEntropy_Tensors(pred).numpy())\n",
    "        if np.argmax(pred) == np.argmax(y):\n",
    "            pAcc.append(1)       \n",
    "        else:\n",
    "            pAcc.append(0)\n",
    "    Predictions = pd.DataFrame({\"label\":pClass,\"evidence\":pEvidence,\"Acc\":pAcc,\"overlap\":0})\n",
    "    return Predictions\n",
    "\n",
    "def displayEntropy(Predictions):\n",
    "    output_names=[\"mainExit\"]\n",
    "    Outputs=pd.DataFrame()\n",
    "    Predictions[\"Acc\"]=Predictions[\"Acc\"].astype('bool')\n",
    "    acc = Predictions[\"Acc\"].value_counts()\n",
    "    print(acc)\n",
    "    print((acc.loc[True] , acc.loc[False]))\n",
    "    mean = Predictions.loc[(Predictions['Acc'] == False)].groupby(\"Acc\")[\"evidence\"].mean().iloc[0]\n",
    "    std = Predictions.loc[(Predictions['Acc'] == False)].groupby(\"Acc\")[\"evidence\"].std().iloc[0]\n",
    "    E_threshold = mean - std\n",
    "    correct_rows = Predictions.loc[Predictions['Acc'] == True]\n",
    "    incorrect_rows = Predictions.loc[Predictions['Acc'] == False]\n",
    "    # Incorrects_overlap = Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"evidence\"] > E_threshold) & (Predictions[\"overlap\"] == 0)].count().iloc[0]\n",
    "    print(acc)\n",
    "    for i,name in enumerate(output_names):\n",
    "        Outputs = Outputs.append(pd.DataFrame({\"Branch Name\":output_names[i],\n",
    "                \"Accuracy\":(acc.loc[True] /  (acc.loc[True] + acc.loc[False])),\n",
    "                \"E_Threshold\":E_threshold,\n",
    "                # \"Overlap_Threshold\":non_overlapping_incorrects_threshold,\n",
    "                \"acceptance_rate\":Predictions.loc[(Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0]/(Predictions.count().iloc[0]),\n",
    "                \"accepted_correct\":Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                \"accepted_incorrect\":Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                \"accepted_accuracy\":(Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0])/ Predictions.loc[(Predictions[\"evidence\"] < E_threshold)].count()[0],\n",
    "                # \"overlap_adjusted_accuracy\":(Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0] + Incorrects_overlap) / Predictions.loc[(Predictions[\"evidence\"] > E_threshold)].count()[0],\n",
    "                \"rejected_correct\":Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                \"rejected_incorrect\":Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                # \"Incorrects_overlap\":Incorrects_overlap,\n",
    "                },index=[i]))\n",
    "\n",
    "    # fig, axs = plt.subplots(1, 2)\n",
    "    plt.suptitle('Horizontally stacked subplots')\n",
    "    plt.scatter(correct_rows['label'],correct_rows['evidence'],c ='r',marker='+')\n",
    "    plt.scatter(incorrect_rows['label']+.3,incorrect_rows['evidence'],c ='k',marker='x')\n",
    "    plt.plot(np.repeat(E_threshold,11),'b--')\n",
    "    plt.title(\"evidence\")\n",
    "\n",
    "\n",
    "    # fig.set_size_inches(10, 10)\n",
    "    plt.show()\n",
    "    return Outputs\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entropy_predictions = collectEntropy(model_2,test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayEntropy(Entropy_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
    "test_images = test_images.reshape(10000, 32,32,3).astype(\"float32\") / 255\n",
    "\n",
    "# print(y_train)\n",
    "K= 10 # number of classes\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels,10)\n",
    "shuffle_size = 22500\n",
    "batch_size=1\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "\n",
    "def augment_images(image, label,input_size=(227,227), channel_first = False):\n",
    "            image = tf.image.resize(image,input_size)\n",
    "            if channel_first:\n",
    "                image = tf.transpose(image, [2, 0, 1])\n",
    "            return image, label\n",
    "test_ds_size = len(list(test_ds))\n",
    "# test_ds = (test_ds.map(augment_images))\n",
    "t_target = tf.data.Dataset.from_tensor_slices((test_labels))\n",
    "test_ds = tf.data.Dataset.zip((test_ds,t_target))\n",
    "test_ds = (test_ds.batch(batch_size=1, drop_remainder=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictions_mse = collectEvidence(model,test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayEvidence(Predictions_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sum entropy \n",
    "import pandas as pd\n",
    "def entropy(x):\n",
    "    return -(x * math.log(x))\n",
    "# Data for plotting\n",
    "t = np.arange(0.00001, 1, 0.01)\n",
    "print(t.shape)\n",
    "t_ = np.full((100,), .1)\n",
    "df = pd.DataFrame([t,t,t_,t,t])\n",
    "# print(df.transpose())\n",
    "p = df.apply(calcEntropy,axis=0)\n",
    "# print(p)\n",
    "# print(p)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(t, p)\n",
    "ax.set(xlabel='Probability of Outcome',ylabel='Entropy of event')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [0]\n",
    "y_pred = [.99,.01, .01, .0, .01, .01]\n",
    "# Using 'auto'/'sum_over_batch_size' reduction type.  \n",
    "scce = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "crossE = scce(y_true, y_pred).numpy()\n",
    "print(\"crossE: \",crossE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [0,1,0,0,0,0]\n",
    "y_pred = [.99,.01, .01, .0, .01, .01]\n",
    "# Using 'auto'/'sum_over_batch_size' reduction type.  \n",
    "scce = tf.keras.losses.CategoricalCrossentropy()\n",
    "crossE = scce(y_true, y_pred).numpy()\n",
    "print(\"crossE: \",crossE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [0]\n",
    "y_pred = [.0,.01, .9, .0, .0, .0]\n",
    "ent = calcEntropy(y_pred)\n",
    "print(\"Entropy: \",ent)\n",
    "loss = ent *1\n",
    "print(\"Loss: \",loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [[0],[0],[0]]\n",
    "y_pred = [[.9,.5, .6, .5, .5, .5],[.8,.5, .6, .5, .5, .5],[.7,.5, .6, .5, .5, .5]]\n",
    "y_pred = [[.9,.0,.0,.0,.0,.0,],[.8,.5, .6, .5, .5, .5],[.7,.5, .6, .5, .5, .5]]\n",
    "# y_pred = [.1,.1, .1, .1, .1, .1]\n",
    "# Using 'auto'/'sum_over_batch_size' reduction type.  \n",
    "scce = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "crossE = scce(y_true, y_pred).numpy()\n",
    "print(\"crossE: \",crossE)\n",
    "\n",
    "''' When the answer is correct, CrossE goes down\n",
    "    When \n",
    "    When its wrong, Entropy High\n",
    "    When its right, Entropy Low\n",
    "    \n",
    "    so penalize being right with low entropy and reward being right with high entropy\n",
    "    \n",
    "    \n",
    "    OORRRR train a second model for a branch to determine if you are going to get it right or not?\n",
    "    Isn't that what ResNet Did? you calculate if the blocks will contribute, was it block drop?\n",
    "    Binary classification,\n",
    "    could be done at the branch end as a separate evaulator, using the entropy score and the input to the branch as inputs?\n",
    "'''\n",
    "\n",
    "\n",
    "ent = calcEntropy(y_pred)\n",
    "print(\"Entropy: \",ent)\n",
    "loss = crossE + ent\n",
    "print(\"combined Loss: \",loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[.1,.1, .675, .1091, .4311, .1875,.121,.143,.2,.5]]\n",
    "x = tf.constant([[2, 20, 30, 3, 6], [3, 11, 16, 1, 8],\n",
    "                 [14, 45, 23, 5, 27]])\n",
    "\n",
    "print(list(map(np.argmax,np.array(x))))\n",
    "def foo(y_pred):\n",
    "    y_pred = y_pred.numpy()\n",
    "    pred_label = list(map(np.argmax,np.array(y_pred)))\n",
    "    return pred_label\n",
    "%timeit foo(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_true = tf.constant([[2],[2],[0]])\n",
    "A = tf.constant([.1,.1, .675, .1091, .4311, .1875,.121,.143,.2,.5])\n",
    "B = tf.constant([[2, 20, 30, 3, 6], [3, 11, 16, 1, 8],\n",
    "                 [14, 45, 23, 5, 27]])\n",
    "\n",
    "y_pred = tf.constant([[.9,.5, .6, .5, .5, .5],[.8,.5, .6, .5, .5, .5],[.7,.5, .6, .5, .5, .5]])\n",
    "\n",
    "# new_list = new_list = [list(range(10)) for _ in range(10)]\n",
    "\n",
    "print(tf.math.argmax(y_pred,1))\n",
    "pred_labels = tf.math.argmax(y_pred,1)\n",
    "print(tf.reshape(y_true,pred_labels.shape))\n",
    "indexes = tf.where(tf.math.equal(pred_labels, tf.cast(tf.reshape(y_true,pred_labels.shape),'int64')))\n",
    "indexes = tf.reshape(indexes,[-1])\n",
    "# print(tf.gather(B,indexes))\n",
    "CorrectE = tf.gather(y_pred,indexes)\n",
    "print(CorrectE)\n",
    "# print(calcEntropy(CorrectE[0]))\n",
    "\n",
    "\n",
    "results = tf.map_fn(calcEntropy,tf.cast(CorrectE,'float'))\n",
    "print(\"results: \",results)\n",
    "\n",
    "\n",
    "\n",
    "%timeit tf.map_fn(calcEntropy,tf.cast(CorrectE,'float'))\n",
    "\n",
    "\n",
    "crossE = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "crossE(y_true,y_pred)\n",
    "%timeit crossE(y_true,y_pred)\n",
    "# [\n",
    "#     [\n",
    "#         [ 2 20 30  3  6]\n",
    "#     ]\n",
    "#     [\n",
    "#         [ 3 11 16  1  8]\n",
    "#     ]\n",
    "# ]\n",
    "\n",
    "def entropyAddition_noCross(y_true, y_pred):\n",
    "    crossE = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    #Entropy is added to the CrossE divided by the len of inputs\n",
    "    pred_labels = tf.math.argmax(y_pred,1)\n",
    "    indexes = tf.where(tf.math.equal(pred_labels, tf.cast(tf.reshape(y_true,pred_labels.shape),'int64')))\n",
    "    indexes = tf.reshape(indexes,[-1])\n",
    "    entropies = tf.gather(y_pred,indexes)\n",
    "    if tf.equal(tf.size(entropies), 0):\n",
    "        correctEntropies = 0\n",
    "    else:\n",
    "        correctEntropies = tf.reduce_mean(tf.map_fn(calcEntropy_Tensors,tf.cast(entropies,'float')))\n",
    "    scce = crossE(y_true, y_pred)\n",
    "    loss = correctEntropies\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.constant([[1],[2],[0]])\n",
    "y_pred = tf.constant([[0,0, .6, .5, .5, .5],[.8,.5, .6, .5, .5, .5],[.9,.3, .3, .2, .1, .32]])\n",
    "crossE = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "def entropyAddition(y_true, y_pred):\n",
    "    crossE = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    #Entropy is added to the CrossE divided by the len of inputs\n",
    "    pred_labels = tf.math.argmax(y_pred,1)\n",
    "    indexes = tf.where(tf.math.equal(pred_labels, tf.cast(tf.reshape(y_true,pred_labels.shape),'int64')))\n",
    "    indexes = tf.reshape(indexes,[-1])\n",
    "    entropies = tf.gather(y_pred,indexes)\n",
    "    if tf.equal(tf.size(entropies), 0):\n",
    "        correctEntropies = 0\n",
    "    else:\n",
    "        correctEntropies = tf.reduce_mean(tf.map_fn(calcEntropy_Tensors,tf.cast(entropies,'float')))\n",
    "    scce = crossE(y_true, y_pred)\n",
    "    loss = scce + (correctEntropies * scce)\n",
    "    return loss\n",
    "\n",
    "\n",
    "print(\"normal CrossE: \",crossE(y_true ,y_pred))\n",
    "\n",
    "print(\"normal Entropy\",entropyAddition_noCross(y_true2,y_pred2))\n",
    "\n",
    "print(entropyAddition(y_true2, y_pred2))\n",
    "# %timeit entropyAddition(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.constant([1])\n",
    "y_pred = tf.constant([0,1, 0, 0, 0, 0])\n",
    "# print(crossE(y_true,y_pred))\n",
    "\n",
    "print(tf.cast(1e-8,'float')+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.constant([[1],[2],[0]])\n",
    "y_pred = tf.constant([[.9,.1, .6, .5, .5, .5],[.8,.5, .6, .5, .5, .5],[.9,.3, .3, .2, .1, .32]])\n",
    "crossE = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "def entropyMultiplication(y_true, y_pred):\n",
    "    crossE = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    #Entropy is added to the CrossE divided by the len of inputs\n",
    "    pred_labels = tf.math.argmax(y_pred,1)\n",
    "    indexes = tf.where(tf.math.equal(pred_labels, tf.cast(tf.reshape(y_true,pred_labels.shape),'int64')))\n",
    "    indexes = tf.reshape(indexes,[-1])\n",
    "    entropies = tf.gather(y_pred,indexes)\n",
    "    if tf.equal(tf.size(entropies), 0):\n",
    "        correctEntropies = 1\n",
    "    else:\n",
    "        correctEntropies = tf.reduce_mean(tf.map_fn(calcEntropy_Tensors,tf.cast(entropies,'float')))\n",
    "    scce = crossE(y_true, y_pred)\n",
    "    loss = correctEntropies * scce\n",
    "    return loss\n",
    "\n",
    "\n",
    "print(\"normal CrossE: \",crossE(y_true,y_pred))\n",
    "print(entropyAddition(y_true, y_pred))\n",
    "# %timeit entropyAddition(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.constant([[1],[2],[1]])\n",
    "y_pred = tf.constant([[.9,.1, .6, .5, .5, .5],[.8,.5, .6, .5, .5, .5],[.9,.3, .3, .2, .1, .32]])\n",
    "\n",
    "def confidenceScore(y_true, y_pred):\n",
    "        # print(y_pred)\n",
    "        # print(tf.keras.backend.get_value(y_pred))\n",
    "        \n",
    "        # y_true =y_true.numpy()\n",
    "        # y_pred = y_pred.numpy()\n",
    "        # AvgConfidence = -1\n",
    "        pred_labels = tf.math.argmax(y_pred,1)\n",
    "        # countCorrect=0\n",
    "        indexes = tf.where(tf.math.equal(pred_labels, tf.cast(tf.reshape(y_true,pred_labels.shape),'int64')))\n",
    "        indexes = tf.reshape(indexes,[-1])\n",
    "        entropies = tf.gather(y_pred,indexes)\n",
    "        if tf.equal(tf.size(entropies), 0):\n",
    "            correctEntropies = 0\n",
    "        else:\n",
    "            correctEntropies = tf.reduce_mean(tf.map_fn(calcEntropy,tf.cast(entropies,'float')))    \n",
    "        \n",
    "        return correctEntropies\n",
    "    \n",
    "print(confidenceScore(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [[2],[2],[0]]\n",
    "y_pred = [[.9,0, .6, .5, .5, .5],[.8,.5, .6, .5, .5, .5],[.7,.5, .6, .5, .5, .5]]\n",
    "\n",
    "def foo(x, y):\n",
    "    scce = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    crossE = scce(x, y).numpy()\n",
    "    return crossE\n",
    "\n",
    "print(foo(y_true,y_pred))\n",
    "%timeit foo(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Python program explaining \n",
    "# where() function \n",
    "  \n",
    "import numpy as np\n",
    "  \n",
    "# a is an array of integers.\n",
    "a = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "  \n",
    "print(a)\n",
    "  \n",
    "print ('Indices of elements <4')\n",
    "  \n",
    "b = np.where(a<5)\n",
    "print(b)\n",
    "  \n",
    "print(\"Elements which are <4\")\n",
    "print(a[b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [[0],[0],[0]]\n",
    "y_pred = [[.5,.5, .6, .5, .5, .1],[.5,.5, .6, .5, .5, .2],[.5,.5, .6, .5, .5, .3]]\n",
    "# y_pred = [[1],[1],[1]]\n",
    "# print(np.array(y_pred))\n",
    "\n",
    "####\n",
    "# Numpy confidence metric version\n",
    "y_true =np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "def argmax(x):\n",
    "    return [np.argmax(x)]\n",
    "pred_labels = list(map(argmax,np.array(y_pred)))\n",
    "x = np.where(np.equal(y_true,pred_labels) ==True)\n",
    "y = y_pred[x[0]]\n",
    "results = calcEntropy(y)\n",
    "print(results)\n",
    "if not (results):\n",
    "    print(\"A\")\n",
    "print(np.median(results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_true = [[2],[2],[0]]\n",
    "y_pred = [[.5,.5, .6, .5, .5, .5],[.5,.5, .6, .5, .5, .5],[.5,.5, .6, .5, .5, .5]]\n",
    "\n",
    "y_true = [[2]]\n",
    "y_pred = [[.1,.1, .15, .1, .1, .1]]\n",
    "def entropyAddition_loss():\n",
    "    #create a wrapper function that returns a function\n",
    "    crossE = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    def entropyAddition(y_true, y_pred):\n",
    "        #Entropy is added to the CrossE divided by the len of inputs\n",
    "        pred_labels = tf.math.argmax(y_pred,1)\n",
    "        indexes = tf.where(tf.math.equal(pred_labels, tf.cast(tf.reshape(y_true,pred_labels.shape),'int64')))\n",
    "        indexes = tf.reshape(indexes,[-1])\n",
    "        entropies = tf.gather(y_pred,indexes)\n",
    "        correctEntropies = tf.reduce_mean(tf.map_fn(calcEntropy,tf.cast(entropies,'float')))\n",
    "#         print(pred_label)\n",
    "        scce = crossE(y_true, y_pred)\n",
    "        sumEntropy = 0\n",
    "        loss = correctEntropies + scce\n",
    "        return loss\n",
    "    \n",
    "    return entropyAddition\n",
    "\n",
    "def custom_loss_multi(y_true, y_pred):\n",
    "    #CrossE is multiplied by the Entropy\n",
    "    pred_label = list(map(np.argmax,np.array(y_pred)))\n",
    "    crossE = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    sumLoss = 0\n",
    "    \n",
    "    for i in range(len(y_pred)):\n",
    "        loss = crossE(y_true[i], y_pred[i])\n",
    "#         print('crossE: ',loss)\n",
    "        if pred_label[i] == y_true[i]:\n",
    "#             print('calcEntropy ',calcEntropy(y_pred[i]))\n",
    "            loss = loss * calcEntropy(y_pred[i])\n",
    "        sumLoss += loss\n",
    "    sumLoss = sumLoss / len(y_pred)         \n",
    "    \n",
    "#     loss = crossE(y_true, y_pred)\n",
    "#     print(\"CrossE : \",loss.numpy())\n",
    "#     print(\"Loss : \",sumLoss)\n",
    "    return sumLoss\n",
    "    ### I want to reduce the entropy of correct answers\n",
    "    ### if label - pred = 0 (aka correct) then add entropy to crossE\n",
    "    \n",
    "    \n",
    "#     squared_difference = tf.square(np.array(y_true) - np.array(y_pred))\n",
    "#     return tf.reduce_mean(squared_difference, axis=-1)  # Note the `axis=-1`\n",
    "\n",
    "scce = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "crossE = scce(y_true, y_pred).numpy()\n",
    "print(\"crossEntropyLoss: \",crossE)\n",
    "\n",
    "\n",
    "crossE = custom_loss_addition(y_true, y_pred).numpy()\n",
    "print(\"customLoss_addition: \",crossE)\n",
    "\n",
    "\n",
    "crossE = custom_loss_multi(y_true, y_pred).numpy()\n",
    "print(\"customLoss_multi: \",crossE)\n",
    "\n",
    "  \n",
    "# model.compile(loss=custom_loss, optimizer='adam')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sub(x,y):\n",
    "    if x - y == 0:\n",
    "        return 1\n",
    "%timeit sub(5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sub(x,y):\n",
    "    if x == y:\n",
    "        return 0\n",
    "    \n",
    "%timeit sub(5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7483e188a462fd4248cd8d23b24bc727a5fe7a35e4044aa57ebcc92f8fe9e445"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
